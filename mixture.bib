
@article{van_kollenburg_lazy_nodate,
	title = {The {Lazy} {Bootstrap}. {A} {Fast} {Resampling} {Method} for {Evaluating} {Latent} {Class} {Model} {Fit}},
	abstract = {The latent class model is a powerful unsupervised clustering algorithm for categorical data. Many statistics exist to test the ﬁt of the latent class model. However, traditional methods to evaluate those ﬁt statistics are not always useful. Asymptotic distributions are not always known, and empirical reference distributions can be very time consuming to obtain. In this paper we propose a fast resampling scheme with which any type of model ﬁt can be assessed. We illustrate it here on the latent class model, but the methodology can be applied in any situation. The principle behind the lazy bootstrap method is to specify a statistic which captures the characteristics of the data that a model should capture correctly. If those characteristics in the observed data and in model-generated data are very diﬀerent we can assume that the model could not have produced the observed data. With this method we achieve the ﬂexibility of tests from the Bayesian framework, while only needing maximum likelihood estimates. We provide a step-wise algorithm with which the ﬁt of a model can be assessed based on the characteristics we as researcher ﬁnd important. In a Monte Carlo study we show that the method has very low type I errors, for all illustrated statistics. Power to reject a model depended largely on the type of statistic that was used and on sample size. We applied the method to an empirical data set on clinical subgroups with risk of Myocardial infarction and compared the results directly to the parametric bootstrap. The results of our method were highly similar to those obtained by the parametric bootstrap, while the required computations diﬀered three orders of magnitude in favour of our method.},
	language = {en},
	author = {van Kollenburg, Geert H and Mulder, Joris and Vermunt, Jeroen K},
	pages = {23},
	file = {van Kollenburg et al_The Lazy Bootstrap.pdf:C\:\\Users\\danie\\Zotero\\storage\\TAW37RC4\\van Kollenburg et al_The Lazy Bootstrap.pdf:application/pdf},
}

@article{akogul_comparison_2016,
	title = {A {Comparison} of {Information} {Criteria} in {Clustering} {Based} on {Mixture} of {Multivariate} {Normal} {Distributions}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2297-8747/21/3/34},
	doi = {10.3390/mca21030034},
	abstract = {Clustering analysis based on a mixture of multivariate normal distributions is commonly used in the clustering of multidimensional data sets. Model selection is one of the most important problems in mixture cluster analysis based on the mixture of multivariate normal distributions. Model selection involves the determination of the number of components (clusters) and the selection of an appropriate covariance structure in the mixture cluster analysis. In this study, the efficiency of information criteria that are commonly used in model selection is examined. The effectiveness of information criteria has been determined according to the success in the selection of the number of components and in the selection of an appropriate covariance matrix.},
	language = {en},
	number = {3},
	urldate = {2021-08-09},
	journal = {Mathematical and Computational Applications},
	author = {Akogul, Serkan and Erisoglu, Murat},
	month = sep,
	year = {2016},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cluster analysis, information criteria, mixture models},
	pages = {34},
	file = {Akogul_Erisoglu_2016_A Comparison of Information Criteria in Clustering Based on Mixture of.pdf:C\:\\Users\\danie\\Zotero\\storage\\WKX9F323\\Akogul_Erisoglu_2016_A Comparison of Information Criteria in Clustering Based on Mixture of.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\6JKUC3QF\\htm.html:text/html},
}

@article{lee_comparison_2021,
	title = {A comparison of full information maximum likelihood and multiple imputation in structural equation modeling with missing data},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/met0000381},
	abstract = {This article compares two missing data procedures, full information maximum likelihood (FIML) and multiple imputation (MI), to investigate their relative performances in relation to the results from analyses of the original complete data or the hypothetical data available before missingness occurred. By expressing the FIML estimator as a special MI estimator, we predicted the expected patterns of discrepancy between the two estimators. Via Monte Carlo simulation studies where we have access to the original complete data, we compare the performance of FIML and MI estimators to that of the complete data maximum likelihood (ML) estimator under a wide range of conditions, including differences in sample size, percent of missingness, and degrees of model misfit. Our study confirmed well-known knowledge that the two estimators tend to yield essentially equivalent results to each other and to those from analysis of complete data when the postulated model is correctly specified. However, some noteworthy patterns of discrepancies were found between the FIML and MI estimators when the hypothesized model does not hold exactly in the population: MI-based parameter estimates, comparative fit index (CFI), and the Tucker Lewis index (TLI) tend to be closer to the counterparts of the complete data ML estimates, whereas FIML-based chi-squares and root mean square error of approximation (RMSEA) tend to be closer to the counterparts of the complete data ML estimates. We explained the observed patterns of discrepancy between the two estimators as a function of the interplay between the parsimony and accuracy of the imputation model. We concluded by discussing practical and methodological implications and issues for further research. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	journal = {Psychological Methods},
	author = {Lee, Taehun and Shi, Dexin},
	year = {2021},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Maximum Likelihood, Sample Size, Simulation, Statistical Data, Structural Equation Modeling},
	pages = {No Pagination Specified--No Pagination Specified},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\JFMXBC8G\\2021-12018-001.html:text/html},
}

@article{norman_likert_2010,
	title = {Likert scales, levels of measurement and the “laws” of statistics},
	volume = {15},
	issn = {1573-1677},
	url = {https://doi.org/10.1007/s10459-010-9222-y},
	doi = {10.1007/s10459-010-9222-y},
	abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for “getting the wrong answer”.},
	language = {en},
	number = {5},
	urldate = {2021-08-03},
	journal = {Advances in Health Sciences Education},
	author = {Norman, Geoff},
	month = dec,
	year = {2010},
	pages = {625--632},
	file = {Norman_2010_Likert scales, levels of measurement and the “laws” of statistics.pdf:C\:\\Users\\danie\\Zotero\\storage\\J3D499WJ\\Norman_2010_Likert scales, levels of measurement and the “laws” of statistics.pdf:application/pdf},
}

@article{vermunt_k-means_2011,
	title = {K-means may perform as well as mixture model clustering but may also be much worse: {Comment} on {Steinley} and {Brusco} (2011).},
	volume = {16},
	issn = {1939-1463, 1082-989X},
	shorttitle = {K-means may perform as well as mixture model clustering but may also be much worse},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0020144},
	doi = {10.1037/a0020144},
	abstract = {Steinley and Brusco (2011) presented the results of a huge simulation study aimed at evaluating cluster recovery of mixture model clustering (MMC) both for the situation where the number of clusters is known and is unknown. They derived rather strong conclusions on the basis of this study, especially with regard to the good performance of K-means (KM) compared with MMC. I agree with the authors’ conclusion that the performance of KM may be equal to MMC in certain situations, which are primarily the situations investigated by Steinley and Brusco. However, a weakness of the paper is the failure to investigate many important real-world situations where theory suggests that MMC should outperform KM. This article elaborates on the KM–MMC comparison in terms of cluster recovery and provides some additional simulation results that show that KM may be much worse than MMC. Moreover, I show that KM is equivalent to a restricted mixture model estimated by maximizing the classiﬁcation likelihood and comment on Steinley and Brusco’s recommendation regarding the use of mixture models for clustering.},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {Psychological Methods},
	author = {Vermunt, Jeroen K.},
	month = mar,
	year = {2011},
	pages = {82--88},
	file = {Vermunt_2011_K-means may perform as well as mixture model clustering but may also be much.pdf:C\:\\Users\\danie\\Zotero\\storage\\LILNTAL7\\Vermunt_2011_K-means may perform as well as mixture model clustering but may also be much.pdf:application/pdf},
}

@article{rubin_inference_1976,
	title = {Inference and {Missing} {Data}},
	volume = {63},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2335739},
	doi = {10.2307/2335739},
	abstract = {When making sampling distribution inferences about the parameter of the data, θ, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about θ, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from θ. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.},
	number = {3},
	urldate = {2021-07-27},
	journal = {Biometrika},
	author = {Rubin, Donald B.},
	year = {1976},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {581--592},
}

@article{boker_openmx_2011,
	title = {{OpenMx}: {An} {Open} {Source} {Extended} {Structural} {Equation} {Modeling} {Framework}},
	volume = {76},
	issn = {0033-3123},
	shorttitle = {{OpenMx}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3525063/},
	doi = {10.1007/s11336-010-9200-6},
	abstract = {OpenMx is free, full–featured, open source, structural equation modeling (SEM) software. OpenMx runs within the R statistical programming environment on Windows, Mac OS–X, and Linux computers. The rationale for developing OpenMx is discussed along with the philosophy behind the user interface. The OpenMx data structures are introduced — these novel structures define the user interface framework and provide new opportunities for model specification. Two short example scripts for the specification and fitting of a confirmatory factor model are next presented. We end with an abbreviated list of modeling applications available in OpenMx 1.0 and a discussion of directions for future development.},
	number = {2},
	urldate = {2021-07-26},
	journal = {Psychometrika},
	author = {Boker, Steven and Neale, Michael and Maes, Hermine and Wilde, Michael and Spiegel, Michael and Brick, Timothy and Spies, Jeffrey and Estabrook, Ryne and Kenny, Sarah and Bates, Timothy and Mehta, Paras and Fox, John},
	month = apr,
	year = {2011},
	pmid = {23258944},
	pmcid = {PMC3525063},
	pages = {306--317},
	file = {Boker et al_2011_OpenMx.pdf:C\:\\Users\\danie\\Zotero\\storage\\JPIYUQMB\\Boker et al_2011_OpenMx.pdf:application/pdf},
}

@incollection{vermunt_jk_latent_2004,
	title = {Latent class analysis},
	isbn = {978-0-7619-2363-3},
	url = {https://research.tilburguniversity.edu/en/publications/0caedd00-27c1-42bd-bb4e-d1dcb0864956},
	language = {en},
	urldate = {2021-07-25},
	booktitle = {The {Sage} encyclopedia of social sciences research methods},
	publisher = {Sage},
	author = {{Vermunt, J.K.} and {Magidson, J.} and {Lewis-Beck, M.} and {Bryman, A.} and {Liao, T.F.} and {Department of Methodology and Statistics}},
	year = {2004},
	pages = {549--553},
	file = {Vermunt, J.K. et al_2004_Latent class analysis.pdf:C\:\\Users\\danie\\Zotero\\storage\\UG5JMK2Y\\Vermunt, J.K. et al_2004_Latent class analysis.pdf:application/pdf},
}

@article{shireman_examining_2017,
	title = {Examining the effect of initialization strategies on the performance of {Gaussian} mixture modeling},
	volume = {49},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-015-0697-6},
	doi = {10.3758/s13428-015-0697-6},
	language = {en},
	number = {1},
	urldate = {2021-07-27},
	journal = {Behavior Research Methods},
	author = {Shireman, Emilie and Steinley, Douglas and Brusco, Michael J.},
	month = feb,
	year = {2017},
	pages = {282--293},
	file = {Shireman et al_2017_Examining the effect of initialization strategies on the performance of.pdf:C\:\\Users\\danie\\Zotero\\storage\\LTFZ7BZR\\Shireman et al_2017_Examining the effect of initialization strategies on the performance of.pdf:application/pdf},
}

@article{biernacki_choosing_2003,
	series = {Recent {Developments} in {Mixture} {Model}},
	title = {Choosing starting values for the {EM} algorithm for getting the highest likelihood in multivariate {Gaussian} mixture models},
	volume = {41},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947302001639},
	doi = {10.1016/S0167-9473(02)00163-9},
	abstract = {Simple methods to choose sensible starting values for the EM algorithm to get maximum likelihood parameter estimation in mixture models are compared. They are based on random initialization, using a classification EM algorithm (CEM), a Stochastic EM algorithm (SEM) or previous short runs of EM itself. Those initializations are included in a search/run/select strategy which can be compounded by repeating the three steps. They are compared in the context of multivariate Gaussian mixtures on the basis of numerical experiments on both simulated and real data sets in a target number of iterations. The main conclusions of those numerical experiments are the following. The simple random initialization which is probably the most employed way of initiating EM is often outperformed by strategies using CEM, SEM or shorts runs of EM before running EM. Also, it appears that compounding is generally profitable since using a single run of EM can often lead to suboptimal solutions. Otherwise, none of the experimental strategies can be regarded as the best one and it is difficult to characterize situations where a particular strategy can be expected to outperform the other ones. However, the strategy initiating EM with short runs of EM can be recommended. This strategy, which as far as we know was not used before the present study, has some advantages. It is simple, performs well in a lot of situations presupposing no particular form of the mixture to be fitted to the data and seems little sensitive to noisy data.},
	language = {en},
	number = {3},
	urldate = {2021-07-26},
	journal = {Computational Statistics \& Data Analysis},
	author = {Biernacki, Christophe and Celeux, Gilles and Govaert, Gérard},
	month = jan,
	year = {2003},
	keywords = {Classification EM, EM algorithm, Initialization strategies, Multivariate Gaussian mixture, Optimization, Stochastic EM},
	pages = {561--575},
	file = {ScienceDirect Snapshot:C\:\\Users\\danie\\Zotero\\storage\\YNJBEZNR\\S0167947302001639.html:text/html},
}

@article{wu_abuse_2011,
	title = {Abuse and dependence on prescription opioids in adults: a mixture categorical and dimensional approach to diagnostic classification},
	volume = {41},
	issn = {1469-8978, 0033-2917},
	shorttitle = {Abuse and dependence on prescription opioids in adults},
	url = {https://www.cambridge.org/core/journals/psychological-medicine/article/abs/abuse-and-dependence-on-prescription-opioids-in-adults-a-mixture-categorical-and-dimensional-approach-to-diagnostic-classification/A56D6B96CF458C36A272BD3170D3FA47},
	doi = {10.1017/S0033291710000954},
	abstract = {BackgroundFor the emerging DSM-V, it has been recommended that dimensional and categorical methods be used simultaneously in diagnostic classification; however, little is known about this combined approach for abuse and dependence.MethodUsing data (n=37 708) from the 2007 National Survey on Drug Use and Health (NSDUH), DSM-IV criteria for prescription opioid abuse and dependence among non-prescribed opioid users (n=3037) were examined using factor analysis (FA), latent class analysis (LCA, categorical), item response theory (IRT, dimensional), and factor mixture (hybrid) approaches.ResultsA two-class factor mixture model (FMM) combining features of categorical latent classes and dimensional IRT estimates empirically fitted more parsimoniously to abuse and dependence criteria data than models from FA, LCA and IRT procedures respectively. This mixture model included a severely affected group (7\%) with a comparatively moderate to high probability (0.32−0.88) of endorsing all abuse and dependence criteria items, and a less severely affected group (93\%) with a low probability (0.003−0.16) of endorsing all criteria. The two empirically defined groups differed significantly in the pattern of non-prescribed opioid use, co-morbid major depression, and substance abuse treatment use.ConclusionsA factor mixture model integrating categorical and dimensional features of classification fits better to DSM-IV criteria for prescription opioid abuse and dependence in adults than a categorical or dimensional approach. Research is needed to examine the utility of this mixture classification for substance use disorders and treatment response.},
	language = {en},
	number = {3},
	urldate = {2021-07-25},
	journal = {Psychological Medicine},
	author = {Wu, L.-T. and Woody, G. E. and Yang, C. and Pan, J.-J. and Blazer, D. G.},
	month = mar,
	year = {2011},
	note = {Publisher: Cambridge University Press},
	keywords = {DSM-IV, factor mixture model, item response theory, latent class analyses, nosology, prescription opioid use disorders},
	pages = {653--664},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\MBIYP587\\A56D6B96CF458C36A272BD3170D3FA47.html:text/html;Wu et al_2011_Abuse and dependence on prescription opioids in adults.pdf:C\:\\Users\\danie\\Zotero\\storage\\FMJYDIN4\\Wu et al_2011_Abuse and dependence on prescription opioids in adults.pdf:application/pdf},
}

@article{baughman_mixture_2006,
	title = {Mixture model analysis for establishing a diagnostic cut-off point for pertussis antibody levels},
	volume = {25},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2442},
	doi = {10.1002/sim.2442},
	abstract = {Previous studies of pertussis (whooping cough) that have derived diagnostic cut-off points for pertussis antibody levels have assumed a single distribution for antibody levels and have used small sample sizes. In a recent study of 5409 serum samples from the Third National Health and Nutrition Examination Survey (NHANES III), a finite mixture model was developed to examine the distribution of immunoglobulin G (IgG) antibody levels against pertussis toxin (PT), an antigen specific to the Bordetella pertussis bacterium. The mixture model identified three component populations with antibody levels greater than the quantitative assay's lower limit of quantitation (LLQ) and included a point distribution located at or below the LLQ to account for the excess number of antibody values that fell below the LLQ. The mixture model analysis accounted for the NHANES III design. A cut-off point for anti-PT IgG levels was chosen to have a 99 per cent model specificity based on the two overlapping normal distributions assumed for the two component populations with the highest antibody levels. This cut-off point may have a higher diagnostic sensitivity for acute B. pertussis infection than other cut-off points derived by assuming a single distribution for antibody levels. Published in 2005 by John Wiley \& Sons, Ltd.},
	language = {en},
	number = {17},
	urldate = {2021-07-25},
	journal = {Statistics in Medicine},
	author = {Baughman, Andrew L. and Bisgard, Kristine M. and Lynn, Freyja and Meade, Bruce D.},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2442},
	keywords = {antibodies, diagnostic cut-off point, mixture model, pertussis, Third National Health and Nutrition Examination Survey},
	pages = {2994--3010},
	file = {Baughman et al_2006_Mixture model analysis for establishing a diagnostic cut-off point for.pdf:C\:\\Users\\danie\\Zotero\\storage\\8C4JF3FR\\Baughman et al_2006_Mixture model analysis for establishing a diagnostic cut-off point for.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\8BEQWSGI\\sim.html:text/html},
}

@article{figueiredo_unsupervised_2002,
	title = {Unsupervised learning of finite mixture models},
	volume = {24},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/990138/},
	doi = {10.1109/34.990138},
	abstract = {ÐThis paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective ªunsupervisedº is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.},
	language = {en},
	number = {3},
	urldate = {2021-07-25},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Figueiredo, M.A.T. and Jain, A.K.},
	month = mar,
	year = {2002},
	pages = {381--396},
	file = {Figueiredo_Jain_2002_Unsupervised learning of finite mixture models.pdf:C\:\\Users\\danie\\Zotero\\storage\\WH7EXMDQ\\Figueiredo_Jain_2002_Unsupervised learning of finite mixture models.pdf:application/pdf},
}

@article{van_lissa_worcs_2020,
	title = {{WORCS}: {A} {Workflow} for {Open} {Reproducible} {Code} in {Science}},
	shorttitle = {{WORCS}},
	url = {https://osf.io/zcvbs/},
	doi = {10.17605/OSF.IO/ZCVBS},
	abstract = {Hosted on the Open Science Framework},
	language = {en},
	urldate = {2020-05-06},
	author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara},
	month = may,
	year = {2020},
	note = {Publisher: OSF},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\UMDTXGQG\\zcvbs.html:text/html},
}

@article{nylund_deciding_2007,
	title = {Deciding on the {Number} of {Classes} in {Latent} {Class} {Analysis} and {Growth} {Mixture} {Modeling}: {A} {Monte} {Carlo} {Simulation} {Study}},
	volume = {14},
	issn = {1070-5511},
	shorttitle = {Deciding on the {Number} of {Classes} in {Latent} {Class} {Analysis} and {Growth} {Mixture} {Modeling}},
	url = {http://dx.doi.org/10.1080/10705510701575396},
	doi = {10.1080/10705510701575396},
	abstract = {Mixture modeling is a widely applied data analysis technique used to identify unobserved heterogeneity in a population. Despite mixture models' usefulness in practice, one unresolved issue in the application of mixture models is that there is not one commonly accepted statistical indicator for deciding on the number of classes in a study population. This article presents the results of a simulation study that examines the performance of likelihood-based tests and the traditionally used Information Criterion (ICs) used for determining the number of classes in mixture modeling. We look at the performance of these tests and indexes for 3 types of mixture models: latent class analysis (LCA), a factor mixture model (FMA), and a growth mixture models (GMM). We evaluate the ability of the tests and indexes to correctly identify the number of classes at three different sample sizes (n = 200, 500, 1,000). Whereas the Bayesian Information Criterion performed the best of the ICs, the bootstrap likelihood ratio test proved to be a very consistent indicator of classes across all of the models considered.},
	number = {4},
	urldate = {2016-12-08},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Nylund, Karen L. and Asparouhov, Tihomir and Muthén, Bengt O.},
	month = oct,
	year = {2007},
	pages = {535--569},
	file = {Nylund et al_2007_Deciding on the Number of Classes in Latent Class Analysis and Growth Mixture.pdf:C\:\\Users\\danie\\Zotero\\storage\\CWQE8NMZ\\Nylund et al_2007_Deciding on the Number of Classes in Latent Class Analysis and Growth Mixture.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\JTC9MZKW\\10705510701575396.html:text/html},
}

@article{nylund-gibson_ten_2018,
	title = {Ten frequently asked questions about latent class analysis.},
	volume = {4},
	issn = {2332-2179, 2332-2136},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/tps0000176},
	doi = {10.1037/tps0000176},
	abstract = {Latent class analysis (LCA) is a statistical method used to identify unobserved subgroups in a population with a chosen set of indicators. Given the increasing popularity of LCA, our aim is to equip psychological researchers with the theoretical and statistical fundamentals that we believe will facilitate the application of LCA models in practice. In this article, we provide answers to 10 frequently asked questions about LCA. The questions included in this article were fielded from our experience consulting with applied researchers interested in using LCA. The major topics include a general introduction in the LCA; an overview of class enumeration (e.g., deciding on the number of classes), including commonly used statistical fit indices; substantive interpretation of LCA solutions; estimation of covariates and distal outcome relations to the latent class variable; data requirements for LCA; software choices and considerations; distinctions and similarities among LCA and related latent variable models; and extensions of the LCA model. To illustrate the modeling ideas described in this article, we present an applied example using LCA. Specifically, we use LCA to model individual differences in positive youth development among college students and analyze demographic characteristics as covariates and a distal outcome of overall life satisfaction. We also include key references that direct readers to more detailed and technical discussions of these topics for which we provide an applied and introductory overview. We conclude by mentioning future developments in research and practice, including advanced cross-sectional and longitudinal extensions of LCA.},
	language = {en},
	number = {4},
	urldate = {2021-07-25},
	journal = {Translational Issues in Psychological Science},
	author = {Nylund-Gibson, Karen and Choi, Andrew Young},
	month = dec,
	year = {2018},
	pages = {440--461},
	annote = {Extracted Annotations (7/26/2021, 8:27:32 AM)"Classes may be thought of as unobserved "subgroups" or "typologies" that characterize heterogeneity in a population with respect to a given phenomenon." (Nylund-Gibson and Choi 2018:444)"think of LCA as a way to group similar people together, whereas factor analysis groups items." (Nylund-Gibson and Choi 2018:444)"LCA can be thought of as a "person-centered" approach to creating empirically-derived typologies, contrasting the dominant "variable-centered" tradition that generally requires arbitrary cutoffs for classifying or differentiating among individual cases (Nylund, Bellmore, Nishina, \& Graham, 2007)" (Nylund-Gibson and Choi 2018:444)"unlike other classification techniques such as cluster analysis or k-means clustering, LCA is model-based and permits a mathematical evaluation of how well a proposed LCA model represents the data" (Nylund-Gibson and Choi 2018:444)"Suppose there are M binary latent class indicators, u1, u2,..., uM observed on n individuals. The LCA model assumes that the M indicators are all reflective measures of an underlying unordered categorical latent class variable, c, that has K latent classes." (Nylund-Gibson and Choi 2018:444)"two parameters of interest in an LCA model without covariates (e.g., an unconditional LCA): the relative size of the latent" (Nylund-Gibson and Choi 2018:444)"LATENT CLASS ANALYSIS FREQUENTLY ASKED QUESTIONS 6 classes and the conditional item probabilities." (Nylund-Gibson and Choi 2018:445)"the relative size of each class, or the proportion of individuals in a given latent class k, P(c = k), is denoted by" (Nylund-Gibson and Choi 2018:445)"the K classes are mutually exclusive and exhaustive, meaning that each individual in the population has membership in exactly one of the K latent classes and" (Nylund-Gibson and Choi 2018:445)"The second key parameter in the LCA model, then, is the set of conditional item probability parameters, ." (Nylund-Gibson and Choi 2018:446)"similar to deciding on the number of factors to retain in an exploratory factor analysis. Class enumeration includes fitting several LCA models with differing numbers of latent classes, collecting and tabulating fit information for each fitted model, and studying patterns to decide on how many classes best describe the patterns observed in the data." (Nylund-Gibson and Choi 2018:447)"there is not a single fit index that is agreed upon for use in enumerating classes, but rather, we use a set of fit indices to decide" (Nylund-Gibson and Choi 2018:447)"the recommended procedure for exploring and deciding on the number of classes is to jointly consider statistical fit indices, substantive interpretability and utility, and classification diagnostics, which help to illuminate how well the classes are classifying and differentiating among the individuals considered (Masyn, 2013; B. O. Muthén, 2003)." (Nylund-Gibson and Choi 2018:447)"begin the modeling process by estimating a 1-class LCA model, which is a model that is simply estimating the observed indicator endorsement probability for the item set (the observed item proportions in the sample statistics). This 1-class model serves as a comparative baseline for models with more than one class. Then, we increase the number (k) of classes by one, examining whether the addition of each class results in conceptually and statistically superior solutions. We usually stop estimating additional classes when empirical under-identification (e.g., overparameterization) or convergence issues are encountered (which is generally indicated by error messages from the software being used). Once all the LCA models are fitted, we collect fit information from each one (e.g., copy/paste the information) and summarize them in a single table for ease of evaluation." (Nylund-Gibson and Choi 2018:447)"fit indices that are currently supported for use in deciding on the number of classes in LCA models (Masyn, 2013; Morgan, 2015; Morovati, 2014; Nylund, Asparouhov, \& Muthén, 2007; Yang, 2006). These fit indices have been examined in simulation studies and have been shown to generally work well in identifying the correct number of classes in an LCA" (Nylund-Gibson and Choi 2018:448)"First are information criteria (IC)—including the Bayesian Information Criterion (BIC), Sample-size adjusted Bayesian Information Criterion (SABIC), Consistent Akaike Information Criterion (CAIC), and Approximate Weight of Evidence Criterion (AWE)—which are approximate fit indices where lower values indicate superior fit" (Nylund-Gibson and Choi 2018:448)"t can be useful to plot the values of the BIC, ABIC, CAIC, and AWE" (Nylund-Gibson and Choi 2018:448)"it is not uncommon that the BIC continues to decrease for each additional class added (e.g., there is not a global minimum) and in these instances these plots can be particularly useful to inspect for an "elbow" of point of "diminishing returns" in model fit (e.g., small decreases in the IC for each additional latent class), akin to how one interprets a scree plot in exploratory factor analysis." (Nylund-Gibson and Choi 2018:448)"Second are the likelihood-based tests—the Vuong-Lo-Mendell-Rubin adjusted likelihood ratio test (VLMR-LRT) and the bootstrapped likelihood ratio test (BLRT)—which provide pvalues assessing whether adding a class leads to a statistically significant improvement in model fit. These likelihood-based tests compare the fit between two neighboring class models (e.g., a 2- class versus a 3-class model). A non-significant p-value for a k class solution thus lends support for the k - 1 class solution. See Nylund, Asparouhov, and colleagues (2007)" (Nylund-Gibson and Choi 2018:449)"t is not uncommon that the collection of fit information described here do not converge on one single model. It is more common that the fit indices support one or two candidate models. In this case, we recommend that fit for these candidate model be presented and that the solutions be studied closely (Masyn, 2013; B. O. Muthén, 2003; Ram \& Grimm, 2009)" (Nylund-Gibson and Choi 2018:449)"elative sizes of the emergent classes (e.g., are the emergent classes relatively large—say, having more than 5-8\% of the sample and a decent number of individuals in the class?). It has been shown through simulation studies of a variety of different types of mixture models (Depaoli, 2013; Morgan, 2015; Morovati, 2014; Tofighi \& Enders, 2008; Tueller \& Lubke, 2010) that small or "rare" classes are generally difficult to recover at small sample sizes and when class prevalences are highly unequal (e.g., the classes are not the same size). As such, we encourage researchers to be mindful as to avoid selecting an overextracted and potentially unstable class solution, especially when lacking a large enough sample size that may otherwise support the reliable detection of classes with low prevalences" (Nylund-Gibson and Choi 2018:450)"After a solution is selected and interpreted, there are several guidelines for evaluating how well the classes are differentiated (Masyn, 2013). First, entropy is an omnibus index where values {\textgreater} .80 indicate "good" classification of individual cases into classes (Clark \& Muthén, 2009). Second, average posterior probabilities (AvePP) provide information about how well a given model classifies individuals into their most likely class. Individuals' AvePP values are reported for their most likely class assigned, where values {\textgreater} .70 indicate well-separated classes (Nagin, 2005)" (Nylund-Gibson and Choi 2018:452)"class homogeneity reflects how similar people are to each other with respect to their item responses in each class, where conditional item probabilities {\textgreater} .70 and {\textless} .30 indicate high homogeneity. It can be useful to visually evaluate class homogeneity using the item probability plot" (Nylund-Gibson and Choi 2018:452)"class separation is how dissimilar people are across classes in their item responses, where odds ratios of item probabilities between two classes {\textgreater} 5 and {\textless} .20 indicate high separation. Notably, items may differentiate some classes well but not others. Researchers should thus consider holistically how well each item contributes to class separation for the overall model." (Nylund-Gibson and Choi 2018:452)"include covariates and distal outcomes into an LCA model?" (Nylund-Gibson and Choi 2018:454)"including an auxiliary variable can and may unintentionally influence the formation of the latent class variable, both in relative class size and type (Asparouhov \& Muthén, 2014; Nylund-Gibson, Grimm, Quirk, \& Furlong, 2014; Vermunt, 2010)" (Nylund-Gibson and Choi 2018:455)"Recent simulation studies have recommended that we enumerate classes prior to estimating auxiliary variable relations (Nylund-Gibson \& Masyn, 2016)." (Nylund-Gibson and Choi 2018:455)"we focus on the current best practice, which is to use either the three-step (Vermunt, 2010) or Bolck, Croons, \& Hagenaars (BCH) method (Asparouhov \& Muthén, 2014; Bolck, Croon, \& Hagenaars, 2004; Vermunt, 2010)." (Nylund-Gibson and Choi 2018:455)"required sample size fo r LCA?" (Nylund-Gibson and Choi 2018:457)"N ≈ 300-1000 is roughly the range in which most commonly used fit indices for mixture models can be expected to function adequately (Morgan, 2015; Morovati, 2014; Nylund, Asparouhov, et al., 2007; Tein, Coxe, \& Cham, 2013; Tofighi \& Enders, 2008; Yang, 2006)." (Nylund-Gibson and Choi 2018:457)"Researchers often have a substantive interest in rare classes but, as aforementioned, these cannot be detected without a sufficient overall sample size to estimate classes with low relative prevalences (say, 1-8\%), especially if a large number of indicators have been included and many class-specific parameters are freely estimated (Masyn, 2013)" (Nylund-Gibson and Choi 2018:458)"the likelihood of accurately recovering the correct number of mixture classes depends heavily on class separation (Depaoli, 2013; Lubke \& Muthén, 2007; Lubke \& Neale, 2006; Tein et al., 2013; Tofighi \& Enders, 2008; Tueller \& Lubke, 2010). Adding well-separating items to an LCA has been shown to improve correct latent class recovery and to help mitigate the destabilizing effects of small sample size (Wurpts \& Geiser, 2014)" (Nylund-Gibson and Choi 2018:458)"If we have "good" items that separate classes well, then we do not need as many items (Collins \& Wugalter, 1992)" (Nylund-Gibson and Choi 2018:459)"n most software packages used to estimate mixture models, the LCA model parameters are estimated by maximum likelihood (ML) using the expectation-maximization (EM) procedure. ML estimates have many features that make them desirable and thus are the preferred estimation method. Related to the point estimates is the issue of confidence in a solution. For ML estimation, item-level missingness is easily accommodated and assumed missing at random (MAR). That is, individual cases are not excluded from the analysis unless they are missing data on all the observed items." (Nylund-Gibson and Choi 2018:460)"For mixture models, there is a known sensitivity of the likelihood function to converge on a local, instead of a global, solution (McLachlan \& Peel, 2000). To circumvent this problem, the suggestion is to use a set of random start values, estimate the model many times, and see if across the set of random start values, there is convergence on a similar solution (Berlin, Williams, \& Parra, 2014; Masyn, 2013)." (Nylund-Gibson and Choi 2018:460)"Although LCA is generally used as an exploratory technique, it can be applied in a confirmatory" (Nylund-Gibson and Choi 2018:464)"LATENT CLASS ANALYSIS FREQUENTLY ASKED QUESTIONS 26 manner, for instance to test for the equivalence of latent class solutions across known groupings akin to measurement invariance in factor analysis (Finch \& Bronk, 2011; Laudy et al., 2005; Morin, Meyer, Creusier, \& Biétry, 2016)." (Nylund-Gibson and Choi 2018:465)},
	file = {Nylund-Gibson_Choi_2018_Ten frequently asked questions about latent class analysis.pdf:C\:\\Users\\danie\\Zotero\\storage\\U93E6H2K\\Nylund-Gibson_Choi_2018_Ten frequently asked questions about latent class analysis.pdf:application/pdf},
}

@article{little_test_1988,
	title = {A {Test} of {Missing} {Completely} at {Random} for {Multivariate} {Data} with {Missing} {Values}},
	volume = {83},
	issn = {01621459},
	doi = {10.2307/2290157},
	abstract = {A common concern when faced with multivariate data with missing values is whether the missing data are missing completely at random (MCAR); that is, whether missingness depends on the variables in the data set. One way of assessing this is to compare the means of recorded values of each variable between groups defined by whether other variables in the data set are missing or not. Although informative, this procedure yields potentially many correlated statistics for testing MCAR, resulting in multiple-comparison problems. This article proposes a single global test statistic for MCAR that uses all of the available data. The asymptotic null distribution is given, and the small-sample null distribution is derived for multivariate normal data with a monotone pattern of missing data. The test reduces to a standard t test when the data are bivariate with missing data confined to a single variable. A limited simulation study of empirical sizes for the test applied to normal and nonnormal data suggests that the test is conservative for small samples.},
	number = {404},
	journal = {Journal of the American Statistical Association},
	author = {Little, Roderick J. A.},
	year = {1988},
	pages = {pp. 1198--1202},
}

@article{van_de_schoot_grolts-checklist_2017,
	title = {The {GRoLTS}-{Checklist}: {Guidelines} for {Reporting} on {Latent} {Trajectory} {Studies}},
	volume = {24},
	issn = {1070-5511},
	shorttitle = {The {GRoLTS}-{Checklist}},
	url = {https://doi.org/10.1080/10705511.2016.1247646},
	doi = {10.1080/10705511.2016.1247646},
	abstract = {Estimating models within the mixture model framework, like latent growth mixture modeling (LGMM) or latent class growth analysis (LCGA), involves making various decisions throughout the estimation process. This has led to a wide variety in how results of latent trajectory analysis are reported. To overcome this issue, using a 4-round Delphi study, we developed Guidelines for Reporting on Latent Trajectory Studies (GRoLTS). The purpose of GRoLTS is to present criteria that should be included when reporting the results of latent trajectory analysis across research fields. We have gone through a systematic process to identify key components that, according to a panel of experts, are necessary when reporting results for trajectory studies. We applied GRoLTS to 38 papers where LGMM or LCGA was used to study trajectories of posttraumatic stress after a traumatic event.},
	number = {3},
	urldate = {2021-07-25},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Van De Schoot, Rens and Sijbrandij, Marit and Winter, Sonja D. and Depaoli, Sarah and Vermunt, Jeroen K.},
	month = may,
	year = {2017},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10705511.2016.1247646},
	keywords = {latent classes, LCGA, LGMM, mixture modeling, SEM},
	pages = {451--467},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\AIENK6LB\\10705511.2016.html:text/html;Van De Schoot et al_2017_The GRoLTS-Checklist.pdf:C\:\\Users\\danie\\Zotero\\storage\\A78JVFLD\\Van De Schoot et al_2017_The GRoLTS-Checklist.pdf:application/pdf},
}

@article{jamshidian_tests_2010,
	title = {Tests of {Homoscedasticity}, {Normality}, and {Missing} {Completely} at {Random} for {Incomplete} {Multivariate} {Data}},
	volume = {75},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/article/10.1007/s11336-010-9175-3},
	doi = {10.1007/s11336-010-9175-3},
	abstract = {Test of homogeneity of covariances (or homoscedasticity) among several groups has many applications in statistical analysis. In the context of incomplete data analysis, tests of homoscedasticity among groups of cases with identical missing data patterns have been proposed to test whether data are missing completely at random (MCAR). These tests of MCAR require large sample sizes n and/or large group sample sizes ni, and they usually fail when applied to nonnormal data. Hawkins (Technometrics 23:105–110, 1981) proposed a test of multivariate normality and homoscedasticity that is an exact test for complete data when ni are small. This paper proposes a modification of this test for complete data to improve its performance, and extends its application to test of homoscedasticity and MCAR when data are multivariate normal and incomplete. Moreover, it is shown that the statistic used in the Hawkins test in conjunction with a nonparametric k-sample test can be used to obtain a nonparametric test of homoscedasticity that works well for both normal and nonnormal data. It is explained how a combination of the proposed normal-theory Hawkins test and the nonparametric test can be employed to test for homoscedasticity, MCAR, and multivariate normality. Simulation studies show that the newly proposed tests generally outperform their existing competitors in terms of Type I error rejection rates. Also, a power study of the proposed tests indicates good power. The proposed methods use appropriate missing data imputations to impute missing data. Methods of multiple imputation are described and one of the methods is employed to confirm the result of our single imputation methods. Examples are provided where multiple imputation enables one to identify a group or groups whose covariance matrices differ from the majority of other groups.},
	language = {en},
	number = {4},
	urldate = {2016-08-18},
	journal = {Psychometrika},
	author = {Jamshidian, Mortaza and Jalal, Siavash},
	month = aug,
	year = {2010},
	pages = {649--674},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\BMYLXS4G\\s11336-010-9175-3.html:text/html},
}

@article{weller_latent_2020,
	title = {Latent {Class} {Analysis}: {A} {Guide} to {Best} {Practice}},
	volume = {46},
	issn = {0095-7984},
	shorttitle = {Latent {Class} {Analysis}},
	url = {https://doi.org/10.1177/0095798420930932},
	doi = {10.1177/0095798420930932},
	abstract = {Latent class analysis (LCA) is a statistical procedure used to identify qualitatively different subgroups within populations who often share certain outward characteristics. The assumption underlying LCA is that membership in unobserved groups (or classes) can be explained by patterns of scores across survey questions, assessment indicators, or scales. The application of LCA is an active area of research and continues to evolve. As more researchers begin to apply the approach, detailed information on key considerations in conducting LCA is needed. In the present article, we describe LCA, review key elements to consider when conducting LCA, and provide an example of its application.},
	language = {en},
	number = {4},
	urldate = {2022-05-17},
	journal = {Journal of Black Psychology},
	author = {Weller, Bridget E. and Bowen, Natasha K. and Faubert, Sarah J.},
	month = may,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	keywords = {ADHD, behavior problems, latent class analysis, National Survey of Children’s Health, social determinants of health},
	pages = {287--311},
	file = {SAGE PDF Full Text:C\:\\Users\\danie\\Zotero\\storage\\NHXJHDMN\\Weller et al. - 2020 - Latent Class Analysis A Guide to Best Practice.pdf:application/pdf},
}

@book{hagenaars_applied_2002,
	title = {Applied {Latent} {Class} {Analysis}},
	isbn = {978-1-139-43923-7},
	abstract = {Applied Latent Class Analysis introduces several innovations in latent class analysis to a wider audience of researchers. Many of the world's leading innovators in the field of latent class analysis contributed essays to this volume, each presenting a key innovation to the basic latent class model and illustrating how it can prove useful in situations typically encountered in actual research.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Hagenaars, Jacques A. and McCutcheon, Allan L.},
	month = jun,
	year = {2002},
	keywords = {Mathematics / General, Social Science / Demography, Social Science / Research},
	file = {Hagenaars and McCutcheon - 2002 - Applied Latent Class Analysis.pdf:C\:\\Users\\danie\\Zotero\\storage\\BBAZIEIW\\Hagenaars and McCutcheon - 2002 - Applied Latent Class Analysis.pdf:application/pdf},
}

@book{mclachlan_finite_2004,
	title = {Finite {Mixture} {Models}},
	isbn = {978-0-471-65406-3},
	abstract = {An up-to-date, comprehensive account of major issues in finite mixture modeling This volume provides an up-to-date account of the theory and applications of modeling via finite mixture distributions. With an emphasis on the applications of mixture models in both mainstream analysis and other areas such as unsupervised pattern recognition, speech recognition, and medical imaging, the book describes the formulations of the finite mixture approach, details its methodology, discusses aspects of its implementation, and illustrates its application in many common statistical contexts. Major issues discussed in this book include identifiability problems, actual fitting of finite mixtures through use of the EM algorithm, properties of the maximum likelihood estimators so obtained, assessment of the number of components to be used in the mixture, and the applicability of asymptotic theory in providing a basis for the solutions to some of these problems. The author also considers how the EM algorithm can be scaled to handle the fitting of mixture models to very large databases, as in data mining applications. This comprehensive, practical guide: * Provides more than 800 references-40\% published since 1995 * Includes an appendix listing available mixture software * Links statistical literature with machine learning and pattern recognition literature * Contains more than 100 helpful graphs, charts, and tables Finite Mixture Models is an important resource for both applied and theoretical statisticians as well as for researchers in the many areas in which finite mixture models can be used to analyze data.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {McLachlan, Geoffrey J. and Peel, David},
	month = mar,
	year = {2004},
	note = {Google-Books-ID: c2\_fAox0DQoC},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
	file = {McLachlan and Peel - 2004 - Finite Mixture Models.pdf:C\:\\Users\\danie\\Zotero\\storage\\YEAFQRBB\\McLachlan and Peel - 2004 - Finite Mixture Models.pdf:application/pdf},
}

@book{geiser_data_2012,
	title = {Data {Analysis} with {Mplus}},
	isbn = {978-1-4625-0245-5},
	abstract = {A practical introduction to using Mplus for the analysis of multivariate data, this volume provides step-by-step guidance, complete with real data examples, numerous screen shots, and output excerpts. The author shows how to prepare a data set for import in Mplus using SPSS. He explains how to specify different types of models in Mplus syntax and address typical caveats--for example, assessing measurement invariance in longitudinal SEMs. Coverage includes path and factor analytic models as well as mediational, longitudinal, multilevel, and latent class models. Specific programming tips and solution strategies are presented in boxes in each chapter. The companion website (http://crmda.ku.edu/guilford/geiser) features data sets, annotated syntax files, and output for all of the examples. Of special utility to instructors and students, many of the examples can be run with the free demo version of Mplus.},
	language = {en},
	publisher = {Guilford Press},
	author = {Geiser, Christian},
	month = nov,
	year = {2012},
	note = {Google-Books-ID: d2VLVhEQ7IMC},
	keywords = {Business \& Economics / Statistics, Computers / Databases / General, Computers / Mathematical \& Statistical Software, Education / Statistics, Mathematics / Probability \& Statistics / Multivariate Analysis, Medical / Nursing / General, Psychology / Statistics, Social Science / Statistics},
	file = {Geiser - 2012 - Data Analysis with Mplus.pdf:C\:\\Users\\danie\\Zotero\\storage\\CJ7CX54J\\Geiser - 2012 - Data Analysis with Mplus.pdf:application/pdf},
}

@article{killian_systematic_2019,
	title = {A {Systematic} {Review} of {Latent} {Variable} {Mixture} {Modeling} {Research} in {Social} {Work} {Journals}},
	volume = {16},
	issn = {2640-8066},
	url = {https://doi.org/10.1080/23761407.2019.1577783},
	doi = {10.1080/23761407.2019.1577783},
	abstract = {Purpose: Latent variable mixture modeling (LVMM) estimates possible classes, profiles, or trajectories within a sample and then identifies individuals with similar patterns. This systematic review examines the use of person-centered LVMM analyses published in social work journals.Methods: We screened 478 articles and obtained a final sample of 32 studies meeting inclusion criteria.Results: Studies using LVMM were published between 2004 and 2017 with a majority appearing after 2012. Latent class analysis was used in most studies followed by latent profile analysis and longitudinal variants of LVMM. Samples sizes ranged from 199 to 1,002,122 (median = 533). Less than half of the identified studies met model fit reporting standards.Discussion: This systematic review demonstrates the usefulness and growing popularity of LVMM studies within social work journals. Social Work researchers are encouraged to employ person-centered methods to explore unobserved groups or trajectories within cross-sectional and longitudinal data.},
	number = {2},
	urldate = {2022-06-19},
	journal = {Journal of Evidence-Based Social Work},
	author = {Killian, Michael O. and Cimino, Andrea N. and Weller, Bridget E. and Hyun Seo, Chang},
	month = mar,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/23761407.2019.1577783},
	keywords = {Latent class analysis, latent variable mixture modeling, systematic review},
	pages = {192--210},
	file = {Killian et al. - 2019 - A Systematic Review of Latent Variable Mixture Mod.pdf:C\:\\Users\\danie\\Zotero\\storage\\RBXE7DHQ\\Killian et al. - 2019 - A Systematic Review of Latent Variable Mixture Mod.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\5RJG5KN6\\23761407.2019.html:text/html},
}

@article{petersen_application_2019,
	title = {The {Application} of {Latent} {Class} {Analysis} for {Investigating} {Population} {Child} {Mental} {Health}: {A} {Systematic} {Review}},
	volume = {10},
	issn = {1664-1078},
	shorttitle = {The {Application} of {Latent} {Class} {Analysis} for {Investigating} {Population} {Child} {Mental} {Health}},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.01214},
	abstract = {Background: Latent class analysis (LCA) can be used to identify subgroups of children with similar patterns of mental health symptoms and/or strengths. The method is becoming more commonly used in child mental health research, but there are reservations about the replicability, reliability, and validity of findings.Objective: A systematic literature review was conducted to investigate the extent to which LCA has been used to study population mental health in children, and whether replicable, reliable and valid findings have been demonstrated.Methods: Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines were followed. A search of literature, published between January 1998 and December 2017, was carried out using MEDLINE, EMBASE, PsycInfo, Scopus, ERIC, ASSIA, and Google Scholar. A total of 2,748 studies were initially identified, of which 23 were eligible for review. The review examined the methods which studies had used to choose the number of mental health classes, the classes that they found, and whether there was evidence for the validity and reliability of the classes.Results: Reviewed studies used LCA to investigate both disparate mental health symptoms, and those associated with specific disorders. The corpus of studies using similar indicators was small. Differences in the criteria used to select the final LCA model were found between studies. All studies found meaningful or useful subgroups, but there were differences in the extent to which the validity and reliability of classes were explicitly demonstrated.Conclusions : LCA is a useful tool for studying and classifying child mental health at the population level. Recommendations are made to improve the application and reporting of LCA and to increase confidence in findings in the future, including use of a range of indices and criteria when enumerating classes, clear reporting of methods for replicability, and making efforts to establish the validity and reliability of identified classes.},
	urldate = {2022-06-19},
	journal = {Frontiers in Psychology},
	author = {Petersen, Kimberly J. and Qualter, Pamela and Humphrey, Neil},
	year = {2019},
	file = {Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\TT2BHNW3\\Petersen et al. - 2019 - The Application of Latent Class Analysis for Inves.pdf:application/pdf},
}

@article{ulbricht_use_2018,
	title = {The use of latent class analysis for identifying subtypes of depression: {A} systematic review},
	volume = {266},
	shorttitle = {The use of latent class analysis for identifying subtypes of depression},
	journal = {Psychiatry Res},
	author = {Ulbricht, C. M. and Chrysanthopoulou, S. A. and Levin, L. and Lapane, K. L.},
	year = {2018},
	pages = {228--246},
	file = {The use of latent class analysis for identifying subtypes of depression\: A systematic review | Len Levin, MS LIS, MA, AHIP:C\:\\Users\\danie\\Zotero\\storage\\MVH6PWNL\\use-latent-class-analysis-identifying-subtypes-depression-systematic-review.html:text/html;Ulbricht et al. - 2018 - The use of latent class analysis for identifying s.pdf:C\:\\Users\\danie\\Zotero\\storage\\HWHN7YW7\\Ulbricht et al. - 2018 - The use of latent class analysis for identifying s.pdf:application/pdf},
}

@book{little_oxford_2013,
	title = {The {Oxford} {Handbook} of {Quantitative} {Methods} in {Psychology}: {Vol}. 2: {Statistical} {Analysis}},
	isbn = {978-0-19-993489-8},
	shorttitle = {The {Oxford} {Handbook} of {Quantitative} {Methods} in {Psychology}},
	abstract = {Research today demands the application of sophisticated and powerful research tools. Fulfilling this need, The Oxford Handbook of Quantitative Methods in Psychology is the complete tool box to deliver the most valid and generalizable answers to today's complex research questions. It is a one-stop source for learning and reviewing current best-practices in quantitative methods as practiced in the social, behavioral, and educational sciences. Comprising two volumes, this handbook covers a wealth of topics related to quantitative research methods. It begins with essential philosophical and ethical issues related to science and quantitative research. It then addresses core measurement topics before delving into the design of studies. Principal issues related to modern estimation and mathematical modeling are also detailed. Topics in the handbook then segway into the realm of statistical inference and modeling with chapters dedicated to classical approaches as well as modern latent variable approaches. Numerous chapters associated with longitudinal data and more specialized techniques round out this broad selection of topics. Comprehensive, authoritative, and user-friendly, this two-volume set will be an indispensable resource for serious researchers across the social, behavioral, and educational sciences.},
	language = {en},
	publisher = {OUP USA},
	author = {Little, Todd D.},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: \_ulgdl4BPH0C},
	keywords = {Psychology / General, Psychology / Social Psychology, Medical / Psychiatry / General, Psychology / Research \& Methodology},
	annote = {Chapter 25 Latent Class Analysis
},
	file = {Little - 2013 - The Oxford Handbook of Quantitative Methods in Psy.pdf:C\:\\Users\\danie\\Zotero\\storage\\2ST8KXKI\\Little - 2013 - The Oxford Handbook of Quantitative Methods in Psy.pdf:application/pdf},
}

@incollection{masyn_latent_2013,
	title = {Latent {Class} {Analysis} and {Finite} {Mixture} {Modeling}},
	volume = {2: Statistical Analysis},
	abstract = {Finite mixture models, which are a type of latent variable model, express the overall distribution of
one or more variables as a mixture of a finite number of component distributions. In direct
applications, one assumes that the overall population heterogeneity with respect to a set of manifest
variables results from the existence of two or more distinct homogeneous subgroups, or latent
classes, of individuals. This chapter presents the prevailing “best practices” for direct applications of
basic finite mixture modeling, specifically latent class analysis (LCA) and latent profile analysis (LPA), in
terms of model assumptions, specification, estimation, evaluation, selection, and interpretation. In
addition, a brief introduction to structural equation mixture modeling in the form of latent class
regression is provided as well as a partial overview of the many more advanced mixture models
currently in use. The chapter closes with a cautionary note about the limitations and common misuses
of latent class models and a look toward promising future developments in mixture modeling.},
	language = {en},
	booktitle = {The {Oxford} {Handbook} of {Quantitative} {Methods}},
	publisher = {Oxford University Press},
	author = {Masyn, Katherine E.},
	year = {2013},
	pages = {551},
	file = {Masyn - 2013 - Latent Class Analysis and Finite Mixture Modeling.pdf:C\:\\Users\\danie\\Zotero\\storage\\28JAQ4M7\\Masyn - 2013 - Latent Class Analysis and Finite Mixture Modeling.pdf:application/pdf},
}

@article{chung_difficulties_2004,
	title = {Difficulties in {Drawing} {Inferences} {With} {Finite}-{Mixture} {Models}},
	volume = {58},
	issn = {0003-1305},
	url = {https://doi.org/10.1198/0003130043286},
	doi = {10.1198/0003130043286},
	abstract = {Likelihood functions from finite mixture models have many unusual features. Maximum likelihood (ML) estimates may behave poorly over repeated samples, and the abnormal shape of the likelihood often makes it difficult to assess the uncertainty in parameter estimates. Bayesian inference via Markov chain Monte Carlo (MCMC) can be a useful alternative to ML, but the component labels may switch during the MCMC run, making the output difficult to interpret. Two basic methods for handling the label-switching problem have been proposed: imposing constraints on the parameter space and cluster-based relabeling of the simulated parameters. We have found that label switching may also be reduced by supplying small amounts of prior information that are asymmetric with respect to the mixture components. Simply assigning one observation to each component a priori may effectively eliminate the problem. Using a very simple example—a univariate sample from a mixture of two exponentials—we evaluate the performance of likelihood and MCMC-based estimates and intervals over repeated sampling. Our simulations show that MCMC performs much better than ML if the label-switching problem is adequately addressed, and that asymmetric prior information performs as well as or better than the other proposed methods.},
	number = {2},
	urldate = {2022-07-02},
	journal = {The American Statistician},
	author = {Chung, Hwan and Loken, Eric and Schafer, Joseph L},
	month = may,
	year = {2004},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/0003130043286},
	keywords = {EM algorithm, Label switching, Markov chain Monte Carlo},
	pages = {152--158},
	file = {Chung et al. - 2004 - Difficulties in Drawing Inferences With Finite-Mix.pdf:C\:\\Users\\danie\\Zotero\\storage\\GQ4AM9QJ\\Chung et al. - 2004 - Difficulties in Drawing Inferences With Finite-Mix.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\8HXMTFCX\\0003130043286.html:text/html},
}

@incollection{lanza_introduction_2003,
	edition = {2},
	title = {An {Introduction} to {Latent} {Class} and {Latent} {Transition} {Analysis}},
	volume = {2},
	booktitle = {Handbook of {Psychology}: {Research} {Methods} in {Psychology}},
	publisher = {John Wiley \& Sons},
	author = {Lanza, Stephanie T. and Bray, Bethany C. and Collins, Linda M.},
	year = {2003},
	pages = {690--712},
	file = {Lanza et al. - An Introduction to Latent Class and Latent Transit.pdf:C\:\\Users\\danie\\Zotero\\storage\\J6326NUP\\Lanza et al. - An Introduction to Latent Class and Latent Transit.pdf:application/pdf},
}

@article{foster_open_2017,
	title = {Open {Science} {Framework} ({OSF})},
	volume = {105},
	issn = {1536-5050},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	doi = {10.5195/jmla.2017.88},
	number = {2},
	urldate = {2022-07-24},
	journal = {Journal of the Medical Library Association : JMLA},
	author = {Foster, Erin D. and Deardorff, Ariel},
	month = apr,
	year = {2017},
	pmid = {null},
	pmcid = {PMC5370619},
	pages = {203--206},
	file = {Full Text:C\:\\Users\\danie\\Zotero\\storage\\UD3DETS5\\Foster and Deardorff - 2017 - Open Science Framework (OSF).pdf:application/pdf},
}

@article{spurk_latent_2020,
	title = {Latent profile analysis: {A} review and “how to” guide of its application within vocational behavior research},
	volume = {120},
	issn = {0001-8791},
	shorttitle = {Latent profile analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0001879120300701},
	doi = {10.1016/j.jvb.2020.103445},
	abstract = {Latent profile analysis (LPA) is a categorical latent variable approach that focuses on identifying latent subpopulations within a population based on a certain set of variables. LPA thus assumes that people can be typed with varying degrees of probabilities into categories that have different configural profiles of personal and/or environmental attributes. Within this article, we (a) review the existing applications of LPA within past vocational behavior research; (b) illustrate best practice procedures in a non-technical way of how to use LPA methodology, with an illustrative example of identifying different latent profiles of heavy work investment (i.e., working compulsively, working excessively, and work engagement); and (c) outline future research possibilities in vocational behavior research. By reviewing 46 studies stemming from central journals of the field, we identified seven distinct topics that have already been investigated by LPA (e.g., job and organizational attitudes and behaviors, work motivation, career-related attitudes and orientations, vocational interests). Together with showing descriptive statistics about how LPA has been conducted in past vocational behavior research, we illustrate and derive best-practice recommendations for future LPA research. The review and “how to” guide can be helpful for all researchers interested in conducting LPA studies.},
	language = {en},
	urldate = {2022-07-25},
	journal = {Journal of Vocational Behavior},
	author = {Spurk, Daniel and Hirschi, Andreas and Wang, Mo and Valero, Domingo and Kauffeld, Simone},
	month = aug,
	year = {2020},
	keywords = {Bestpractice, Categorical latent variable model, Factor mixture models, Heavy work investment, Latent profile analysis, Person-centered methods, Review, Work engagement, Working compulsively, Working excessively},
	pages = {103445},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\5WX5MJD6\\Spurk et al. - 2020 - Latent profile analysis A review and “how to” gui.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\danie\\Zotero\\storage\\BWV97HYG\\S0001879120300701.html:text/html},
}

@article{van_lissa_worcs_2021,
	title = {{WORCS}: {A} workflow for open reproducible code in science},
	volume = {4},
	issn = {2451-8484},
	shorttitle = {{WORCS}},
	url = {https://content.iospress.com/articles/data-science/ds210031},
	doi = {10.3233/DS-210031},
	abstract = {Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can},
	language = {en},
	number = {1},
	urldate = {2022-07-28},
	journal = {Data Science},
	author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara M. I.},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {29--49},
	file = {Full Text PDF:C\:\\Users\\danie\\Zotero\\storage\\CTKPR7IM\\Van Lissa et al. - 2021 - WORCS A workflow for open reproducible code in sc.pdf:application/pdf;Snapshot:C\:\\Users\\danie\\Zotero\\storage\\MFFHKNXL\\ds210031.html:text/html},
}

@misc{bauer_whats_2021,
	title = {What’s the best way to determine the number of latent classes in a finite mixture analysis?},
	url = {https://centerstat.org/class-enumeration/},
	abstract = {Selecting the number of classes (or components) is one of the most challenging decisions to make when fitting a finite mixture model (including latent class analysis and latent profile analysis). In this post, we talk through the conventional wisdom on class enumeration, as well as when this breaks down.},
	language = {en-US},
	urldate = {2022-08-16},
	journal = {CenterStat},
	author = {Bauer, Dan and Curran, Patrick},
	month = nov,
	year = {2021},
	file = {Snapshot:C\:\\Users\\danie\\Zotero\\storage\\XLY2YZHI\\class-enumeration.html:text/html},
}
