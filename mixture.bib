
@article{akogulComparisonInformationCriteria2016,
  title = {A {{Comparison}} of {{Information Criteria}} in {{Clustering Based}} on {{Mixture}} of {{Multivariate Normal Distributions}}},
  author = {Akogul, Serkan and Erisoglu, Murat},
  year = {2016},
  month = sep,
  journal = {Mathematical and Computational Applications},
  volume = {21},
  number = {3},
  pages = {34},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/mca21030034},
  abstract = {Clustering analysis based on a mixture of multivariate normal distributions is commonly used in the clustering of multidimensional data sets. Model selection is one of the most important problems in mixture cluster analysis based on the mixture of multivariate normal distributions. Model selection involves the determination of the number of components (clusters) and the selection of an appropriate covariance structure in the mixture cluster analysis. In this study, the efficiency of information criteria that are commonly used in model selection is examined. The effectiveness of information criteria has been determined according to the success in the selection of the number of components and in the selection of an appropriate covariance matrix.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cluster analysis,information criteria,mixture models},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\WKX9F323\\Akogul_Erisoglu_2016_A Comparison of Information Criteria in Clustering Based on Mixture of.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\6JKUC3QF\\htm.html}
}

@article{baughmanMixtureModelAnalysis2006,
  title = {Mixture Model Analysis for Establishing a Diagnostic Cut-off Point for Pertussis Antibody Levels},
  author = {Baughman, Andrew L. and Bisgard, Kristine M. and Lynn, Freyja and Meade, Bruce D.},
  year = {2006},
  journal = {Statistics in Medicine},
  volume = {25},
  number = {17},
  pages = {2994--3010},
  issn = {1097-0258},
  doi = {10.1002/sim.2442},
  abstract = {Previous studies of pertussis (whooping cough) that have derived diagnostic cut-off points for pertussis antibody levels have assumed a single distribution for antibody levels and have used small sample sizes. In a recent study of 5409 serum samples from the Third National Health and Nutrition Examination Survey (NHANES III), a finite mixture model was developed to examine the distribution of immunoglobulin G (IgG) antibody levels against pertussis toxin (PT), an antigen specific to the Bordetella pertussis bacterium. The mixture model identified three component populations with antibody levels greater than the quantitative assay's lower limit of quantitation (LLQ) and included a point distribution located at or below the LLQ to account for the excess number of antibody values that fell below the LLQ. The mixture model analysis accounted for the NHANES III design. A cut-off point for anti-PT IgG levels was chosen to have a 99 per cent model specificity based on the two overlapping normal distributions assumed for the two component populations with the highest antibody levels. This cut-off point may have a higher diagnostic sensitivity for acute B. pertussis infection than other cut-off points derived by assuming a single distribution for antibody levels. Published in 2005 by John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {antibodies,diagnostic cut-off point,mixture model,pertussis,Third National Health and Nutrition Examination Survey},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2442},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\8C4JF3FR\\Baughman et al_2006_Mixture model analysis for establishing a diagnostic cut-off point for.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\8BEQWSGI\\sim.html}
}

@article{biernackiChoosingStartingValues2003,
  title = {Choosing Starting Values for the {{EM}} Algorithm for Getting the Highest Likelihood in Multivariate {{Gaussian}} Mixture Models},
  author = {Biernacki, Christophe and Celeux, Gilles and Govaert, G{\'e}rard},
  year = {2003},
  month = jan,
  journal = {Computational Statistics \& Data Analysis},
  series = {Recent {{Developments}} in {{Mixture Model}}},
  volume = {41},
  number = {3},
  pages = {561--575},
  issn = {0167-9473},
  doi = {10.1016/S0167-9473(02)00163-9},
  abstract = {Simple methods to choose sensible starting values for the EM algorithm to get maximum likelihood parameter estimation in mixture models are compared. They are based on random initialization, using a classification EM algorithm (CEM), a Stochastic EM algorithm (SEM) or previous short runs of EM itself. Those initializations are included in a search/run/select strategy which can be compounded by repeating the three steps. They are compared in the context of multivariate Gaussian mixtures on the basis of numerical experiments on both simulated and real data sets in a target number of iterations. The main conclusions of those numerical experiments are the following. The simple random initialization which is probably the most employed way of initiating EM is often outperformed by strategies using CEM, SEM or shorts runs of EM before running EM. Also, it appears that compounding is generally profitable since using a single run of EM can often lead to suboptimal solutions. Otherwise, none of the experimental strategies can be regarded as the best one and it is difficult to characterize situations where a particular strategy can be expected to outperform the other ones. However, the strategy initiating EM with short runs of EM can be recommended. This strategy, which as far as we know was not used before the present study, has some advantages. It is simple, performs well in a lot of situations presupposing no particular form of the mixture to be fitted to the data and seems little sensitive to noisy data.},
  langid = {english},
  keywords = {Classification EM,EM algorithm,Initialization strategies,Multivariate Gaussian mixture,Optimization,Stochastic EM},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\YNJBEZNR\\S0167947302001639.html}
}

@article{bokerOpenMxOpenSource2011,
  title = {{{OpenMx}}: {{An Open Source Extended Structural Equation Modeling Framework}}},
  shorttitle = {{{OpenMx}}},
  author = {Boker, Steven and Neale, Michael and Maes, Hermine and Wilde, Michael and Spiegel, Michael and Brick, Timothy and Spies, Jeffrey and Estabrook, Ryne and Kenny, Sarah and Bates, Timothy and Mehta, Paras and Fox, John},
  year = {2011},
  month = apr,
  journal = {Psychometrika},
  volume = {76},
  number = {2},
  pages = {306--317},
  issn = {0033-3123},
  doi = {10.1007/s11336-010-9200-6},
  abstract = {OpenMx is free, full\textendash featured, open source, structural equation modeling (SEM) software. OpenMx runs within the R statistical programming environment on Windows, Mac OS\textendash X, and Linux computers. The rationale for developing OpenMx is discussed along with the philosophy behind the user interface. The OpenMx data structures are introduced \textemdash{} these novel structures define the user interface framework and provide new opportunities for model specification. Two short example scripts for the specification and fitting of a confirmatory factor model are next presented. We end with an abbreviated list of modeling applications available in OpenMx 1.0 and a discussion of directions for future development.},
  pmcid = {PMC3525063},
  pmid = {23258944},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\JPIYUQMB\\Boker et al_2011_OpenMx.pdf}
}

@article{chungDifficultiesDrawingInferences2004,
  title = {Difficulties in {{Drawing Inferences With Finite-Mixture Models}}},
  author = {Chung, Hwan and Loken, Eric and Schafer, Joseph L},
  year = {2004},
  month = may,
  journal = {The American Statistician},
  volume = {58},
  number = {2},
  pages = {152--158},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1198/0003130043286},
  abstract = {Likelihood functions from finite mixture models have many unusual features. Maximum likelihood (ML) estimates may behave poorly over repeated samples, and the abnormal shape of the likelihood often makes it difficult to assess the uncertainty in parameter estimates. Bayesian inference via Markov chain Monte Carlo (MCMC) can be a useful alternative to ML, but the component labels may switch during the MCMC run, making the output difficult to interpret. Two basic methods for handling the label-switching problem have been proposed: imposing constraints on the parameter space and cluster-based relabeling of the simulated parameters. We have found that label switching may also be reduced by supplying small amounts of prior information that are asymmetric with respect to the mixture components. Simply assigning one observation to each component a priori may effectively eliminate the problem. Using a very simple example\textemdash a univariate sample from a mixture of two exponentials\textemdash we evaluate the performance of likelihood and MCMC-based estimates and intervals over repeated sampling. Our simulations show that MCMC performs much better than ML if the label-switching problem is adequately addressed, and that asymmetric prior information performs as well as or better than the other proposed methods.},
  keywords = {EM algorithm,Label switching,Markov chain Monte Carlo},
  annotation = {\_eprint: https://doi.org/10.1198/0003130043286},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\GQ4AM9QJ\\Chung et al. - 2004 - Difficulties in Drawing Inferences With Finite-Mix.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\8HXMTFCX\\0003130043286.html}
}

@article{figueiredoUnsupervisedLearningFinite2002,
  title = {Unsupervised Learning of Finite Mixture Models},
  author = {Figueiredo, M.A.T. and Jain, A.K.},
  year = {2002},
  month = mar,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {3},
  pages = {381--396},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/34.990138},
  abstract = {\DH This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective \textordfeminine unsupervised\textordmasculine{} is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\WH7EXMDQ\\Figueiredo_Jain_2002_Unsupervised learning of finite mixture models.pdf}
}

@article{fosterOpenScienceFramework2017,
  title = {Open {{Science Framework}} ({{OSF}})},
  author = {Foster, Erin D. and Deardorff, Ariel},
  year = {2017},
  month = apr,
  journal = {Journal of the Medical Library Association : JMLA},
  volume = {105},
  number = {2},
  pages = {203--206},
  issn = {1536-5050},
  doi = {10.5195/jmla.2017.88},
  pmcid = {PMC5370619},
  pmid = {null},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\UD3DETS5\\Foster and Deardorff - 2017 - Open Science Framework (OSF).pdf}
}

@book{geiserDataAnalysisMplus2012,
  title = {Data {{Analysis}} with {{Mplus}}},
  author = {Geiser, Christian},
  year = {2012},
  month = nov,
  publisher = {{Guilford Press}},
  abstract = {A practical introduction to using Mplus for the analysis of multivariate data, this volume provides step-by-step guidance, complete with real data examples, numerous screen shots, and output excerpts. The author shows how to prepare a data set for import in Mplus using SPSS. He explains how to specify different types of models in Mplus syntax and address typical caveats--for example, assessing measurement invariance in longitudinal SEMs. Coverage includes path and factor analytic models as well as mediational, longitudinal, multilevel, and latent class models. Specific programming tips and solution strategies are presented in boxes in each chapter. The companion website (http://crmda.ku.edu/guilford/geiser) features data sets, annotated syntax files, and output for all of the examples. Of special utility to instructors and students, many of the examples can be run with the free demo version of Mplus.},
  googlebooks = {d2VLVhEQ7IMC},
  isbn = {978-1-4625-0245-5},
  langid = {english},
  keywords = {Business \& Economics / Statistics,Computers / Databases / General,Computers / Mathematical \& Statistical Software,Education / Statistics,Mathematics / Probability \& Statistics / Multivariate Analysis,Medical / Nursing / General,Psychology / Statistics,Social Science / Statistics},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\CJ7CX54J\\Geiser - 2012 - Data Analysis with Mplus.pdf}
}

@book{hagenaarsAppliedLatentClass2002,
  title = {Applied {{Latent Class Analysis}}},
  author = {Hagenaars, Jacques A. and McCutcheon, Allan L.},
  year = {2002},
  month = jun,
  publisher = {{Cambridge University Press}},
  abstract = {Applied Latent Class Analysis introduces several innovations in latent class analysis to a wider audience of researchers. Many of the world's leading innovators in the field of latent class analysis contributed essays to this volume, each presenting a key innovation to the basic latent class model and illustrating how it can prove useful in situations typically encountered in actual research.},
  isbn = {978-1-139-43923-7},
  langid = {english},
  keywords = {Mathematics / General,Social Science / Demography,Social Science / Research},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\BBAZIEIW\\Hagenaars and McCutcheon - 2002 - Applied Latent Class Analysis.pdf}
}

@article{jamshidianTestsHomoscedasticityNormality2010,
  title = {Tests of {{Homoscedasticity}}, {{Normality}}, and {{Missing Completely}} at {{Random}} for {{Incomplete Multivariate Data}}},
  author = {Jamshidian, Mortaza and Jalal, Siavash},
  year = {2010},
  month = aug,
  journal = {Psychometrika},
  volume = {75},
  number = {4},
  pages = {649--674},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-010-9175-3},
  abstract = {Test of homogeneity of covariances (or homoscedasticity) among several groups has many applications in statistical analysis. In the context of incomplete data analysis, tests of homoscedasticity among groups of cases with identical missing data patterns have been proposed to test whether data are missing completely at random (MCAR). These tests of MCAR require large sample sizes n and/or large group sample sizes ni, and they usually fail when applied to nonnormal data. Hawkins (Technometrics 23:105\textendash 110, 1981) proposed a test of multivariate normality and homoscedasticity that is an exact test for complete data when ni are small. This paper proposes a modification of this test for complete data to improve its performance, and extends its application to test of homoscedasticity and MCAR when data are multivariate normal and incomplete. Moreover, it is shown that the statistic used in the Hawkins test in conjunction with a nonparametric k-sample test can be used to obtain a nonparametric test of homoscedasticity that works well for both normal and nonnormal data. It is explained how a combination of the proposed normal-theory Hawkins test and the nonparametric test can be employed to test for homoscedasticity, MCAR, and multivariate normality. Simulation studies show that the newly proposed tests generally outperform their existing competitors in terms of Type I error rejection rates. Also, a power study of the proposed tests indicates good power. The proposed methods use appropriate missing data imputations to impute missing data. Methods of multiple imputation are described and one of the methods is employed to confirm the result of our single imputation methods. Examples are provided where multiple imputation enables one to identify a group or groups whose covariance matrices differ from the majority of other groups.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\BMYLXS4G\\s11336-010-9175-3.html}
}

@article{killianSystematicReviewLatent2019,
  title = {A {{Systematic Review}} of {{Latent Variable Mixture Modeling Research}} in {{Social Work Journals}}},
  author = {Killian, Michael O. and Cimino, Andrea N. and Weller, Bridget E. and Hyun Seo, Chang},
  year = {2019},
  month = mar,
  journal = {Journal of Evidence-Based Social Work},
  volume = {16},
  number = {2},
  pages = {192--210},
  publisher = {{Routledge}},
  issn = {2640-8066},
  doi = {10.1080/23761407.2019.1577783},
  abstract = {Purpose: Latent variable mixture modeling (LVMM) estimates possible classes, profiles, or trajectories within a sample and then identifies individuals with similar patterns. This systematic review examines the use of person-centered LVMM analyses published in social work journals.Methods: We screened 478 articles and obtained a final sample of 32 studies meeting inclusion criteria.Results: Studies using LVMM were published between 2004 and 2017 with a majority appearing after 2012. Latent class analysis was used in most studies followed by latent profile analysis and longitudinal variants of LVMM. Samples sizes ranged from 199 to 1,002,122 (median = 533). Less than half of the identified studies met model fit reporting standards.Discussion: This systematic review demonstrates the usefulness and growing popularity of LVMM studies within social work journals. Social Work researchers are encouraged to employ person-centered methods to explore unobserved groups or trajectories within cross-sectional and longitudinal data.},
  keywords = {Latent class analysis,latent variable mixture modeling,systematic review},
  annotation = {\_eprint: https://doi.org/10.1080/23761407.2019.1577783},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\RBXE7DHQ\\Killian et al. - 2019 - A Systematic Review of Latent Variable Mixture Mod.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\5RJG5KN6\\23761407.2019.html}
}

@incollection{lanzaIntroductionLatentClass2003,
  title = {An {{Introduction}} to {{Latent Class}} and {{Latent Transition Analysis}}},
  booktitle = {Handbook of {{Psychology}}: {{Research Methods}} in {{Psychology}}},
  author = {Lanza, Stephanie T. and Bray, Bethany C. and Collins, Linda M.},
  year = {2003},
  edition = {Second},
  volume = {2},
  pages = {690--712},
  publisher = {{John Wiley \& Sons}},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\J6326NUP\\Lanza et al. - An Introduction to Latent Class and Latent Transit.pdf}
}

@article{leeComparisonFullInformation2021,
  title = {A Comparison of Full Information Maximum Likelihood and Multiple Imputation in Structural Equation Modeling with Missing Data},
  author = {Lee, Taehun and Shi, Dexin},
  year = {2021},
  journal = {Psychological Methods},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1463(Electronic),1082-989X(Print)},
  doi = {10.1037/met0000381},
  abstract = {This article compares two missing data procedures, full information maximum likelihood (FIML) and multiple imputation (MI), to investigate their relative performances in relation to the results from analyses of the original complete data or the hypothetical data available before missingness occurred. By expressing the FIML estimator as a special MI estimator, we predicted the expected patterns of discrepancy between the two estimators. Via Monte Carlo simulation studies where we have access to the original complete data, we compare the performance of FIML and MI estimators to that of the complete data maximum likelihood (ML) estimator under a wide range of conditions, including differences in sample size, percent of missingness, and degrees of model misfit. Our study confirmed well-known knowledge that the two estimators tend to yield essentially equivalent results to each other and to those from analysis of complete data when the postulated model is correctly specified. However, some noteworthy patterns of discrepancies were found between the FIML and MI estimators when the hypothesized model does not hold exactly in the population: MI-based parameter estimates, comparative fit index (CFI), and the Tucker Lewis index (TLI) tend to be closer to the counterparts of the complete data ML estimates, whereas FIML-based chi-squares and root mean square error of approximation (RMSEA) tend to be closer to the counterparts of the complete data ML estimates. We explained the observed patterns of discrepancy between the two estimators as a function of the interplay between the parsimony and accuracy of the imputation model. We concluded by discussing practical and methodological implications and issues for further research. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Maximum Likelihood,Sample Size,Simulation,Statistical Data,Structural Equation Modeling},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\JFMXBC8G\\2021-12018-001.html}
}

@book{littleOxfordHandbookQuantitative2013,
  title = {The {{Oxford Handbook}} of {{Quantitative Methods}} in {{Psychology}}: {{Vol}}. 2: {{Statistical Analysis}}},
  shorttitle = {The {{Oxford Handbook}} of {{Quantitative Methods}} in {{Psychology}}},
  author = {Little, Todd D.},
  year = {2013},
  month = mar,
  publisher = {{OUP USA}},
  abstract = {Research today demands the application of sophisticated and powerful research tools. Fulfilling this need, The Oxford Handbook of Quantitative Methods in Psychology is the complete tool box to deliver the most valid and generalizable answers to today's complex research questions. It is a one-stop source for learning and reviewing current best-practices in quantitative methods as practiced in the social, behavioral, and educational sciences. Comprising two volumes, this handbook covers a wealth of topics related to quantitative research methods. It begins with essential philosophical and ethical issues related to science and quantitative research. It then addresses core measurement topics before delving into the design of studies. Principal issues related to modern estimation and mathematical modeling are also detailed. Topics in the handbook then segway into the realm of statistical inference and modeling with chapters dedicated to classical approaches as well as modern latent variable approaches. Numerous chapters associated with longitudinal data and more specialized techniques round out this broad selection of topics. Comprehensive, authoritative, and user-friendly, this two-volume set will be an indispensable resource for serious researchers across the social, behavioral, and educational sciences.},
  googlebooks = {\_ulgdl4BPH0C},
  isbn = {978-0-19-993489-8},
  langid = {english},
  keywords = {Medical / Psychiatry / General,Psychology / General,Psychology / Research \& Methodology,Psychology / Social Psychology},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\2ST8KXKI\\Little - 2013 - The Oxford Handbook of Quantitative Methods in Psy.pdf}
}

@article{littleTestMissingCompletely1988,
  title = {A {{Test}} of {{Missing Completely}} at {{Random}} for {{Multivariate Data}} with {{Missing Values}}},
  author = {Little, Roderick J. A.},
  year = {1988},
  journal = {Journal of the American Statistical Association},
  volume = {83},
  number = {404},
  pages = {pp. 1198-1202},
  issn = {01621459},
  doi = {10.2307/2290157},
  abstract = {A common concern when faced with multivariate data with missing values is whether the missing data are missing completely at random (MCAR); that is, whether missingness depends on the variables in the data set. One way of assessing this is to compare the means of recorded values of each variable between groups defined by whether other variables in the data set are missing or not. Although informative, this procedure yields potentially many correlated statistics for testing MCAR, resulting in multiple-comparison problems. This article proposes a single global test statistic for MCAR that uses all of the available data. The asymptotic null distribution is given, and the small-sample null distribution is derived for multivariate normal data with a monotone pattern of missing data. The test reduces to a standard t test when the data are bivariate with missing data confined to a single variable. A limited simulation study of empirical sizes for the test applied to normal and nonnormal data suggests that the test is conservative for small samples.}
}

@incollection{masynLatentClassAnalysis2013,
  title = {Latent {{Class Analysis}} and {{Finite Mixture Modeling}}},
  booktitle = {The {{Oxford Handbook}} of {{Quantitative Methods}}},
  author = {Masyn, Katherine E.},
  year = {2013},
  volume = {2: Statistical Analysis},
  pages = {551},
  publisher = {{Oxford University Press}},
  abstract = {Finite mixture models, which are a type of latent variable model, express the overall distribution of one or more variables as a mixture of a finite number of component distributions. In direct applications, one assumes that the overall population heterogeneity with respect to a set of manifest variables results from the existence of two or more distinct homogeneous subgroups, or latent classes, of individuals. This chapter presents the prevailing ``best practices'' for direct applications of basic finite mixture modeling, specifically latent class analysis (LCA) and latent profile analysis (LPA), in terms of model assumptions, specification, estimation, evaluation, selection, and interpretation. In addition, a brief introduction to structural equation mixture modeling in the form of latent class regression is provided as well as a partial overview of the many more advanced mixture models currently in use. The chapter closes with a cautionary note about the limitations and common misuses of latent class models and a look toward promising future developments in mixture modeling.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\28JAQ4M7\\Masyn - 2013 - Latent Class Analysis and Finite Mixture Modeling.pdf}
}

@book{mclachlanFiniteMixtureModels2004,
  title = {Finite {{Mixture Models}}},
  author = {McLachlan, Geoffrey J. and Peel, David},
  year = {2004},
  month = mar,
  publisher = {{John Wiley \& Sons}},
  abstract = {An up-to-date, comprehensive account of major issues in finite mixture modeling This volume provides an up-to-date account of the theory and applications of modeling via finite mixture distributions. With an emphasis on the applications of mixture models in both mainstream analysis and other areas such as unsupervised pattern recognition, speech recognition, and medical imaging, the book describes the formulations of the finite mixture approach, details its methodology, discusses aspects of its implementation, and illustrates its application in many common statistical contexts. Major issues discussed in this book include identifiability problems, actual fitting of finite mixtures through use of the EM algorithm, properties of the maximum likelihood estimators so obtained, assessment of the number of components to be used in the mixture, and the applicability of asymptotic theory in providing a basis for the solutions to some of these problems. The author also considers how the EM algorithm can be scaled to handle the fitting of mixture models to very large databases, as in data mining applications. This comprehensive, practical guide: * Provides more than 800 references-40\% published since 1995 * Includes an appendix listing available mixture software * Links statistical literature with machine learning and pattern recognition literature * Contains more than 100 helpful graphs, charts, and tables Finite Mixture Models is an important resource for both applied and theoretical statisticians as well as for researchers in the many areas in which finite mixture models can be used to analyze data.},
  googlebooks = {c2\_fAox0DQoC},
  isbn = {978-0-471-65406-3},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\YEAFQRBB\\McLachlan and Peel - 2004 - Finite Mixture Models.pdf}
}

@article{normanLikertScalesLevels2010,
  title = {Likert Scales, Levels of Measurement and the ``Laws'' of Statistics},
  author = {Norman, Geoff},
  year = {2010},
  month = dec,
  journal = {Advances in Health Sciences Education},
  volume = {15},
  number = {5},
  pages = {625--632},
  issn = {1573-1677},
  doi = {10.1007/s10459-010-9222-y},
  abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for ``getting the wrong answer''.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\J3D499WJ\\Norman_2010_Likert scales, levels of measurement and the “laws” of statistics.pdf}
}

@article{nylund-gibsonTenFrequentlyAsked2018,
  title = {Ten Frequently Asked Questions about Latent Class Analysis.},
  author = {{Nylund-Gibson}, Karen and Choi, Andrew Young},
  year = {2018},
  month = dec,
  journal = {Translational Issues in Psychological Science},
  volume = {4},
  number = {4},
  pages = {440--461},
  issn = {2332-2179, 2332-2136},
  doi = {10.1037/tps0000176},
  abstract = {Latent class analysis (LCA) is a statistical method used to identify unobserved subgroups in a population with a chosen set of indicators. Given the increasing popularity of LCA, our aim is to equip psychological researchers with the theoretical and statistical fundamentals that we believe will facilitate the application of LCA models in practice. In this article, we provide answers to 10 frequently asked questions about LCA. The questions included in this article were fielded from our experience consulting with applied researchers interested in using LCA. The major topics include a general introduction in the LCA; an overview of class enumeration (e.g., deciding on the number of classes), including commonly used statistical fit indices; substantive interpretation of LCA solutions; estimation of covariates and distal outcome relations to the latent class variable; data requirements for LCA; software choices and considerations; distinctions and similarities among LCA and related latent variable models; and extensions of the LCA model. To illustrate the modeling ideas described in this article, we present an applied example using LCA. Specifically, we use LCA to model individual differences in positive youth development among college students and analyze demographic characteristics as covariates and a distal outcome of overall life satisfaction. We also include key references that direct readers to more detailed and technical discussions of these topics for which we provide an applied and introductory overview. We conclude by mentioning future developments in research and practice, including advanced cross-sectional and longitudinal extensions of LCA.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\U93E6H2K\\Nylund-Gibson_Choi_2018_Ten frequently asked questions about latent class analysis.pdf}
}

@article{nylundDecidingNumberClasses2007,
  title = {Deciding on the {{Number}} of {{Classes}} in {{Latent Class Analysis}} and {{Growth Mixture Modeling}}: {{A Monte Carlo Simulation Study}}},
  shorttitle = {Deciding on the {{Number}} of {{Classes}} in {{Latent Class Analysis}} and {{Growth Mixture Modeling}}},
  author = {Nylund, Karen L. and Asparouhov, Tihomir and Muth{\'e}n, Bengt O.},
  year = {2007},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {14},
  number = {4},
  pages = {535--569},
  issn = {1070-5511},
  doi = {10.1080/10705510701575396},
  abstract = {Mixture modeling is a widely applied data analysis technique used to identify unobserved heterogeneity in a population. Despite mixture models' usefulness in practice, one unresolved issue in the application of mixture models is that there is not one commonly accepted statistical indicator for deciding on the number of classes in a study population. This article presents the results of a simulation study that examines the performance of likelihood-based tests and the traditionally used Information Criterion (ICs) used for determining the number of classes in mixture modeling. We look at the performance of these tests and indexes for 3 types of mixture models: latent class analysis (LCA), a factor mixture model (FMA), and a growth mixture models (GMM). We evaluate the ability of the tests and indexes to correctly identify the number of classes at three different sample sizes (n = 200, 500, 1,000). Whereas the Bayesian Information Criterion performed the best of the ICs, the bootstrap likelihood ratio test proved to be a very consistent indicator of classes across all of the models considered.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\CWQE8NMZ\\Nylund et al_2007_Deciding on the Number of Classes in Latent Class Analysis and Growth Mixture.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\JTC9MZKW\\10705510701575396.html}
}

@article{petersenApplicationLatentClass2019,
  title = {The {{Application}} of {{Latent Class Analysis}} for {{Investigating Population Child Mental Health}}: {{A Systematic Review}}},
  shorttitle = {The {{Application}} of {{Latent Class Analysis}} for {{Investigating Population Child Mental Health}}},
  author = {Petersen, Kimberly J. and Qualter, Pamela and Humphrey, Neil},
  year = {2019},
  journal = {Frontiers in Psychology},
  volume = {10},
  issn = {1664-1078},
  abstract = {Background: Latent class analysis (LCA) can be used to identify subgroups of children with similar patterns of mental health symptoms and/or strengths. The method is becoming more commonly used in child mental health research, but there are reservations about the replicability, reliability, and validity of findings.Objective: A systematic literature review was conducted to investigate the extent to which LCA has been used to study population mental health in children, and whether replicable, reliable and valid findings have been demonstrated.Methods: Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines were followed. A search of literature, published between January 1998 and December 2017, was carried out using MEDLINE, EMBASE, PsycInfo, Scopus, ERIC, ASSIA, and Google Scholar. A total of 2,748 studies were initially identified, of which 23 were eligible for review. The review examined the methods which studies had used to choose the number of mental health classes, the classes that they found, and whether there was evidence for the validity and reliability of the classes.Results: Reviewed studies used LCA to investigate both disparate mental health symptoms, and those associated with specific disorders. The corpus of studies using similar indicators was small. Differences in the criteria used to select the final LCA model were found between studies. All studies found meaningful or useful subgroups, but there were differences in the extent to which the validity and reliability of classes were explicitly demonstrated.Conclusions : LCA is a useful tool for studying and classifying child mental health at the population level. Recommendations are made to improve the application and reporting of LCA and to increase confidence in findings in the future, including use of a range of indices and criteria when enumerating classes, clear reporting of methods for replicability, and making efforts to establish the validity and reliability of identified classes.},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\TT2BHNW3\\Petersen et al. - 2019 - The Application of Latent Class Analysis for Inves.pdf}
}

@article{rubinInferenceMissingData1976,
  title = {Inference and {{Missing Data}}},
  author = {Rubin, Donald B.},
  year = {1976},
  journal = {Biometrika},
  volume = {63},
  number = {3},
  pages = {581--592},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {0006-3444},
  doi = {10.2307/2335739},
  abstract = {When making sampling distribution inferences about the parameter of the data, \texttheta, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about \texttheta, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from \texttheta. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.}
}

@article{shiremanExaminingEffectInitialization2017,
  title = {Examining the Effect of Initialization Strategies on the Performance of {{Gaussian}} Mixture Modeling},
  author = {Shireman, Emilie and Steinley, Douglas and Brusco, Michael J.},
  year = {2017},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {49},
  number = {1},
  pages = {282--293},
  issn = {1554-3528},
  doi = {10.3758/s13428-015-0697-6},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\LTFZ7BZR\\Shireman et al_2017_Examining the effect of initialization strategies on the performance of.pdf}
}

@article{spurkLatentProfileAnalysis2020,
  title = {Latent Profile Analysis: {{A}} Review and ``How to'' Guide of Its Application within Vocational Behavior Research},
  shorttitle = {Latent Profile Analysis},
  author = {Spurk, Daniel and Hirschi, Andreas and Wang, Mo and Valero, Domingo and Kauffeld, Simone},
  year = {2020},
  month = aug,
  journal = {Journal of Vocational Behavior},
  volume = {120},
  pages = {103445},
  issn = {0001-8791},
  doi = {10.1016/j.jvb.2020.103445},
  abstract = {Latent profile analysis (LPA) is a categorical latent variable approach that focuses on identifying latent subpopulations within a population based on a certain set of variables. LPA thus assumes that people can be typed with varying degrees of probabilities into categories that have different configural profiles of personal and/or environmental attributes. Within this article, we (a) review the existing applications of LPA within past vocational behavior research; (b) illustrate best practice procedures in a non-technical way of how to use LPA methodology, with an illustrative example of identifying different latent profiles of heavy work investment (i.e., working compulsively, working excessively, and work engagement); and (c) outline future research possibilities in vocational behavior research. By reviewing 46 studies stemming from central journals of the field, we identified seven distinct topics that have already been investigated by LPA (e.g., job and organizational attitudes and behaviors, work motivation, career-related attitudes and orientations, vocational interests). Together with showing descriptive statistics about how LPA has been conducted in past vocational behavior research, we illustrate and derive best-practice recommendations for future LPA research. The review and ``how to'' guide can be helpful for all researchers interested in conducting LPA studies.},
  langid = {english},
  keywords = {Bestpractice,Categorical latent variable model,Factor mixture models,Heavy work investment,Latent profile analysis,Person-centered methods,Review,Work engagement,Working compulsively,Working excessively},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\5WX5MJD6\\Spurk et al. - 2020 - Latent profile analysis A review and “how to” gui.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\BWV97HYG\\S0001879120300701.html}
}

@article{ulbrichtUseLatentClass2018,
  title = {The Use of Latent Class Analysis for Identifying Subtypes of Depression: {{A}} Systematic Review},
  shorttitle = {The Use of Latent Class Analysis for Identifying Subtypes of Depression},
  author = {Ulbricht, C. M. and Chrysanthopoulou, S. A. and Levin, L. and Lapane, K. L.},
  year = {2018},
  journal = {Psychiatry Res},
  volume = {266},
  pages = {228--246},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\HWHN7YW7\\Ulbricht et al. - 2018 - The use of latent class analysis for identifying s.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\MVH6PWNL\\use-latent-class-analysis-identifying-subtypes-depression-systematic-review.html}
}

@article{vandeschootGRoLTSChecklistGuidelinesReporting2017,
  title = {The {{GRoLTS-Checklist}}: {{Guidelines}} for {{Reporting}} on {{Latent Trajectory Studies}}},
  shorttitle = {The {{GRoLTS-Checklist}}},
  author = {Van De Schoot, Rens and Sijbrandij, Marit and Winter, Sonja D. and Depaoli, Sarah and Vermunt, Jeroen K.},
  year = {2017},
  month = may,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {24},
  number = {3},
  pages = {451--467},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1080/10705511.2016.1247646},
  abstract = {Estimating models within the mixture model framework, like latent growth mixture modeling (LGMM) or latent class growth analysis (LCGA), involves making various decisions throughout the estimation process. This has led to a wide variety in how results of latent trajectory analysis are reported. To overcome this issue, using a 4-round Delphi study, we developed Guidelines for Reporting on Latent Trajectory Studies (GRoLTS). The purpose of GRoLTS is to present criteria that should be included when reporting the results of latent trajectory analysis across research fields. We have gone through a systematic process to identify key components that, according to a panel of experts, are necessary when reporting results for trajectory studies. We applied GRoLTS to 38 papers where LGMM or LCGA was used to study trajectories of posttraumatic stress after a traumatic event.},
  keywords = {latent classes,LCGA,LGMM,mixture modeling,SEM},
  annotation = {\_eprint: https://doi.org/10.1080/10705511.2016.1247646},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\A78JVFLD\\Van De Schoot et al_2017_The GRoLTS-Checklist.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\AIENK6LB\\10705511.2016.html}
}

@article{vankollenburgLazyBootstrapFast,
  title = {The {{Lazy Bootstrap}}. {{A Fast Resampling Method}} for {{Evaluating Latent Class Model Fit}}},
  author = {{van Kollenburg}, Geert H and Mulder, Joris and Vermunt, Jeroen K},
  pages = {23},
  abstract = {The latent class model is a powerful unsupervised clustering algorithm for categorical data. Many statistics exist to test the fit of the latent class model. However, traditional methods to evaluate those fit statistics are not always useful. Asymptotic distributions are not always known, and empirical reference distributions can be very time consuming to obtain. In this paper we propose a fast resampling scheme with which any type of model fit can be assessed. We illustrate it here on the latent class model, but the methodology can be applied in any situation. The principle behind the lazy bootstrap method is to specify a statistic which captures the characteristics of the data that a model should capture correctly. If those characteristics in the observed data and in model-generated data are very different we can assume that the model could not have produced the observed data. With this method we achieve the flexibility of tests from the Bayesian framework, while only needing maximum likelihood estimates. We provide a step-wise algorithm with which the fit of a model can be assessed based on the characteristics we as researcher find important. In a Monte Carlo study we show that the method has very low type I errors, for all illustrated statistics. Power to reject a model depended largely on the type of statistic that was used and on sample size. We applied the method to an empirical data set on clinical subgroups with risk of Myocardial infarction and compared the results directly to the parametric bootstrap. The results of our method were highly similar to those obtained by the parametric bootstrap, while the required computations differed three orders of magnitude in favour of our method.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\TAW37RC4\\van Kollenburg et al_The Lazy Bootstrap.pdf}
}

@article{vanlissaWORCSWorkflowOpen2020,
  title = {{{WORCS}}: {{A Workflow}} for {{Open Reproducible Code}} in {{Science}}},
  shorttitle = {{{WORCS}}},
  author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara},
  year = {2020},
  month = may,
  publisher = {{OSF}},
  doi = {10.17605/OSF.IO/ZCVBS},
  abstract = {Hosted on the Open Science Framework},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\UMDTXGQG\\zcvbs.html}
}

@article{vanlissaWORCSWorkflowOpen2021,
  title = {{{WORCS}}: {{A}} Workflow for Open Reproducible Code in Science},
  shorttitle = {{{WORCS}}},
  author = {Van Lissa, Caspar J. and Brandmaier, Andreas M. and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E. and Vreede, Barbara M. I.},
  year = {2021},
  month = jan,
  journal = {Data Science},
  volume = {4},
  number = {1},
  pages = {29--49},
  publisher = {{IOS Press}},
  issn = {2451-8484},
  doi = {10.3233/DS-210031},
  abstract = {Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\CTKPR7IM\\Van Lissa et al. - 2021 - WORCS A workflow for open reproducible code in sc.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\MFFHKNXL\\ds210031.html}
}

@incollection{vermuntj.k.LatentClassAnalysis2004,
  title = {Latent Class Analysis},
  booktitle = {The {{Sage}} Encyclopedia of Social Sciences Research Methods},
  author = {{Vermunt, J.K.} and {Magidson, J.} and {Lewis-Beck, M.} and {Bryman, A.} and {Liao, T.F.} and {Department of Methodology and Statistics}},
  year = {2004},
  pages = {549--553},
  publisher = {{Sage}},
  isbn = {978-0-7619-2363-3},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\UG5JMK2Y\\Vermunt, J.K. et al_2004_Latent class analysis.pdf}
}

@article{vermuntKmeansMayPerform2011,
  title = {K-Means May Perform as Well as Mixture Model Clustering but May Also Be Much Worse: {{Comment}} on {{Steinley}} and {{Brusco}} (2011).},
  shorttitle = {K-Means May Perform as Well as Mixture Model Clustering but May Also Be Much Worse},
  author = {Vermunt, Jeroen K.},
  year = {2011},
  month = mar,
  journal = {Psychological Methods},
  volume = {16},
  number = {1},
  pages = {82--88},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0020144},
  abstract = {Steinley and Brusco (2011) presented the results of a huge simulation study aimed at evaluating cluster recovery of mixture model clustering (MMC) both for the situation where the number of clusters is known and is unknown. They derived rather strong conclusions on the basis of this study, especially with regard to the good performance of K-means (KM) compared with MMC. I agree with the authors' conclusion that the performance of KM may be equal to MMC in certain situations, which are primarily the situations investigated by Steinley and Brusco. However, a weakness of the paper is the failure to investigate many important real-world situations where theory suggests that MMC should outperform KM. This article elaborates on the KM\textendash MMC comparison in terms of cluster recovery and provides some additional simulation results that show that KM may be much worse than MMC. Moreover, I show that KM is equivalent to a restricted mixture model estimated by maximizing the classification likelihood and comment on Steinley and Brusco's recommendation regarding the use of mixture models for clustering.},
  langid = {english},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\LILNTAL7\\Vermunt_2011_K-means may perform as well as mixture model clustering but may also be much.pdf}
}

@article{wellerLatentClassAnalysis2020,
  title = {Latent {{Class Analysis}}: {{A Guide}} to {{Best Practice}}},
  shorttitle = {Latent {{Class Analysis}}},
  author = {Weller, Bridget E. and Bowen, Natasha K. and Faubert, Sarah J.},
  year = {2020},
  month = may,
  journal = {Journal of Black Psychology},
  volume = {46},
  number = {4},
  pages = {287--311},
  publisher = {{SAGE Publications Inc}},
  issn = {0095-7984},
  doi = {10.1177/0095798420930932},
  abstract = {Latent class analysis (LCA) is a statistical procedure used to identify qualitatively different subgroups within populations who often share certain outward characteristics. The assumption underlying LCA is that membership in unobserved groups (or classes) can be explained by patterns of scores across survey questions, assessment indicators, or scales. The application of LCA is an active area of research and continues to evolve. As more researchers begin to apply the approach, detailed information on key considerations in conducting LCA is needed. In the present article, we describe LCA, review key elements to consider when conducting LCA, and provide an example of its application.},
  langid = {english},
  keywords = {ADHD,behavior problems,latent class analysis,National Survey of Children’s Health,social determinants of health},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\NHXJHDMN\\Weller et al. - 2020 - Latent Class Analysis A Guide to Best Practice.pdf}
}

@article{wuAbuseDependencePrescription2011,
  title = {Abuse and Dependence on Prescription Opioids in Adults: A Mixture Categorical and Dimensional Approach to Diagnostic Classification},
  shorttitle = {Abuse and Dependence on Prescription Opioids in Adults},
  author = {Wu, L.-T. and Woody, G. E. and Yang, C. and Pan, J.-J. and Blazer, D. G.},
  year = {2011},
  month = mar,
  journal = {Psychological Medicine},
  volume = {41},
  number = {3},
  pages = {653--664},
  publisher = {{Cambridge University Press}},
  issn = {1469-8978, 0033-2917},
  doi = {10.1017/S0033291710000954},
  abstract = {BackgroundFor the emerging DSM-V, it has been recommended that dimensional and categorical methods be used simultaneously in diagnostic classification; however, little is known about this combined approach for abuse and dependence.MethodUsing data (n=37 708) from the 2007 National Survey on Drug Use and Health (NSDUH), DSM-IV criteria for prescription opioid abuse and dependence among non-prescribed opioid users (n=3037) were examined using factor analysis (FA), latent class analysis (LCA, categorical), item response theory (IRT, dimensional), and factor mixture (hybrid) approaches.ResultsA two-class factor mixture model (FMM) combining features of categorical latent classes and dimensional IRT estimates empirically fitted more parsimoniously to abuse and dependence criteria data than models from FA, LCA and IRT procedures respectively. This mixture model included a severely affected group (7\%) with a comparatively moderate to high probability (0.32-0.88) of endorsing all abuse and dependence criteria items, and a less severely affected group (93\%) with a low probability (0.003-0.16) of endorsing all criteria. The two empirically defined groups differed significantly in the pattern of non-prescribed opioid use, co-morbid major depression, and substance abuse treatment use.ConclusionsA factor mixture model integrating categorical and dimensional features of classification fits better to DSM-IV criteria for prescription opioid abuse and dependence in adults than a categorical or dimensional approach. Research is needed to examine the utility of this mixture classification for substance use disorders and treatment response.},
  langid = {english},
  keywords = {DSM-IV,factor mixture model,item response theory,latent class analyses,nosology,prescription opioid use disorders},
  file = {C\:\\Users\\lissa102\\Zotero\\storage\\FMJYDIN4\\Wu et al_2011_Abuse and dependence on prescription opioids in adults.pdf;C\:\\Users\\lissa102\\Zotero\\storage\\MBIYP587\\A56D6B96CF458C36A272BD3170D3FA47.html}
}


