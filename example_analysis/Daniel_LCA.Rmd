---
title: "LCA in R using tidySEM"
output: html_notebook
---
This is an example of an exploratory LCA using `tidySEM`.

# Loading the Dataset

In this example, we use *data_mix_ordinal*, 
a simulated data for mixture modelling with ordinal indicators. 
This dataset is built-in to `tidySEM`.
For more information about the dataset, 
type `?tidySEM::data_mix_ordinal` into the R console
after loading the `tidySEM` using library().

We load the dataset and convert the indicators into ordered factors.

```{r, include = TRUE}
library(tidySEM) # loading tidySEM
df <- data_mix_ordinal  # dataset
df[1:4] <- lapply(df, ordered) # indicators as ordered factors
```

# Exploring the Data

An important step to preceding any statistical analysis is data exploration.
Here we use `tidySEM::descriptives()` 
to describe the dataset we are using.

```{r}
tidySEM::descriptives(df) # descriptives
```
As we can see, the output includes various descriptives of our dataset.
Special attention should be paid to examining the pattern of missingness,
as discussed in the *Handling missing data* section of this paper.
In our example, we see that there are no missing values,
hence we proceed with our analyses.

# Conducting Latent Class Analysis

Before we fit a series of LCA models, we set a random seed
using set.seed().
The seed number can be any digit.
This is an important step as 
there is some inherent randomness in the LCA computations,
and having the same seed number ensures that
two separate researcher obtain exactly the same results
when fitting LCA models.

Finally, we reach the step of fitting LCA models.
To do so, we use `tidySEM::mx_lca()`
which takes data and number of classes as inputs.
In our example, we want to fit 1 to 4 class solutions
and compare their output.
Depending on your computer's computational power,
this might take a while.

```{r}
set.seed(123) # setting seed 
res <- mx_lca(data = df, classes = 1:4) # fitting LCA 
```
# Class enumeration

In class enumeration, 
we want to compare a sequence of LCA models fitted to the data.
To do so, we use `tidySEM::table_fit()` 
with the results object as the input.
This function creates the model fit table formatted for publication.
However, it contains a lot of information on each of the four models.
It may be more helpful to focus on a subset of model fit indices
and classification diagnostics which we do in the subsequent step.

```{r}
fit_table <- table_fit(res) # model fit table
fit_table[ , c("Name", "LL", "AIC", "BIC", "Entropy", "prob_min", "prob_max", "n_min", "n_max")] # a selection from the model fit table
```
The model fit table is important for deciding on the final class solution.
Our subset of fit indices and classification diagnostics includes:

**Name** indicates the $K$-class solution.
In our case, we chose to fit 1 - 4 class solutions,
each is represented by its row in the table.
**LL** is the -2*log-likelihood of each model.
**AIC** and **BIC** are the Akaike 
and the Bayesian Information Criterion, respectively.
**prob_min** and **prob_max** are 
the lowest and the highest posterior class probability
by most likely class membership.
**n_min** and **n_max** are the lowest and the highest
class proportion based on the posterior class probabilities.

In this paper, we discussed several possible strategies 
to select the final class solution.

Here, we apply our own. 
First, we examine the -2*log likelihood 
which falls successively with each added class.

Then, we look at the BIC value
which is fairly close for the one, two, and three-class solutions,
but high for the four-class solution.

As previously stated, classification diagnostics should not be used for model selection,
but they can be used to disqualify certain solutions because they are uninterpretable.
We see that prob_min for the four-class solution is low,
therefore we disqualify this solution.

Out of the remaining three solutions,
we notice that entropy is the highest for the three-class solution,
and it has a satisfactory prob_min and n_min.
Based on this, we can retain the three class solution in model selection.
Note that entropy for the one-class solution will always equal to one,
as it is 100% true that every case is in that class.
Based on the low entropy of the two-class solution,
we eliminate this model.

Finally, when comparing the one and three-class solutions,
we consult the BIC which tells us that the added complexity
of having three classes still explains the data better
than a one-class solution.
Therefore, we select the three-class solution as our final-class solution.

# Interpreting Final Class Solution

To aid our understanding of the final class solution,
we use `ggplot2::plot_prob()` 
with the results of the three-class model as the input.
The resulting graph shows response patterns 
on all the indicators for each group.

If we want to know the probability of each response option's endoresement 
for each class, we can use `tidySEM::table_prob`.
These are thresholds for ordinal dependent variables in the probability scale.

```{r}
library(ggplot2)
plot_prob(res[[3]]) # plotting the response patterns for the final class solution
table_prob(res[[3]]) # tabulating the response patterns for the final class solution
```
In the plot, we can see the distributions each of the response probabilities on the indicators
for each of the three classes.
For instance, we see in Class 1 the most common response to u2 is 2,
while in Class 2 and Class 3 this is 0.
We can also see that response 1 is a rare response not forming the majority in 
any class.
Class 2 distinguishes itself because the majority scores the response 0 category of u3 and u4,
while in Class 1 and 2 this is not the case.
Class 3 distinguishes itself because the most common response to u3 and u4 is 3.

We can also interpret the response patterns numerically.

# Extracting posterior class probabilities

Another step is to extract posterior class probabilities.
This is done by the use of `TidySEM::class_prob`
with the results of the final class solution as the input.


```{r}
probs <- class_prob(res[[3]]) # extracting the posterior class probabilities of the final class solution
probs$mostlikely.class # posterior class probabilities by most likely class membership
probs$individual # individual posterior class probabilities
```



BACKUP TUTORIAL (OLD)

This used to be in the tutorial section of the paper.
I store it here for backup, but I don't think it is longer relevant.


<!-- 5. Tutorial -->
<!-- 5.1 ‘mclust’ -->
<!-- To run LPA using the ‘mclust’ package, the Mclust() function can be used. This function -->
<!-- requires data as its minimum input. In addition, the number of clusters to fit (G) and model -->
<!-- variants to fit and select from (modelNames) can be entered (defaults are: G=1-9 and all -->
<!-- fourteen model variants). In many cases, we may want to consider a more limited range of -->
<!-- model variants to with different numbers of classes. For multivariate data, a total of fourteen -->
<!-- options are available (see help("mclustModelNames") for an overview). Each model variant -->
<!-- is estimated for each value of the specified range of G using Expectation Maximization (EM), -->
<!-- using the Bayesian Information Criterion (BIC) to compare different model variants and -->
<!-- select the optimal one. -->
<!-- Conducting a latent variable model or mixture analysis with Mplus or comparable software -->
<!-- usually entails fitting models with different numbers of classes (that are otherwise configured -->
<!-- similarly) and to compare the fit between these models to select the best model. The -->
<!-- default approach taken in the ‘mclust’ package is slightly different in that the main modeling -->
<!-- command Mclust() fits multiple models for all possible combinations of the specified number -->
<!-- of classes and model configurations . The eventual output of ‘mclust’ is the BIC-selected best -->
<!-- model variant with the optimal combination of number of classes and model configuration. -->
<!-- An advantage of the ‘mclust’ approach is that it is efficient and flexible: given a number of -->
<!-- classes, the best model configuration is selected straight away and we do not have to run all -->
<!-- model combinations one by one. This makes the approach especially suitable for exploratory -->
<!-- analyses. However, like stated above, this approach is somewhat less usual in some fields, -->
<!-- where estimation of LPA is approached in a more confirmatory fashion. In addition, it does -->
<!-- take some control away from the researcher, who may want to primarily focus on selecting -->
<!-- the number of classes, given a particular , theory-based model configuration that is kept -->
<!-- constant throughout analyses, which is often the chosen strategy in software like Mplus and -->
<!-- made easily available through the ‘tidyLPA’ package. -->
<!-- Here, both approaches are shown: (1) the ‘mclust’ aproach and (2) the ‘tidyLPA’ approach. -->




<!--                                               5 -->
<!-- 5.1.1 The ‘mclust’ approach -->
<!-- In this approach, we run consecutive models with increasing numbers of classes (G=1 to -->
<!-- G=9), for each model we let the package fit the four above described model variants (“EEI”, -->
<!-- “EEE”, “VVI” and “VVV”) and select the best-fitting one. We start by loading the package -->
<!-- (library(mclust)) and creating an object mnames that contains the names of the four models -->
<!-- we want to be fitted. Next, we use the Mclust() function to fit the models: -->
<!-- library(mclust) -->

<!-- ## Package 'mclust' version 5.4.7 -->
<!-- ## Type 'citation("mclust")' for citing this R package in publications. -->
<!-- mnames <- c("EEI", "EEE", "VVI", "VVV") -->

<!-- # Fit 1-5 class model -->
<!-- mod_g1_9 <- Mclust(dat1[, 1:10], modelNames = mnames) -->

<!-- We can first look at the optimal number of classes and the optimal model variant that were -->
<!-- selected, using the following code: -->
<!-- # Opimal number of classes -->
<!-- mod_g1_9$G -->

<!-- ## [1] 3 -->
<!-- # Optimal model variant -->
<!-- mod_g1_9$modelName -->

<!-- ## [1] "EEI" -->
<!-- This shows us that a 3-class EEI model was selected as the best model based on the BIC. We -->
<!-- can get a better perspective of this model’s performance if we compare it to the other fitted -->
<!-- models. We can do this by taking a closer look at the other models’ BIC values: -->
<!-- mod_g1_9$BIC -->

<!-- ##   Bayesian Information Criterion (BIC): -->
<!-- ##           EEI       EEE       VVI       VVV -->
<!-- ##   1 -14661.61 -12986.57 -14661.61 -12986.57 -->
<!-- ##   2 -13275.65 -12611.60 -13095.82 -12678.12 -->
<!-- ##   3 -12142.11 -12290.68 -12163.08 -12731.18 -->
<!-- ##   4 -12178.44 -12330.04 -12241.21 -12970.57 -->
<!-- ##   5 -12223.14 -12379.96 -12320.47 -13231.35 -->
<!-- ##   6 -12264.04 -12423.72 -12406.59 -13522.40 -->
<!-- ##   7 -12269.39 -12451.25 -12497.03 -13748.91 -->
<!-- ##   8 -12298.30 -12483.35 -12568.62 -13980.82 -->
<!-- ##   9 -12347.11 -12529.40 -12645.50 -14269.34 -->
<!-- ## -->


<!--                                              6 -->
<!-- ## Top 3 models based on the BIC criterion: -->
<!-- ##     EEI,3     VVI,3     EEI,4 -->
<!-- ## -12142.11 -12163.08 -12178.44 -->
<!-- mod_g1_9$loglik -->

<!-- ## [1] -5951.275 -->
<!-- mod_g1_9$df -->

<!-- ## [1] 42 -->
<!-- Here, we can see the BICs for all fitted models (in this case 1-9 classes and 4 model variants: -->
<!-- 36 models in total). We can see that the closest contenders were a 3-class model with a VVI -->
<!-- configuration (with variances allowed to vary both within and between classes) and a 4-class -->
<!-- EEI model. -->
<!-- Note that the BIC values are negative, and that values that are more negative are considered -->
<!-- to fit poorer than values closer to 0. This may strike some users as odd, given that in -->
<!-- many modeling applications, we are used to consider lower BIC values to indicate better -->
<!-- fit. However, the ‘mclust’ approach of maximizing the BIC is correct for the used modeling -->
<!-- approach (see e.g., Fraley & Raftery, 2003; Banfield & Raftery, 1993). For theoretical reasons, -->
<!-- the BIC is calculated in’mclust’ as: -->


<!--                            BIC = 2(Loglikelihood) - df (log(n)) -->

<!-- where df is the number of parameters (degrees of freedom) and n is the sample size. We can -->
<!-- see, that here, higher log likelihood values lead to a higher BIC. For the best fitting model in -->
<!-- our example, the log likelihood is -5951.275, the number of parameters is 42 and the sample -->
<!-- size is 300. If we plug these into the formula, we get the following BIC: -->


<!--                      BIC = 2(-5951.275) - 42(log(300)) = -12142.11 -->

<!-- As expected, the obtained value indeed corresponds to the BIC we got in the model output -->
<!-- (see above). Other software packages, such as Mplus and ‘tidyLPA’ (see below) use a slightly -->
<!-- different formula to calculate the BIC, where higher log likelihood values lead to lower BIC -->
<!-- values: -->


<!--                            BIC = df (log(n)) - 2(Loglikelihood) -->

<!-- When we plug the best-model values into this formula, we get: -->


<!--                       BIC = 42(log(300)) - 2(-5951.275) = 12142.11 -->

<!-- We can see that the absolute BIC value is the same, irrespective of the used formula, with -->
<!-- only the sign differing between the two approaches. -->

<!--                                               7 -->
<!-- Now, let us continue by taking a closer look at the class sizes and the mean values and -->
<!-- variances of the ten variables for the three identified classes. Because the best model has and -->
<!-- EEI configuration, printing out a single variance matrix from one class will suffice, because -->
<!-- the variances are the same across classes (this is different in cases where the optimal model -->
<!-- allows for between-class differences in (co)variances: -->
<!-- # tabulate class-membership numbers -->
<!-- table(summary(mod_g1_9)$classification) -->

<!-- ## -->
<!-- ##   1   2      3 -->
<!-- ## 100 110     90 -->
<!-- # display the means per class -->
<!-- mod_g1_9$parameters$mean -->

<!-- ##             [,1]         [,2]        [,3] -->
<!-- ##   var1 2.023572      6.083019   2.0304980 -->
<!-- ##   var2 3.056837      6.937785   4.8997993 -->
<!-- ##   var3 1.718166      1.107873   7.9385872 -->
<!-- ##   var4 6.086727      2.854402   6.9657536 -->
<!-- ##   var5 7.101109      2.225675   4.7416266 -->
<!-- ##   var6 3.691936      8.081570   2.2469977 -->
<!-- ##   var7 5.009819      2.817889   0.8862725 -->
<!-- ##   var8 8.316894      8.080891   3.9350536 -->
<!-- ##   var9 1.978136      1.896294   9.1537131 -->
<!-- ##   var10 1.191249     5.142590   8.0332628 -->
<!-- # select the first of 3 10-by-10 variance matrices -->
<!-- mod_g1_9$parameters$variance$sigma[1:10, 1:10, 1] -->

<!-- ##               var1       var2       var3       var4       var5       var6       var7       var8 -->
<!-- ##   var1    2.539537   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##   var2    0.000000   2.117941   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##   var3    0.000000   0.000000   2.509035   0.000000   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##   var4    0.000000   0.000000   0.000000   2.812796   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##   var5    0.000000   0.000000   0.000000   0.000000   2.647399   0.000000   0.000000   0.000000 -->
<!-- ##   var6    0.000000   0.000000   0.000000   0.000000   0.000000   2.694156   0.000000   0.000000 -->
<!-- ##   var7    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   2.368379   0.000000 -->
<!-- ##   var8    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   2.540704 -->
<!-- ##   var9    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##   var10   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000 -->
<!-- ##               var9      var10 -->
<!-- ##   var1    0.000000   0.000000 -->
<!-- ##   var2    0.000000   0.000000 -->
<!-- ##   var3    0.000000   0.000000 -->
<!-- ##   var4    0.000000   0.000000 -->


<!--                                                8 -->
<!-- ##   var5    0.000000   0.000000 -->
<!-- ##   var6    0.000000   0.000000 -->
<!-- ##   var7    0.000000   0.000000 -->
<!-- ##   var8    0.000000   0.000000 -->
<!-- ##   var9    2.509146   0.000000 -->
<!-- ##   var10   0.000000   2.204457 -->
<!-- From this output, we can see that the three classes have class-sizes of 100, 110 and 90, -->
<!-- respectively. These sizes along with the patterns of class-specific mean variable scores -->
<!-- correspond with those that served as the input for the simulation. As specified, the variances -->
<!-- vary slightly across variables. -->
<!-- The class allocation in LPA is probabilistic in nature: each subject in the data is assigned a -->
<!-- probability for each of the estimated classes, based on their pattern of scores on the input -->
<!-- variables. These probabilities can be inspected in the z-matrix (here: mod_g1_9$z). Subjects -->
<!-- can be allocated to one of the classes based on their highest class-probability. These posterior -->
<!-- allocations can be found in the classification matrix (here: mod_g1_9$classification). -->
<!-- These class-allocations were tabulated above to evaluate class sizes. -->
<!-- Note that class-allocation in this way only yields useful classifications if the patterns of -->
<!-- class-probabilities allow for allocation of each subject to a single class with sufficient certainty. -->
<!-- In case of too much uncertainty, using the classification is not advised. We can inspect the -->
<!-- uncertainty of allocation for all subjects (here: mod_g1_9$uncertainty). This gives us a list -->
<!-- of uncertainties for all subjects. Next, we can evaluate the extent of uncertainty by looking -->
<!-- at the maximum uncertainty or, for instance, the averaged uncertainty across subjects: -->
<!-- max(mod_g1_9$uncertainty) -->

<!-- ## [1] 0.003852604 -->
<!-- mean(mod_g1_9$uncertainty) -->

<!-- ## [1] 2.607299e-05 -->
<!-- Here, the uncertainty is atypically low because of the used idealized data. In many cases, -->
<!-- uncertainty is higher and it may be of interest to investigate it further, for instance, by -->
<!-- looking at (e.g., plotting or tabulating) the uncertainty per class: -->
<!-- cprob <- cbind(mod_g1_9$z, mod_g1_9$classification) -->
<!-- cprob <- as.data.frame(cprob) -->
<!-- colnames(cprob) <- c("prob (class 1)", "prob (class 2)", "prob (class 3)", "class") -->
<!-- aggregate(cprob[, 1:3], list(cprob$class), mean) -->

<!-- ##   Group.1 prob (class 1) prob (class 2) prob (class 3) -->
<!-- ## 1       1   9.999824e-01   1.761611e-05   3.350070e-10 -->
<!-- ## 2       2   5.486300e-05   9.999451e-01   7.192849e-08 -->
<!-- ## 3       3   2.591358e-08   1.675400e-07   9.999998e-01 -->
<!-- Here we can see that for each class, the mean probability of membership of that class was -->


<!--                                                  9 -->
<!-- very high and probabilities for the other classes were very low. Again, these values reflect the -->
<!-- idealized data; in many cases, more differentiated class-probability patterns may be observed. -->

<!-- 5.1.2 ‘tidyLPA’ -->
<!-- When running ‘mclust’ models from the ‘tidyLPA’ package, the estimations are approached -->
<!-- a little differently. By default, the number of models that can be estimated is restricted to -->
<!-- six relatively common variants (see help(tidyLPA::estimate_profiles) for details). Of -->
<!-- these models, four can be estimated with ‘mclust’. These models differ in terms of how the -->
<!-- variances and covariances are allowed to vary or constrained to be equal across classes and -->
<!-- whether covariances are or are not fixed to zero within classes. These models have each been -->
<!-- allocated a number (1-6) in ‘tidyLPA’. See the table below how these numbers correspond to -->
<!-- the above mentioned model configurations. -->
<!--  Model variant    model number -->
<!--  EEI              1 -->
<!--  EEE              3 -->
<!--  VVI              2 -->
<!--  VVV              6 -->
<!-- Models four and five are different and can only be fit when R is interfacing with Mplus using -->
<!-- the ‘MplusAutomation’ package. This is outside the scope of this tutorial. -->
<!-- To fit an LPA model in ‘tidyLPA’, we use the estimate_profiles() function. Here, we need -->
<!-- to enter the data.frame to be used (df) and the number of classes to estimate (n_profiles). -->
<!-- To determine what kind of model configuration to estimate, the authors have provided two -->
<!-- different ways in the estimate_profiles() command. In the first approach, we simply tell what -->
<!-- model number (see Table 2) we want to estimate using the models= argument For instance, if -->
<!-- we want to estimate LPA models with 1 to 9 classes, with an EEI configuration, we can use: -->
<!-- <!-- suppressMessages(library(tidyLPA)) --> -->
<!-- <!-- suppressMessages(mod_1c_v1 <- estimate_profiles(df = dat1[1:10], n_profiles = 1:9, --> -->
<!-- <!--     models = 1)) --> -->

<!-- The package issues a standard message by default notifying us that we use the models -->
<!-- argument and that the variances and covariances arguments are ignored. Here, we suppress -->
<!-- the message. The output shows us the model-fit information for the 1 to 9-class EEI models: -->
<!-- <!-- mod_1c_v1 --> -->

<!-- ## tidyLPA analysis using mclust: -->
<!-- ## -->
<!-- ## Model Classes AIC       BIC      Entropy            prob_min   prob_max   n_min   n_max   BLRT_p -->
<!-- ## 1      1       14587.53 14661.61 1.00               1.00       1.00       1.00    1.00 -->
<!-- ## 1      2       13160.84 13275.65 1.00               1.00       1.00       0.30    0.70    0.01 -->
<!-- ## 1      3       11986.55 12142.11 1.00               1.00       1.00       0.30    0.37    0.01 -->
<!-- ## 1      4       11982.14 12178.44 0.91               0.79       1.00       0.14    0.33    0.05 -->
<!-- ## 1      5       11986.09 12223.14 0.89               0.75       1.00       0.06    0.33    0.30 -->


<!--                                               10 -->
<!-- ##   1      6         11986.25    12264.04   0.84      0.78       1.00        0.08   0.30    0.16 -->
<!-- ##   1      7         11950.86    12269.39   0.81      0.77       0.91        0.08   0.17    0.01 -->
<!-- ##   1      8         11939.04    12298.30   0.82      0.79       0.92        0.08   0.17    0.02 -->
<!-- ##   1      9         11947.10    12347.11   0.82      0.76       0.92        0.06   0.16    0.57 -->
<!-- Here, we can see that the BIC takes on different values compared to ‘mclust’, with lower -->
<!-- rather than higher values indicating best fit (see explanation above). Instead of drawing the -->
<!-- fit indices (e.g., BIC, AIC) directly from the ‘mclust’ package, ‘tidyLPA’ only draws the ‘raw’ -->
<!-- log likelihood values and posterior probabilities from the ‘mclust’ output and (re)calculates -->
<!-- the BIC, AIC, entropy etc. to mirror as well as possible those provided in Mplus. In addition, -->
<!-- p-values of the the bootstrapped likelihood ratio test (BLRT) are given by default. These -->
<!-- p-values indicate for each k-class model whether adding the kth class adds significantly to -->
<!-- model fit. For instance, the BLRT_p of 0.04 for the 4-class model indicates that adding -->
<!-- a fourth class led to an improvement of model fit compared to the 3-class model that was -->
<!-- just significant when using an alpha of 0.05. When using ’mclust’ as a stand-alone package, -->
<!-- the BLRT is not calculated by default, but can be obtained with the mclustBootstrapLRT -->
<!-- function. -->
<!-- Next, we can run similar commands, with different values for the models argument. It is -->
<!-- also possible to estimate more than one model variant in a single run by providing a vector -->
<!-- of model numbers (e.g., models=c(1,6)). -->
<!-- The second approach to determine the model variant to be estimated is by using the variances -->
<!-- and covariances arguments in the estimate_profiles command. The variances argument -->
<!-- can have the values "equal" (i.e. variable variances constrained to be equal across classes) or -->
<!-- "varying" (i.e. variances allowed to vary across classes). The covariances argument can -->
<!-- have the values: "zero" (i.e. all variable covariances fixed to zero), "equal" (i.e. covariances -->
<!-- constrained to be equal across classes) or "varying" (i.e. covariances allowed to vary across -->
<!-- classes). Now, if we again want to estimate LPA models with 1 to 9 classes, with an EEI -->
<!-- configuration, we can use: -->
<!-- <!-- mod_1c_v2 <- estimate_profiles(df = dat1[1:10], n_profiles = 1:9, variances = "equal", --> -->
<!-- <!--     covariances = "zero") --> -->
<!-- <!-- mod_1c_v2$model_1_class_2$fit --> -->

<!-- <!-- ##         Model           Classes        LogLik                   AIC              AWE --> -->
<!-- <!-- ## 1.000000e+00       2.000000e+00 -6.549418e+03          1.316084e+04     1.354347e+04 --> -->
<!-- <!-- ##           BIC              CAIC           CLC                   KIC            SABIC --> -->
<!-- <!-- ## 1.327565e+04       1.330665e+04 1.310084e+04           1.319484e+04     1.317734e+04 --> -->
<!-- <!-- ##           ICL           Entropy      prob_min              prob_max            n_min --> -->
<!-- <!-- ## -1.327568e+04      9.996750e-01 9.999484e-01           9.999990e-01     3.000000e-01 --> -->
<!-- <!-- ##         n_max          BLRT_val        BLRT_p --> -->
<!-- <!-- ## 7.000000e-01       1.448699e+03 9.900990e-03 --> -->
<!-- As expected, the output is exactly the same as the one we got when using the models -->
<!-- argument. Now, if we want to, we can continue fitting other model variants using either -->
<!-- approach. Next, we can manually compare the models in terms of their BIC and AIC values -->


<!--                                               11 -->
<!-- or we can use compare_solutions to do this in an automated fashion. Interestingly, the -->
<!-- best model can be selected based on the integrated information about several fit indices -->
<!-- (analytic hierarchy process; see help(tidyLPA::AHP)) for more details). We obtain the model -->
<!-- comparison with the following code. -->
<!-- <!-- comp <- suppressWarnings(compare_solutions(mod_1c_v1)) --> -->
<!-- <!-- comp$fits --> -->

<!-- <!-- ##   # A tibble: 9 x 18 --> -->
<!-- <!-- ##     Model Classes LogLik    AIC    AWE    BIC   CAIC    CLC    KIC SABIC      ICL --> -->
<!-- <!-- ##     <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>           <dbl> --> -->
<!-- <!-- ##   1     1       1 -7274. 14588. 14834. 14662. 14682. 14550. 14611. 14598. -14662. --> -->
<!-- <!-- ##   2     1       2 -6549. 13161. 13543. 13276. 13307. 13101. 13195. 13177. -13276. --> -->
<!-- <!-- ##   3     1       3 -5951. 11987. 12506. 12142. 12184. 11905. 12032. 12009. -12142. --> -->
<!-- <!-- ##   4     1       4 -5938. 11982. 12638. 12178. 12231. 11878. 12038. 12010. -12218. --> -->
<!-- <!-- ##   5     1       5 -5929. 11986. 12778. 12223. 12287. 11860. 12053. 12020. -12273. --> -->
<!-- <!-- ##   6     1       6 -5918. 11986. 12915. 12264. 12339. 11838. 12064. 12026. -12353. --> -->
<!-- <!-- ##   7     1       7 -5889. 11951. 13016. 12269. 12355. 11780. 12040. 11997. -12376. --> -->
<!-- <!-- ##   8     1       8 -5873. 11939. 13141. 12298. 12395. 11747. 12039. 11991. -12409. --> -->
<!-- <!-- ##   9     1       9 -5866. 11947. 13285. 12347. 12455. 11733. 12058. 12005. -12458. --> -->
<!-- <!-- ##   # ... with 7 more variables: Entropy <dbl>, prob_min <dbl>, prob_max <dbl>, --> -->
<!-- <!-- ##   #   n_min <dbl>, n_max <dbl>, BLRT_val <dbl>, BLRT_p <dbl> --> -->
<!-- <!-- comp$best --> -->

<!-- <!-- ## LogLik       AIC      AWE      BIC     CAIC        CLC    KIC   SABIC       ICL --> -->
<!-- <!-- ##      9         8        3        3        3          9      3       8         3 --> -->
<!-- As shown in the ‘mclust’ examples above, the EEI model (models=1) with 3 classes fit the -->
<!-- data best, not only according to the BIC, but according to the integrated information from a -->
<!-- broader range of fit indices. Note that we did not fit any competing EEE, VVV and VVI -->
<!-- models here. If we would have wanted to compare fit to these model variants too, we should -->
<!-- have actively told the package to fit these too, either by specifying a vector of different types -->
<!-- of models to fit in the models argument or by repeating the analysis with different values for -->
<!-- the variances and covariances arguments. -->

<!-- 5.2 Comparison to Mplus -->
<!-- For comparison, we fit the equivalent EEI model variants in Mplus. For this, we can mostly -->
<!-- rely on the defaults of Mplus. We only need to specify that we want to estimate class-specific -->
<!-- variable means. The variances are automatically constrained to be equal across classes and -->
<!-- within class variable covariances are fixed to 0. Here we have the separate codes for fitting -->
<!-- the first 4 models wit 1-4 class models (code for the 5-9 class models not shown). -->
<!-- <!-- !! 1-class model --> -->
<!-- <!--   DATA: file='dat1.dat'; --> -->
<!-- <!--   VARIABLE: --> -->


<!-- <!--                                                  12 --> -->
<!-- <!--     names=id v1-v10; --> -->
<!-- <!--     usevariables= v1-v10; --> -->
<!-- <!--     classes = c(1); --> -->
<!-- <!--   ANALYSIS: --> -->
<!-- <!--     type = mixture; --> -->
<!-- <!--     starts= 250 50; --> -->
<!-- <!--   MODEL: --> -->
<!-- <!--   %overall% --> -->
<!-- <!--   %C#1% --> -->
<!-- <!--   [v1-v10]; --> -->

<!-- <!-- !! 2-class model --> -->
<!-- <!--   DATA: file='dat1.dat'; --> -->
<!-- <!--   VARIABLE: --> -->
<!-- <!--     names=id v1-v10; --> -->
<!-- <!--     usevariables= v1-v10; --> -->
<!-- <!--     classes = c(2); --> -->
<!-- <!--   ANALYSIS: --> -->
<!-- <!--     type = mixture; --> -->
<!-- <!--     starts= 250 50; --> -->
<!-- <!--   MODEL: --> -->
<!-- <!--   %overall% --> -->
<!-- <!--   %C#1% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#2% --> -->
<!-- <!--   [v1-v10]; --> -->

<!-- <!-- !! 3-class model --> -->
<!-- <!--   DATA: file='dat1.dat'; --> -->
<!-- <!--   VARIABLE: --> -->
<!-- <!--     names=id v1-v10; --> -->
<!-- <!--     usevariables= v1-v10; --> -->
<!-- <!--     classes = c(3); --> -->
<!-- <!--   ANALYSIS: --> -->
<!-- <!--     type = mixture; --> -->
<!-- <!--     starts= 250 50; --> -->
<!-- <!--   MODEL: --> -->
<!-- <!--   %overall% --> -->
<!-- <!--   %C#1% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#2% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#3% --> -->
<!-- <!--   [v1-v10]; --> -->


<!-- <!--                             13 --> -->
<!-- <!-- !! 3-class model --> -->
<!-- <!--   DATA: file='dat1.dat'; --> -->
<!-- <!--   VARIABLE: --> -->
<!-- <!--     names=id v1-v10; --> -->
<!-- <!--     usevariables= v1-v10; --> -->
<!-- <!--     classes = c(4); --> -->
<!-- <!--   ANALYSIS: --> -->
<!-- <!--     type = mixture; --> -->
<!-- <!--     starts= 250 50; --> -->
<!-- <!--   MODEL: --> -->
<!-- <!--   %overall% --> -->
<!-- <!--   %C#1% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#2% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#3% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- <!--   %C#4% --> -->
<!-- <!--   [v1-v10]; --> -->
<!-- Each of the models was fitted with multiple initial stage random starts and multiple final -->
<!-- stage optimizations to reduce the risk of finding solutions on a local maximum. For the 1-6 -->
<!-- class models, 250 iniitial and 50 final starts were used. For the 7-class model 1000 initial -->
<!-- starts and 200 final optimizations were used and for the 8- and 9-class models, a replicable -->
<!-- global solution could only be obtained with 5000 initial stage starts and 1000 final stage -->
<!-- optimizations. The fit indices for each of the fitted models is displayed in the table below. -->
<!-- For now, we only look at the estimated fit indices. -->
<!--                 EEI models -->
<!--  Classes   AIC       BIC -->
<!--  1         14587.535 14587.535 -->
<!--  2         13160.836 13275.653 -->
<!--  3         11986.551 12142.11 -->
<!--  4         11957.71  12154.01 -->
<!--  5         11951.766 12188.808 -->
<!--  6         11944.632 12222.415 -->
<!--  7         11935.501 12254.027 -->
<!--  8         11929.428 12288.695 -->
<!--  9         11925.203 12325.212 -->
<!-- If we compare the BIC values for the EEI models to those obtained with ‘mclust’ directly -->
<!-- and via ‘tidyLPA’, we can see that the results are quite similar for the less complex models, -->
<!-- with the BIC-values for the 2- and 3-class models being exactly the same in terms of their -->
<!-- absolute values. When taking a closer look at the 3-class model that was previously found to -->
<!-- be the best model, we can also see that that the Mplus-based classifications (n=100, n=110, -->
<!-- and n=90) and entropy estimates (entropy=1.0) are similar to those obtained with ‘mclust’ -->

<!--                                              14 -->
<!-- and/or ‘tidyLPA’. -->
<!--  If we look at the larger picture and evaluate the overlap between the BIC values obtained -->
<!--  for all models with class numbers ranging from 1 to 9, we can see that the estimated BIC -->
<!-- values show more differences between the R-packages and Mplus for the models with larger -->
<!--  numbers of classes. This can be explained by the different methods used by Mplus and -->
<!-- ‘mclust’/’tidyLPA’ to generate the start values for estimation (see below). These differences -->
<!--  can cause the packages to yield different results for more complex models and/or models that -->
<!--  are increasingly misspecified (as the models with more than 3 classes were in our example). -->

<!-- 6. Final comments -->
<!-- In this tutorial we have seen that it is relatively easy to run an LPA in R. As with all -->
<!-- data-driven analyses, care should be taken not to over-interpret the results. In the end, LPA -->
<!-- identifies classes in such a way as to optimally explain variance on a range of variables and -->
<!-- not to optimize interpretability or usefulness. -->
<!-- Another remark with regard to LPA results is that class-membership is probabilistic in nature: -->
<!-- each subject in an analyzed sample has a probability of being in each of the model’s classes. -->
<!-- Subjects can be allocated to a class based on their highest class-probability. Importantly, -->
<!-- this can only be done with enough certainty if separation between classes is sufficient, which -->
<!-- means that we see that each subject has a clear highest probability (e.g., p=0.9) for one of -->
<!-- the classes. The entropy statistic is often used to quantify this separation, with values <0.8 -->
<!-- being taken to indicate insufficient separation to allocate subjects to one class. In such cases, -->
<!-- the class probabilities themselves can still be used in further investigations. -->
<!-- Depending on one’s preferences, one can choose either the ‘mclust’ or the ‘tidyLPA’ package. -->
<!-- The latter may be especially attractive for persons that already have experience with Mplus -->
<!-- or comparable software. It is important to note, though, that differences exist between the -->
<!-- estimation approaches taken by both R-packages and by Mplus. -->
<!-- Mixture models such as LPA need to be estimated in an iterative fashion, using an EM -->
<!-- algorithm that is very sensitive to the used start values, where poor start values can lead the -->
<!-- estimation process to a poor solution. In addition, there is often a chance that the iterative -->
<!-- EM process leads to a solution that is at a local, rather than a global maximum in the -->
<!-- likelihood ‘landscape’. -->

<!-- ### Starting values -->
<!-- Different methods have been developed to initialize the estimation (get starting values) in -->
<!-- such a way as to optimize the chance of arriving at an accurate model solution (Biernacki et -->
<!-- al., 2003; Shireman et al., 2016). Mplus and ‘mclust’ take two different approaches. Mplus -->
<!-- uses a ‘brute force’ approach and reruns the model with multiple sets of random start values, -->
<!-- each generated from uniform distributions of values with ranges that are based on the data -->
<!-- (Muthén & Muthén, 1998-2015). The best solution is the model with the highest log likelihood -->
<!-- that was arrived upon from at least two different starting points. In contrast, ‘mclust’ uses -->
<!-- the data itself to generate a set of plausible start values using hierarchical clustering. This -->
<!-- means that the start values are informed by the (hierarchical structure of) the data, which -->
<!-- can work well. A downside is that only a single set of start values is used, so the risk of -->
<!-- arriving at a local optimum is not addressed. These approaches show clear differences and -->
<!-- have been shown previously to not always arrive at the same solutions, with some authors -->
<!-- being especially critical of the ‘mclust’ approach (Shireman et al., 2017). In our example, -->
<!-- we did not see much difference between the two approaches, but it should be noted that -->
<!-- many real-world data sets do not have such a clear latent structure, making it much more -->
<!-- challenging to arrive at an accurate solution, given the data. -->
<!-- Based on the provided examples and these technical differences between ‘mclust’ and Mplus, -->
<!-- it is probably better to see ‘mclust’ and ‘tidyLPA’ as useful alternatives for Mplus, rather -->
<!-- than as tools to exactly mimic what can be done with the latter software. -->


<!-- References -->
<!-- Banfield, J., Raftery, A.E. (1993). Model-based Gaussian and non-Gaussian clustering. -->
<!-- Biometrics. 49: 803–821. -->
<!-- Biernacki,C.,Celeux,G., Govaert,G.(2003).Choosing starting values for the EM algorithm -->
<!-- for getting the highest likelihood in multivariate Gaussian mixture models. Computational -->
<!-- Studies and Data Analysis, 41, 561–575. -->
<!-- Celeux, G., Govaert, G. (1995) Gaussian parsimonious clustering models. Pattern Recognition. -->
<!-- 28:781–793 -->
<!-- Fraley, C., Raftery, A.E. (1998) How many clusters? Which clustering method? Answers via -->
<!-- model-based cluster analysis. The Computer Journal 41: 578-588. -->
<!-- Gibson, W. A. (1959). Three multivariate models: Factor analysis, latent structure analysis, -->
<!-- and latent profile analysis. Psychometrika, 24, 229–252. -->
<!-- Linzer, D.A., Lewis J. (2011). “poLCA: an R Package for Polytomous Variable Latent Class -->
<!-- Analysis.” Journal of Statistical Software. 42(10): 1-29 -->
<!-- Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., Leisch, F. (2019). e1071: Misc -->
<!-- Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU -->
<!-- Wien. R package version 1.7-3. https://CRAN.R-project.org/package=e1071 -->
<!-- Muthén, L., Muthén, B., 1998–2015. Mplus User’s Guide, 7th ed., Muthén & Muthén, Los -->
<!-- Angeles. -->
<!-- Neale, M.C., Hunter, M.D., Pritikin, J.N., Zahery, M., Brick, T.R., Kirkpatrick, R.M., -->
<!-- Estabrook, R., Bates, T.C., Maes, H.H., Boker, S.M. (2016). “OpenMx 2.0: Extended -->
<!-- structural equation and statistical modeling.” Psychometrika 81(2): 535-549. -->
<!-- Nylund-Gibson, K., Choi, A. Y. (2018). Ten frequently asked questions about latent class -->
<!-- analysis. Translational Issues in Psychological Sciences, 4, 440–461. -->
<!-- Oberski, D. (2016). Mixture models: Latent profile and latent class analysis. In J. Robertson -->
<!-- & M. Kaptein (Eds.), Modern statistical methods for HCI (pp. 275–287). Cham, Switzerland: -->
<!-- Springer Inter-national Publishing. -->



<!--                                              16 -->
<!-- Pastor, D.A., Barron, K.E., Miller, B.J., Davis, S.L. (2007). A latent profile analysis of -->
<!-- college students’ achievement goal orientation. Contemporary Educational Psychology 32(1): -->
<!-- 8-47. -->
<!-- Rosenberg, J.M., Beymer, P.N., Anderson, D.J., Van Lissa, C.J., & Schmidt, J.A. (2018). -->
<!-- tidyLPA: An R Package to Easily Carry Out Latent Profile Analysis (LPA) Using Open-Source -->
<!-- or Commercial Software. Journal of Open Source Software 3(30): 978. -->
<!-- Scrucca, L., Fop M., Murphy, T.B., Raftery A.E. (2016) mclust 5: clustering, classification -->
<!-- and density estimation using Gaussian finite mixture models The R Journal 8/1: 289-317. -->
<!-- Shireman, E. M., Steinley, D., & Brusco, M. J. (2016). Local Optima in Mixture Modeling. -->
<!-- Multivariate Behavioral Research 51(4): 466–481. -->
<!-- Shireman, E., Steinley, D., Brusco, M.J. (2017). Examining the effect of initialization -->
<!-- strategies on the performance of Gaussian mixture modeling. Behavioral Research Methods -->
<!-- 49(1):282-293. -->
<!-- Sterba, S.K. (2013). Understanding Linkages Among Mixture Models. Multivariate Behav -->
<!-- Res. 2013 48(6): 775-815. -->
<!-- Wolfe, J. (1970). Pattern clustering by multivariate mixture analysis. Multivariate Behavioral -->
<!-- Research, 5: 329–350. -->


<!-- Shireman 2016: -->
<!-- https://www.tandfonline.com/doi/full/10.1080/00273171.2016.1160359?casa_token=YMvI52JWPq0AAAAA%3A20nlLRukoCkUmIil2lRWnsUS-33AlU6HmDRGsu07aJ0nTzS-skjvHnroJBtBVHM5HE0X8iStM1eyqw -->

<!-- mixture models have two possible uses: either (a) classifying observations into groups through the estimation of distinct, underlying distributions or (b) using a set of well-defined parametric distributions (often times the Gaussian distribution) to approximate a messy data space that cannot be approximated by standard models that assume a single distribution (whether univariate or multivariate). While both are legitimate uses of mixture modeling, the only necessary and sufficient condition for fitting a mixture model is nonnormality in the data (see Bauer & Curran, 2003). It is certainly true that if there are distinct groups arising from distinct distributions, it is necessary to have a set of parameters to model each of those groups. Unfortunately, it may often be the case (in fact, it is probably likely) we are in the converse situation where the full data space is either nonlinear, asymmetric, or both, and there exist no distinct groups in the population. In this case, the mixture model is capturing the departure from “clean” structure, but the groups themselves are not meaningful in the sense that they are giving rise to distinct subpopulations. As such, their boundaries are going to be amorphous, and their parameters, regardless of their stability, lose meaning in terms of reflecting an underlying data-generative mechanism, making the interpretation of the means, covariances, or a specific individuals' membership an exercise in folly. Obviously, knowing which situation a data set falls in is paramount, and using the prevalence of local optima as a potential indicator is a crucial first step. -->




<!-- The optimal number of latent classes (i.e. identity configurations) was determined using the BIC (Fraley & Raftery, 1998); with lower values indicating a better statistical fit. Solutions were considered to be admissible if they consisted of at least 5% of the sample (Depaoli, 2013), if the entropy (a measure of class separability) exceeded .8 (Wang, Deng, Yang, 2017), and if the solution was theoretically interpretable and qualitatively distinct from the other class solutions (Howard & Hoffman, 2018). -->
