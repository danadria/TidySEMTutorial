---
title: "LCA in R using tidySEM"
output: html_notebook
---

# LOADING THE DATASET

```{r}
library(tidySEM) 
df <- data_mix_ordinal #ask Caspar to rename the dataset in documentation
df[1:4] <- lapply(df, ordered)
```

# Exploring the data

```{r}
tidySEM::descriptives(df)
```

# 1 class solution

```{r}
# fitting the model
set.seed(123)
mx_lca(data = df, classes = 1) -> res_1_class
```

```{r}
# printing model fit table
print(table_1_class <- tidySEM::table_fit(res_1_class))
```

```{r}
# obtain latent class probabilities
LC_Probabilities_1_class <- tidySEM::class_prob(res_1_class)
print(LC_Probabilities_1_class[1:4])
```
```{r}
# conditional item probabilities
tidySEM::table_prob(res_1_class)
```

# 2 class solution

```{r}
# fitting the model
set.seed(123)
mx_lca(data = df, classes = 2) -> res_2_class
```

```{r}
# printing model fit table
print(table_2_class <- tidySEM::table_fit(res_2_class))
```

```{r}
# obtain latent class probabilities
LC_Probabilities_2_class <- tidySEM::class_prob(res_2_class)
print(LC_Probabilities_2_class[1:4])
```
```{r}
# conditional item probabilities
tidySEM::table_prob(res_2_class)
```


# 3 class solution

```{r}
# fitting the model
set.seed(123)
mx_lca(data = df, classes = 3) -> res_3_class
```

```{r}
# printing model fit table
print(table_3_class <- tidySEM::table_fit(res_3_class))
```

```{r}
# obtain latent class probabilities
LC_Probabilities_3_class <- tidySEM::class_prob(res_3_class)
print(LC_Probabilities_3_class[1:4])
```
```{r}
# conditional item probabilities
tidySEM::table_prob(res_3_class)
```

# 4 class solution

```{r}
# fitting the model
set.seed(123)
mx_lca(data = df, classes = 4) -> res_4_class
```

```{r}
# printing model fit table
print(table_4_class <- tidySEM::table_fit(res_4_class))
```

```{r}
# obtain latent class probabilities
LC_Probabilities_4_class <- tidySEM::class_prob(res_4_class)
print(LC_Probabilities_4_class[1:4])
```
```{r}
# conditional item probabilities
tidySEM::table_prob(res_4_class)
```

Comparing model fit

```{r}
print("BIC")
print(c("1 class", table_1_class$BIC))
print(c("2 class", table_2_class$BIC)) #lowest
print(c("3 class", table_3_class$BIC))
print(c("4 class", table_4_class$BIC))
```
```{r}
print("AIC")
print(c("1 class", table_1_class$AIC))
print(c("2 class", table_2_class$AIC))
print(c("3 class", table_3_class$AIC))
print(c("4 class", table_4_class$AIC)) #lowest
```

```{r}
print("Entropy")
print(c("1 class", table_1_class$Entropy)) # entropy = 1 
print(c("2 class", table_2_class$Entropy))
print(c("3 class", table_3_class$Entropy)) # highest
print(c("4 class", table_4_class$Entropy))
```


Using the Bootstrapped Likelihood Ratio Test to compare models

```{r}
tidySEM::BLRT()
```






















# APPENDIX

USING DIFFERENT PACKAGES


This is an example of a Latent Class Analysis (LCA).

In Part 1, I use the Lazarsfeld dataset and OpenMX.
In Part 2, I use the Drinking dataset and OpenMx.
In Part 3, I redo the analysis from Part 2 using tidySEM.

```{r}
library(tidySEM)
library(OpenMx)
```

Part 1: LCA using OpenMx and Lazarsfeld Dataset 

Analysis based on: https://rdrr.io/cran/OpenMx/src/inst/models/passing/LCAlazarsfeld.R

```{r}
data("lazarsfeld", package ="OpenMx", verbose= TRUE)
data <- lazarsfeld

freq <- data[,5]
data[,1] <- as.ordered(data[,1])
data[,2] <- as.ordered(data[,2])
data[,3] <- as.ordered(data[,3])
data[,4] <- as.ordered(data[,4])
vars <- data[,1:4]

nclass <- 2
nvar <- 4
nthresh <- 1

nameList <- names(vars)

class1 <- mxModel("Class1", 
            mxMatrix("Iden", name = "R", nrow = nvar, ncol = nvar, free=FALSE),
            mxMatrix("Full", name = "M", nrow = 1, ncol = nvar, free=FALSE),
            mxMatrix("Full", name = "ThresholdsClass1", nrow = 1, ncol = nvar, 
            	dimnames = list("Threshold",nameList), free=TRUE),
		  mxExpectationNormal(covariance="R", means="M", dimnames=nameList, 
				      thresholds="ThresholdsClass1"),
		  mxFitFunctionML(vector=TRUE))

class2 <- mxModel("Class2", 
            mxMatrix("Iden", name = "R", nrow = nvar, ncol = nvar, free=FALSE),
            mxMatrix("Full", name = "M", nrow = 1, ncol = nvar, free=FALSE),
            mxMatrix("Full", name = "ThresholdsClass2", nrow = 1, ncol = nvar, 
            	dimnames = list("Threshold",nameList), free=TRUE),
		  mxExpectationNormal(covariance="R", means="M", dimnames=nameList,
				      thresholds="ThresholdsClass2"),
		  mxFitFunctionML(vector=TRUE))

# Define the model

lcamodel <- mxModel("lcamodel", class1, class2, mxData(vars, type="raw"), 
            
# Create class membership probabilities, constrain them to be in the range 0-1, and make their sum equal 1.0
            mxMatrix("Full", name = "ClassMembershipProbabilities", nrow = nclass, ncol = 1, free=TRUE, 
			        labels = c(paste("pclass", 1:nclass, sep=""))),
            mxBounds(c(paste("pclass", 1:nclass, sep="")),0,1),
		    mxMatrix("Iden", nrow = 1, name = "constraintLHS"),
		    mxAlgebra(sum(ClassMembershipProbabilities), name = "constraintRHS"),
            mxConstraint(constraintLHS == constraintRHS),

# Define the objective function
            mxAlgebra(-2*sum(freq * log(pclass1%x%Class1.objective + pclass2%x%Class2.objective)), 
            	name="lca"),
            mxFitFunctionAlgebra("lca")
)

# Run the job
model <- mxRun(lcamodel, suppressWarnings=TRUE)
summary(model)
model$matrices


# Check results against those hard-coded from old Mx:
negativeThresholds <- as.vector(mxEval(Class1.ThresholdsClass1, model))
positiveThresholds <- as.vector(mxEval(Class2.ThresholdsClass2, model))
if (negativeThresholds[[1]] > 0) {
	temp <- negativeThresholds
	negativeThresholds <- positiveThresholds
	positiveThresholds <- temp
}

omxCheckCloseEnough(negativeThresholds, c(-1.3247, -0.2909, -0.1466, -0.0044),.01)
omxCheckCloseEnough(positiveThresholds, c(0.1805, 0.9071, 1.3169, 1.5869),.01)
omxCheckCloseEnough(sort(as.vector(mxEval(ClassMembershipProbabilities, model))), c(0.4440, 0.5560),.01)
omxCheckCloseEnough(model$output$Minus2LogLikelihood, 4696.444, 0.01)
```

Part 2: LCA Using OpenMx and Drinking Dataset, 

Dataset from: https://stats.oarc.ucla.edu/sas/dae/latent-class-analysis/

```{r}
data <- read.csv('C:/Users/danie/OneDrive/Desktop/LCA/drinking_data.csv', header = T, sep = ',')

#check if two rows have the same response pattern
library(DAKS)
pattern(data)

dat1 <- c(1,0,0,0,0,0,0,0,0, 126)
dat2 <- c(0,0,0,0,0,0,0,0,0, 102)
dat3 <- c(1,0,0,0,0,0,0,0,1, 47)
dat4 <- c(1,1,0,0,0,0,0,0,0, 47)
dat5 <- c(1,0,0,0,0,1,0,0,0, 43)
dat6 <- c(126, 102, 47, 47, 43)

dat <- data.frame(dat1,dat2,dat3,dat4,dat5)
dat <- t(dat)
dat <- as.data.frame(dat)
names(dat) <- c("Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9", "freq")
rm("data", "dat1", "dat2", "dat3", "dat4", "dat5", "dat6")

dat[,1] <- as.ordered(dat[,1])
dat[,2] <- as.ordered(dat[,2])
dat[,3] <- as.ordered(dat[,3])
dat[,4] <- as.ordered(dat[,4])
dat[,5] <- as.ordered(dat[,5])
dat[,6] <- as.ordered(dat[,6])
dat[,7] <- as.ordered(dat[,7])
dat[,8] <- as.ordered(dat[,8])
dat[,9] <- as.ordered(dat[,9])



freq <- dat[,10]
vars <- dat[,1:9]

nclass <- 2
nvar <- 9
nthresh <- 1
nameList <- names(vars)

class1 <- mxModel("Class1", 
                  mxMatrix("Iden", name = "R", nrow = nvar, ncol = nvar, free=FALSE),
                  mxMatrix("Full", name = "M", nrow = 1, ncol = nvar, free=FALSE),
                  mxMatrix("Full", name = "ThresholdsClass1", nrow = 1, ncol = nvar, 
                           dimnames = list("Threshold",nameList), free=TRUE),
                  mxExpectationNormal(covariance="R", means="M", dimnames=nameList, 
                                      thresholds="ThresholdsClass1"),
                  mxFitFunctionML(vector=TRUE))

class2 <- mxModel("Class2", 
                  mxMatrix("Iden", name = "R", nrow = nvar, ncol = nvar, free=FALSE),
                  mxMatrix("Full", name = "M", nrow = 1, ncol = nvar, free=FALSE),
                  mxMatrix("Full", name = "ThresholdsClass2", nrow = 1, ncol = nvar, 
                           dimnames = list("Threshold",nameList), free=TRUE),
                  mxExpectationNormal(covariance="R", means="M", dimnames=nameList,
                                      thresholds="ThresholdsClass2"),
                  mxFitFunctionML(vector=TRUE))

# Define the model

lcamodel <- mxModel(model = "lcamodel", class1, class2, mxData(vars, type="raw")) 

# Create class membership probabilities, constrain them to be in the range 0-1, and make their sum equal 1.0
mxMatrix("Full", name = "ClassMembershipProbabilities", nrow = nclass, ncol = 1, free=TRUE, labels = c(paste("pclass", 1:nclass, sep=""))) 
mxBounds(c(paste("pclass", 1:nclass, sep="")),0,1) 
mxMatrix("Iden", nrow = 1, name = "constraintLHS") 
mxAlgebra(sum(ClassMembershipProbabilities), name = "constraintRHS") 
mxConstraint(constraintLHS == constraintRHS)

# Define the objective function
mxAlgebra(-2*sum(freq * log(pclass1%x%Class1.objective + pclass2%x%Class2.objective)), name="lca")

mxFitFunctionAlgebra("lca")

# Run the job
model <- mxRun(lcamodel, suppressWarnings=TRUE)
summary(model)
model$matrices                  

# Check results against those hard-coded from old Mx:
negativeThresholds <- as.vector(mxEval(Class1.ThresholdsClass1, model))
positiveThresholds <- as.vector(mxEval(Class2.ThresholdsClass2, model))
if (negativeThresholds[[1]] > 0) {
  temp <- negativeThresholds
  negativeThresholds <- positiveThresholds
  positiveThresholds <- temp
}

```


Part 3: LCA using tidySEM

```{r}
#adjust this code
# The argument `classes` indicates which class solutions should be estimated (e.g., 1 through 6).
# The argument `variances` specifies whether variances should be `"equal"` or `"varying"` across classes.
# The argument `covariances` specifies whether covariances should be constrained to `"zero"`, `"equal"` or `"varying"` across classes.
tidySEM::mx_profiles(classes, variances, covariances)
```

After all models have been estimated, the function `tidySEM::table_fit()` can be used to obtain a model fit table suitable for determining the optimal model according to best practices.
Note however that this table does not include the bootstrapped likelihood ratio test (BLRT) by default,
because this test is very computationally expensive.
It is recommended to use the function `tidySEM::BLRT()` to compare a shortlist of likely candidate models based on other fit indices.
