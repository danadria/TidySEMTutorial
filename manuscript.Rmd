---
title             : "Best Practices in Latent Class Analysis using Free Open Source Software"
shorttitle        : "BEST PRACTICES LATENT CLASS ANALYSIS"
author: 
  - name          : "Caspar J. van Lissa"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Padualaan 14, 3584CH Utrecht, The Netherlands"
    email         : "c.j.vanlissa@gmail.com"
  - name          : "Mauricio Garnier-Villarreal"
    affiliation   : "3"
    corresponding : no   
    email         : "m.garniervillarreal@vu.nl"
  - name          : "Daniel Anadria"
    affiliation   : "1"
    corresponding : no
    address       : "Padualaan 14, 3584CH Utrecht, The Netherlands"
    email         : "d.anadria@uu.nl"
affiliation:
  - id            : "1"
    institution   : "Utrecht University, Methodology & Statistics"
  - id            : "2"
    institution   : "Open Science Community Utrecht"
  - id            : "3"
    institution   : "Vrije Universiteit Amsterdam, Sociology"
author_note: |
  Methodology & Statistics
  Padualaan 14
  3582CH Utrecht, The Netherlands
abstract: |
  Latent class analysis refers to a family of techniques for identifying groups
  in data based on a parametric model.
  Examples include mixture models, latent class analysis with ordinal
  indicators, and latent class growth analysis.
  Despite the popularity of this technique, there is limited
  guidance with respect to best practices in estimating and reporting mixture
  models. Moreover, although user-friendly interfaces for advanced mixture
  modeling have long been available in commercial software packages, open
  source alternatives have remained somewhat inaccessible. This tutorial
  describes best practices for the estimation and reporting of latent class analysis,
  using free and open source software in R. To this end, this tutorial
  introduces new functionality for estimating and reporting mixture
  models in the `tidySEM` R-package whose backend relies on `OpenMx`.
keywords          : "latent class analysis, mixture models, best practices, free open source software, tidySEM"
wordcount         : "9001"
bibliography      : "mixture.bib"
figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no
class             : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
---

```{r load_packages, include = FALSE}
library("papaja")
#bibliography      : ["r-references.bib"]
library(worcs)
run_everything = FALSE
```

Latent class analysis (LCA) is an umbrella term that refers to a number
of techniques for estimating unobserved group membership based on a
parametric model of one or more observed indicators of group membership.
The types of LCA have become quite popular across scientific fields,
most notably finite Gaussian mixture modeling and latent profile
analysis. @vermunt_latent_2004 defined LCA more generally as
virtually any statistical model where "some of the parameters [...]
differ across unobserved subgroups".

Despite its popularity, there is a lack of standards for estimating and
reporting LCA. While @van_de_schoot_grolts-checklist_2017 developed
reporting guidelines for a specific type of LCA known as latent growth
models, general reporting guidelines for best practices in LCA are still
lacking.
This introduces a risk of misapplications of the technique,
and complicates manuscript review and assessment of the quality of published studies.
The present paper seeks to address this gap in the literature by introducing updated guidelines for estimation and reporting on latent class analysis,
based on current best practice. 
Importantly, in order to lower the barrier of entry to latent class analysis
and ensure reproducibility of all examples,
this paper exclusively uses free, open source software for latent class analysis in R.
To this end, new functionality was developed in the R-package `tidySEM` [@vanlissaTidySEMTidyStructural2022].

## Defining Latent Class Analysis

Latent class analysis is a group of methods for estimating unobserved
groups based on a parametric model of observed indicators of group
membership [@vermuntLatentClassAnalysis2004].
This method has become quite popular across scientific fields,
under a number of different names;
most notably (finite Gaussian) mixture modeling and latent profile analysis.
The concept of LCA can be understood in different ways.
Generally speaking, LCA assumes that the study population is composed of $K$
subpopulations.
It further assumes that the observed data are
a mixture of data originating from those subpopulations;
hence the name mixture model.
Consider the simplest possible
univariate "model", which is a normal distribution.
This model has
two parameters: the mean and the variance.
LCA aims to estimate the values of those parameters across a known number of classes $K$,
as well as the probability of every individual $i$ belonging to classes $1 \ldots k$.
Commonly, the same model is estimated across all classes,
but with different parameters for each class (i.e., class-specific means and variances).

As an illustrative example, imagine that a detective wants to know if it
would be possible to use mixture modeling to identify the sex of a
suspect, based on footprints found at the crime scene. To test the
feasibility of this approach, the detective records the shoe sizes and
sex of 100 volunteers. The resulting observed data look like this:

```{r echo = FALSE}
library(tidySEM)
library(ggplot2)
set.seed(1)
n = 100
C <- sample(c("Man", "Woman"), n, replace = TRUE)
means <- c(Man = 9, Woman = 7)
X <- rnorm(n, mean = means[C], sd = 1)
X <- round(X*2)/2
obsparam <- tapply(X, C, mean)
shoesize_shapiro <- shapiro.test(X) # Shapiro-Wilk test of normality
```

```{r echo = FALSE, eval = run_everything}
est <- mx_profiles(data.frame(X), 2)
estparam <- table_results(est, c("label", "est", "matrix"))
estparam <- as.numeric(estparam$est[estparam$matrix == "M"])
props <- class_prob(est, "individual")$individual[ , "predicted"]
dput(props, "props.txt")
dput(estparam, "estparam.txt")

p <- ggplot(data.frame(Shoesize = X), aes(x = Shoesize)) + geom_density() + theme_bw()
ggsave("shoedens.png", p, device = "png")
```

```{r shoedens, echo = FALSE, fig.cap="Kernel density plot of shoe sizes."}
props <- eval(parse("props.txt"))
estparam <- eval(parse("estparam.txt"))
knitr::include_graphics("shoedens.png")
```

The distribution is evidently bimodal, which bodes well for the intended
mixture model. In this case, the number of classes is known a-priori.
When estimating a two-class mixture model, the detective observes that
the model estimates the mean shoe size of the two groups are equal to
`r report(estparam[1], equals = FALSE)` and
`r report(estparam[2], equals = FALSE)`, which is close to the true
means of the two groups, namely `r report(obsparam[1], equals = FALSE)`
and `r report(obsparam[2], equals = FALSE)`. When tabulating estimated
group membership against observed (known) group membership, it can be
seen that women are classified with a high degree of accuracy, but men
are not:

```{r tabshoe, results="asis"}
library(kableExtra)
tab <- table(C, props)
tab <- data.frame(Observed = rownames(tab), as.data.frame.array(tab))
names(tab)[2:3] <- c("Class 1", "Class 2")
rownames(tab) <- NULL
kbl(tab, caption = "Observed group membership by estimated class membership.")
```

Another way to conceptualize LCA is by analogy to a measurement model in structural equation modeling [@molenaarArbitraryNatureLatent1994].
A mixture model is like confirmatory factor analysis,
except with a categorical instead of a continuous latent variable.
One difference between
the two techniques is that factor analysis can be considered as a way to
group observed *variables* into latent constructs, and LCA groups
*individuals* into classes.
While factor analysis seeks to describe the relations between variables,
LCA seeks to describe unobserved groups and classify individual observations to those groups.
In line with this distinction, LCA
(mixture models) is referred to as a "person-centered" technique, and
factor analysis as a "variable-centered" technique
[@nylund-gibson_ten_2018; @masyn_latent_2013].

When the focus is on the model parameters in each group, LCA can be
thought of as similar to a multi-group structural equation model. The
main distinction is that group membership is not known a-priori, but is
instead estimated -- with measurement error -- based on the data.
Whereas in a multi-group model, the data are split by group and treated
as independent samples, in LCA, all cases contribute to the estimation
of all parameters in all groups. The relative contribution of each case
to the parameters of each group is determined by that case's posterior
probability of belonging to that group.

In factor analysis, the latent variable is continuous, so the relationships
between indicators are defined by the communalities between them. Here, the
latent variable represents the error corrected approximation of the
sample. In LCA, by contrast, the relation between indicators is defined by how
well they separate the classes, as a multinomial regression between the
indicators and the latent variable [@masyn_latent_2013].

When the focus is on each individual's estimated class membership,
LCA can be thought of as a type of clustering algorithm that corrects for (random) measurement error.
Specifically, the posterior class probability that an individual belongs to a latent class
can be computed from the likelihood of that individual's observed data under given the class-specific model.
These posterior class probabilities can be used to weight follow-up analyses,
or individuals can be assigned to classes based on their highest class probability.
If the classes are clearly distinct, measurement error is low, and the latter approach may be acceptable.
This perspective on mixture modeling is sometimes referred to as "model-based
clustering" [@hennig_handbook_2015; @scrucca_mclust_2016]. 
Many clustering algorithms apply some recursive splitting algorithm to the data. By
contrast "model-based" clustering refers to the fact that LCA estimates
cluster membership based on a parametric model.
Since a parametric model estimates only a fixed number of parameters,
it can be a relatively parsimonious solution compared to non-parametric techniques.

Finally, in the context of machine learning, LCA can be considered as an
*unsupervised classification* method [@figueiredo_unsupervised_2002].
The term *unsupervised* refers to the fact that the outcome variable --
true class membership -- is not known, and the term *classification*
refers to the fact that the algorithm is predicting a categorical
outcome -- class membership.

## A Taxonomy of Latent Class Analysis Methods

In this paper, we use the term latent class analysis to refer to a
family of techniques that estimate latent class membership based on a
parametric model of observed indicators. From a historical perspective,
the term was initially conceived to refer to analyses with categorical,
usually binary indicators [@vermunt_latent_2004]. Nowadays, there are
a number of related techniques, known by distinct names, that serve a
similar purpose. The term "latent class analysis" seems most appropriate
as an umbrella term for this broader class of models, as it only refers
to the purpose of the analysis, and does not imply restrictions to the
model used, or the level of measurement of the indicators. Given the
abundance of terms in use for closely related classes of models, we will
provide a rudimentary taxonomy of LCA methods.

A common type of LCA is the *finite Gaussian mixture model*; a
univariate analysis where the observed distribution of a single variable
is assumed to result from a mixture of a known number of normal
(Gaussian) distributions. The parameters of a finite Gaussian mixture
model are the means and variances of these underlying normal
distributions. The analysis of shoe sizes presented earlier is a
canonical example of this type of analysis. In the multivariate case,
with more than one indicator variable, the parameters of a mixture model
are the means, variances, and covariances between the indicators (which
can be standardized to obtain correlations). These parameters can be estimated 
freely, or set to be constrained across classes [@collins_latent_2009].

The technique known as *latent profile analysis (LPA)* is a special case
of the mixture model, which assumes conditional independence of the
indicators. Conditional independence means that, after class membership
is accounted for,
the residual covariances/correlations between indicators are
assumed to be zero.
In some cases, such constraints
will be inappropriate; for instance when the cohesion between indicators
is expected to differ between classes [@collins_latent_2009].
Consider, for example, a mixture model of ocean plastic particles, which found two classes of particles based on length and width:
A class of larger particles with a low correlation between length and width,
and a class of smaller particles with a high correlation between length and width.
The reason for this difference in correlations makes theoretical sense:
the large particles were heterogenous in shape,
whereas the smaller particles had been polished to a more uniform (rounded) shape by the elements [@alkema_maximizing_2022].

It is also possible to estimate a mixture model based on latent
indicators. This means that, within each class, one or more continuous
latent variables are estimated based on the observed indicators.
Categorical latent variable membership is then estimated based on these
continuous latent variables. A common application of this approach is in
longitudinal research, where the indicators reflect one construct
assessed at different time points. Examples of this approach include
*growth mixture models* (GMM) and *latent class growth analyses* (LCGA) 
[@jung_introduction_2008]. These techniques estimate a latent growth model 
to describe grouped trajectories over time. The growth mixture model is a 
latent class model where the parameters that indicate class membership are the 
intercepts and variances, and typically covariances of the latent growth 
variables, e.g., a latent intercept and slope. This technique assumes that
individuals within a class can have heterogenous trajectories. If the
variance of the growth parameters is fixed to zero, it is known as a
latent class growth analysis. This latter approach assumes that all
individuals within a class share the same identical trajectory, and that
any variance in the indicators not explained by the class-specific
latent trajectories is due to residual error variance.

The term latent class analysis originally referred to cases where the
observed indicators were ordinal (ordered categorical) [@collins_latent_2009]. 
Nowadays, it is more commonly used
as an umbrella term. To prevent ambiguity, the special case where
indicators are of binary or ordinal measurement level might be described
as *latent class analysis with ordinal indicators*.

<!-- Although this paper primarily focuses on latent class analysis with continuous indicators, -->
<!-- most of the suggested guidelines are equally applicable to ordinal indicators. -->

## Use Cases for Latent Class Analysis

There are several use cases for which LCA methods are suitable. 

### Testing theory

Although latent class analysis is often discussed as an exploratory analysis technique,
it can also be used in a confirmatory manner.
Given that latent class analysis is similar to confirmatory factor analysis,
but with a categorical latent variable, it can be used to similar ends:
To assess whether a theoretical measurement model holds.
This use case is relevant when testing a theory that postulates the existence of a categorical latent variable.
For example, *identity status theory* posits that, at any given point in time, adolescents reside in one of four identity statuses [@marcia_development_1966].
LCA can be used to identify these four statuses based on observed indicators (e.g., self-reported identity exploration and commitment) [@luyckxDevelopmentalTypologiesIdentity2008].
Similarly, *personality type theory* states that dimensional differences in personality can largely be explained by an undercontrolled, overcontrolled, and resilient type, which could also be restored using LCA [@donnellanResilientOvercontrolledUndercontrolled2010].
One challenge is that, unlike confirmatory factor analysis, LCA does not provide absolute fit indices.
Thus, to test a theory, one can ascertain that the data are better described by the number of classes dictated by theory than by a different number of classes.
Furthermore, it would be possible to test whether the observed pattern of class-specific means corresponds to a hypothesized pattern;
either qualitatively or quantitatively, using significance tests for pre-specified values.
A recent study by @maene_perceived_2022 applied this principle to 
test whether identities of Belgian adolescents with migration background can be 
summarized as those relating to their heritage, national and regional identity.

### Measurement model

Another use case relies on LCA's similarity to confirmatory factor analysis.
This approach is useful when class membership is measured imperfectly by several indicators.
This approach can be used to partial out measurement error and restore most likely class membership.
For example, a recent study found descrepancies between self-reported employment status and official register data. 
While it might be tempting to assume that the
register data is free of error, this has been shown to be false.
The authors used a mixture model to estimate the
"error corrected employment status" by using two indicators of the same question
and identifying random and systematic measurement error in both indicators 
[@pavlopoulos_measuring_2015].

This example also illustrates that LCA allows us to evaluate the reliability of different indicators [@geiser_is_2014].
High quality indicators will be strongly related to the
latent variable and will lead to good class separation.
A continuous indicator that discriminates well between classes will show large differences in class-specific means;
an ordinal indicator will show very high or very low conditional response probabilities for some classes but not for others.
This information can be used to select the indicators that are most diagnostic of class membership.
For an example of research on differential item functioning,
consider a study on university admission tests of Saudi Arabian students [@tsaousis_measurement_2020].
LCA revealed three
latent classes: high-, average-, and low-scorers. Subsequently, the authors
used the Multiple Indicator Multiple Causes model to identify both uniform
and non-uniform differential item functioning. The main finding was that gender
was a potential source of differential item functioning for latent class
indicators. Therefore, gender should be included as a covariate when fitting 
a LCA model in order to obtain unbiased estimates.

### Dimension reduction

LCA can also be used to reduce the dimensionality of data,
by reducing many variables to a few prototypes.
This is similar to the use of factor analysis,
with the key distinction that factor analysis accounts for linear covariance between indicators,
whereas LCA can accommodate complex - but discrete - patterns.
As this is a pragmatic application of LCA,
the existence of a true categorical latent variable is questionable (cf. the section on Testing theory).
Consequently, the results of this use case should be treated as descriptive and not "reified": i.e., the found classes should not be treated as evidence of the existence of a categorical latent variable.
The use of LCA for dimension reduction is common in longitudinal research,
where one developmental process is summarized using latent class growth analysis (LCGA),
and the resulting categories are then used as a moderator of another developmental process in a multi-group model.
For example, one study conducted a LCGA of adolescent empathy development on two dimensions of empathy and found three groups: high, average, and low empathy [@van_lissa_divergence_2015].
These groups were then used as moderator of a latent growth analysis of adolescent- and parent-reported conflict.
Results showed that the high-empathy group evidenced greater adolescent-parent agreement about the incidence of conflict than the other groups,
and that the low empathy group had more conflict with parents than the other groups.
Note that both these key findings are non-linear;
modeling them in a single-group model would be difficult.
LCGA greatly simplifies model specification and interpretation,
albeit at a cost of some loss of information and, potentially, generalizability.
<!-- Recently, @alkema_maximizing_2022 studied plastic debris in the Atlantic Ocean. -->
<!-- Prior to this study, ways to categorize ocean microplastics in terms of length, -->
<!-- width and polymer type were rather arbitrary, and assumed that these properties -->
<!-- were independent. Also, there was a lack of information regarding variability  -->
<!-- within these categories. The authors used finite Gaussian mixture modeling to  -->
<!-- build a classification system for ocean microplastic particles based on a set  -->
<!-- of measured characteristics. With regards to particle dimensions, two classes -->
<!-- emerged: one with smaller fragments whose width and height were highly  -->
<!-- correlated, and another consisting of larger fragments with low correlation  -->
<!-- between particle width and height. -->

When using ordinal indicators,
the need for dimension reduction can be especially pertinent.
For example, one study measured
fifteen dichotomous health indicators among injured military personnel [@macgregor_symptom_2021]. 
Combinatorics informs us that fifteen
dichotomous items have $2^{15}$ or $32,768$ unique symptom combinations.
However, LCA was able to reduce response patterns to five clinically meaningful latent classes.

### Class enumeration

Another use case is to explore potential heterogeneity in a population,
and to determine whether the population is comprised of latent subpopulations, and if so, how many.
The primary focus in this use case is on class enumeration.
For example, researchers suspected the existence of different risk profiles of substance use, sexual behavior, and mental health outcomes, and used LCA to determine how many such risk profiles could be distinguished [@hopfer_social_2014].
Another explored heterogeneity in the population of military service members and veterans with prior suicide attempts,
and identified two latent profiles characterized by high versus low suicide risk based on self-reported suicidal ideation and information about prior attempted methods and severity
[@gromatsky_characteristics_2022].

### Classification

Another use case is to estimate individuals' unobserved class membership based on observed indicators.
The shoe size example in Figure \@ref(fig:shoedens)
is a rudimentary illustration of this application.
In applied research, LCA is often used for classification in clinical contexts.
For example, LCA was used to determine clinical cut-off scores for diagnosing whooping cough [@baughman_mixture_2006].
Another study used LCA to not only classify the sample used to estimate the model, but also future cases [Zegwaard et al, in prep].
The study identified four types of care providers among those who supported close kin with mental health problems.
Importantly, the LCA model was embedded in an interactive app that could be used by healthcare professionals to determine the most likely class membership for new care providers, to provide more targeted support.
To obtain predicted class membership based on an existing LCA model,
the authors computed the likelihood of data from a new participant under the multivariate normal distributions estimated within all latent classes.
<!-- DA: this study is not in zotero yet, I lack information (title, authors, etc.) to enter it, @Caspar could you enter this to Zotero and adjust the in-text citation-->
These applications of LCA aid the clinical decision making process,
and help decide whether additional support is warranted,
or what type of intervention is appropriate.

### Violations of normality

Finally, LCA can be used to deal with data which violate certain
assumptions. As discussed in the shoe size example, LCA can deal with
violations of normality. In fact, LCA assumes the population
distribution is a non-normal mixture of $K$ normal distributions, and it
can recover the value of $K$, i.e. generate a $K$-class solution.
For instance, @alkema_maximizing_2022 studied ocean plastic debris. 
Plastic particle width and height are non-normally distributed. The authors 
demonstrate that the non-normal distributions of particle dimensions are
due to the measurements being a mixture composed of several particle types, 
each with its own normal distribution.

<!-- LCA and factor analysis share the approximation of an unobserved latent variable, the difference being if that variable is continuous or categorical. We encourage researchers to be agnostic about the **true** nature of the latent variable. And focus on the approach that fits the research question. -->
<!-- CJ: Why would we encourage researchers to be agnostic about the true...? -->

<!-- ### Controlling for covariates -->
<!-- CJ: I'm not sure we should call this a use case... in principle, -->
<!-- any time you're doing some kind of LCA you may want to predict group membership or predict something from group membership... -->
<!-- An extension of LCA is that containing covariates which can be used to -->
<!-- predict class membership. In this approach, we not only model the latent -->
<!-- class variable based on indicators, but we also relate the class -->
<!-- membership to other explanatory variables (@vermunt_latent_2017). An -->
<!-- example of using covariates comes from @nozadi_moderating_2016 who -->
<!-- applied LCA to identify the probability of children's membership to an -->
<!-- anxiety class. The authors tested several covariates including -->
<!-- children's age, sex, and accuracy scores. Age and sex were not found to -->
<!-- be related to the children's latent class membership, hence these -->
<!-- covariates were excluded from the analysis. Accuracy scores, however, -->
<!-- were related to probabilities of being in anxiety and attention-anxiety -->
<!-- classes. Therefore this covariate was kept as a valuable predictor. -->
<!-- Another example comes from @van_lissa_divergence_2015 who included sex  -->
<!-- as a predictor of the developmental trajectories and class membership in  -->
<!-- the previously discussed adolescent empathy development study. The rationale -->
<!-- was that adding sex as a covariate would account for known sex differences  -->
<!-- in empathy development, and lead to a model with lower bias. -->

<!-- ### Distal outcomes -->
<!-- CJ: I'm not sure we should call this a use case... in principle, -->
<!-- any time you're doing some kind of LCA you may want to predict group membership or predict something from group membership... -->
<!-- When our interest is the prediction of one or more outcomes, LCA can be used  -->
<!-- to construct latent classes as categorical predictors. @lanza_latent_2013  -->
<!-- demonstrated how LCA can be used to classify adolescents into depression  -->
<!-- classes, and subsequently these classes can be used to predict smoking, grades, -->
<!-- and delinquency. The study showed that the outcomes predicted by class  -->
<!-- membership can be binary (regular smoking), continuous (grades) or  -->
<!-- count (delinquency). In the previously discussed study of Belgian adolescent -->
<!-- identities, @maene_perceived_2022 first constructed the latent variable -->
<!-- representing different multiple identification strategies. Subsequently,  -->
<!-- the most likely class membership based on posterior class probability was -->
<!-- used as an "observed" categorical variable for prediction of depressive symptoms. -->

# Best Practices

The best practices in estimation, as outlined in Table
\@ref(tab:checkest), are rooted in existing recommendations for best
practices for estimating specific subtypes of LCA,
including latent
class growth analysis [@van_de_schoot_grolts-checklist_2017] and latent
class analysis with ordinal indicators [e.g., @nylund-gibson_ten_2018].
These were generalized to be relevant to all types of LCA, and updated
to current best practices, as explained below.
In order to aid researchers working with latent trajectory models,
@van_de_schoot_grolts-checklist_2017 developed a protocol called
Guidelines for Reporting on Latent Trajectory Studies (GRoLTS).

## Best Practices in Estimation

```{r checkest, include=TRUE}
tab_check <- data.frame(Item = c(
  "Examining Observed Data",
  "Handling Missing Data",
  "Alternative Model Specifications",
  "Software",
  "Algorithm",
  "Class Enumeration",
  "Model Fit Indices",
  "Classification Diagnostics",
  "Interpreting Class Solutions",
  "Label switching"
  
))
tab_check$`#` = paste0(1:length(tab_check$Item), ".")
kbl(tab_check[, c("#", "Item")])
```

### Examining Observed Data

Examining observed data is essential for any analysis as it may reveal
patterns and violations of assumptions that had not been considered
prior to data collection. Special attention should be paid to level of
measurement of the indicators.
Finite Gaussian mixture models (including
LPA) are only suitable for continuous variables.
Indicators with an
ordinal level of measurement are likely to violate the assumption of
within-class normal distributions of mixture models [see
@vermunt_k-means_2011].
Personal experience consulting on LCA methods
and moderating the `tidyLPA` Google group suggest that the
misapplication of mixture models to ordinal (e.g., Likert-type)
indicators is the most common source of user error. Whereas it has been
argued that some parametric methods are robust when scales with 7+
response categories are treated as continuous [e.g., @norman_likert_2010],
it is very unlikely
that an ordinal variable can be modeled as a *mixture* of multiple
normal distributions.
To illustrate the problem, consider what happens when estimating a 5-class solution on a 5-point Likert scale.
Each class-specific mean could describe a single response
category,
and a class-specific variance component would be nonsensical.
In sum, Likert-type scales are rarely suitable for Gaussian mixture modeling;
latent class analysis with ordinal indicators is more appropriate.

Extensive descriptive statistics (including the number of unique values,
variance of categorical variables, and missingness; see next subsection)
can be obtained using `tidySEM::descriptives(data)`. Note,
however, that sample-level descriptive statistics are of limited value
when the goal of a study is to identify subsamples using latent class
analysis. Plots (density plots for continuous variables, and bar charts
for categorical ones) may be more diagnostic. Note that density plots
can also aid in the choice of the number of classes, as further
explained in the section on visualization. Descriptive statistics and
plots can be relegated to online supplements, provided that these are
readily accessible [consider using a GitHub repository as a
comprehensive public research archive, as explained in
@van_lissa_worcs_2021].

### Data preprocessing
 
LCA can accommodate variables of different measurement levels: continuous, binary, nominal, and ordinal.
Numeric variables should have an interval measurement level,
such that it is sensible to estimate means and (co)variances.
Note that this assumption is likely violated for Likert-type scales.
For the remaining three measurement levels,
some data preprocessing is required.
The exact data types accepted by `tidySEM` at the time of writing are `numeric` and `ordered`.
To correctly specify ordered variables,
such as Likert scales
use the function `OpenMx::mxFactor()`.
Binary variables,
such as presence or absence of some symptom, are also treated as ordinal.
Finally, nominal variables are converted to binary indicators of group membership via dummy coding, for example, using `mx_dummies()`.

A second consideration in data preprocessing is that models with indicators on different scales may present with convergence issues.
The reason for this is that the parameter space is high-dimensional with many potential local optima.
If one indicator is on a much larger scale than another, the parameter space may be more extensively explored for that parameter.
The problem can be resolved by transforming the indicators to place them on (roughly) similar scales.
The most common transformation is standardization, which involves subtracting the mean of each variable from each value and dividing by the standard deviation.
In R, this transformation is applied using the `scale()` function.
Standardization retains all available information,
and model parameters can be transformed back to the original scale of the indicators by reversing the transformation.
The transformed variable has a mean of zero and a standard deviation of one.
Note that standardization is typically not necessary if indicators are already on the same, or similar, scales.


### Handling Missing Data

Previous work has emphasized the importance of examining the pattern of
missing data and reporting how missingness was handled
[@van_de_schoot_grolts-checklist_2017].
While we concur that investigating missingness is due diligence,
it is important to emphasize that missingness is adequately handled by default in `OpenMx`, which is the computational backend of `tidySEM`.
Its Full Information Maximum Likelihood (FIML) estimator makes use of all available
information without imputing missing values [@endersRelativePerformanceFull2001].
FIML is a best-practice solution for handling missing data;
at least on par with multiple imputation [@lee_comparison_2021].
Multiple imputation is less suitable to LCA for two reasons. First,
because LCA methods are often computationally expensive,
and conducting them on multiple imputed datasets may be unfeasible.
Second, because many multiple imputation methods have some assumption of normality, which is likely to be violated when it is assumed that the data come from a heterogenous population.
FIML is not suitable for cases with complete missing data.

Three types of missingness have
been distinguished in the literature [@rubin_inference_1976; 
@enders_applied_2022]: random missingness (MCAR);
missingness contingent on *observed* variables that can thus be known and controlled for (MAR);
and missingness related to unobserved variables, which can neither be known nor controlled for (MNAR).
A so-called "MCAR" test is often reported in relation to missingness
[@jamshidian_tests_2010].
But note that this name is somewhat misleading,
as a significant test indicates that missingness is MAR,
but a non-significant test statistic does not distinguish between MCAR or MNAR.
As the classic MCAR test relies on the comparison of variances across groups with different patterns of missing data, it assumes normality [@little_test_1988].
This assumption is tenuous in the context of LCA.
A non-parametric MCAR test may be more suitable [@jamshidian_tests_2010].
For this tutorial,
the lead author has implemented this test in the `mice` package as `mice::mcar()`.

To conclude; our recommendation is to inspect and report the proportion of missingness per variable (e.g., using `tidySEM::descriptives()`),
and to test for MAR using `mice::mcar()`.
As FIML estimation assumes that missingness is either MCAR or MAR,
one would proceed with FIML regardless of the outcome of the test.
One minor concern is that the approach `tidySEM` uses to determine starting values is *not* robust to
partially missing data.
This should not be a problem, however, as uses a global optimizer to estimate LCA models,
which should be independent of starting values [@coranaMinimizingMultimodalFunctions1987].

### Model Specification

Any LCA model should be carefully specified based on theoretical and empirical considerations.
The parameters of LCA depend on the measurement level of the indicators.
LCA with continuous indicators can be parametrized in terms of means, variances, and covariances.
Latent class growth analyses have the same parameters,
but with respect to the latent growth variables.
LCA with ordinal indicators can be parametrized differently.
The approach implemented in `tidySEM` assumes that each ordinal variable reflects an underlying standard normal distribution.
The parameters are "thresholds" that correspond to quantiles of a standard
normal distribution (with $N(\mu = 0, \sigma = 1)$).
These thresholds
are estimated based on the proportion of individuals in each of the
response categories of the indicator variable. For example, a binary
indicator has a single threshold that distinguishes the two response
categories. If responses are distributed 50/50, then the corresponding
threshold would be $t_1 = 0.00$. If the responses are distributed 60/40,
then the resulting threshold would be $t_1 = 0.25$.
All of the aforementioned parameters can be freely estimated,
or constrained across classes, or fixed (e.g., to zero).

Prior literature emphasized the importance of considering alternative model specifications [@vandeschootGRoLTSChecklistGuidelinesReporting2017].
However, what has remained underemphasized is that alternative model specifications may be approached differently depending on whether an analysis is exploratory or confirmatory (see Use Cases).
Most prior literature has emphasized exploratory applications of LCA [e.g., @nylund_deciding_2007]
In this context, model specification typically consists of an exhaustive grid search along several model specifications and varying numbers of classes.
A "final" model is then selected based on a combination of fit indices,
significance tests,
and interpretability (see Class Enumeration).

Confirmatory LCA does not require such an extensive search over the model space.
If hypothesized models have been specified a priori,
and possibly even preregistered,
it makes sense to focus on these models, rather than proceed in a purely data-driven manner.
Nonetheless, an important reason to consider alternative model specifications is that LCA lacks objective fit indices.
The fit of a theoretical model can thus only be assessed by comparison to other candidates.
For this reason, the theoretical model should still be compared to a few others.
A one-class model is a sensible benchmark, to test whether LCA is even appropriate.
Other candidates for comparison include competing theoretical models and those with a few more or less classes than the hypothesized number.
If the theoretical model has much better fit than other models,
this provides evidence for the theory.
If differences in fit are small, however, this may not  do not give cause to reject a theoretical model.
The theoretical model may still be preferred, for example, to ensure comparability with prior work.
The fact that the theoretical model received little differential support should of course be discussed,
along with potential implications for future work.


<!-- This will ensure that the model accurately represents the data and provides reliable results. -->
<!-- Two factors play a role in LCA model specification: -->
<!-- the number of latent classes and the model estimated within each class. -->
<!-- Assuming the same model is estimated across classes, -->
<!-- the total number of parameters in LCA is equal to the number of parameters of the class-specific model times the number of classes, -->
<!-- plus a vector of class proportions with $K-1$ free elements. -->

<!-- In the general sense, the class-specific model can be any structural equation model. -->
<!-- Its parameters may include means, (co)variances, regression coefficients, factor loadings, and thresholds for ordinal variables. -->
<!-- All of these parameters can be freely estimated, -->
<!-- constrained to be equal across classes, -->
<!-- or fixed to a known value. -->
<!-- The specific types LCA introduced in the Taxonomy all have different parameters. -->
<!-- For example, LPA typically assumes class-specific means, -->
<!-- equal variances across classes, and zero covariances (i.e., indicators are independent after accounting for latent class membership), see `mx_profiles()`. -->
<!-- By contrast, LCA with ordinal indicators assumes free thresholds across classes, -->
<!-- where each threshold reflects a proportion of responses within a particular response category, see `mx_lca()`. -->
<!-- Like LPA, LCGA and GMM typically have free means across classes, -->
<!-- but with respect to the latent growth variables instead of the observed variables, see `mx_growth_mixture()`. -->
<!-- The distinction between LCGA and GMM is whether variances of the latent growth variables are constrained to zero, or freely estimated (either across or within classes). -->
<!-- either using `lavaan` model syntax or using `OpenMx` RAM specification, -->
<!-- and supplied to the general function `mx_mixture()`. -->
<!-- The resulting model may have -->





<!-- HIER -->
<!-- For latent profile analysis, the function -->
<!-- `tidySEM::mx_profiles(classes, variances, covariances)` largely -->
<!-- automates this process. The argument `classes` indicates which class -->
<!-- solutions should be estimated (e.g., 1 through 6). The argument -->
<!-- `variances` specifies whether variances should be `"equal"` or -->
<!-- `"varying"` across classes. The argument `covariances` specifies whether -->
<!-- covariances should be constrained to `"zero"`, `"equal"` or `"varying"` -->
<!-- across classes. The means are free to vary across classes by default, -->
<!-- although the more general function `tidySEM::mx_mixture()` could be used -->
<!-- to circumvent this. After all models have been estimated, the function -->
<!-- `tidySEM::table_fit()` can be used to obtain a model fit table suitable -->
<!-- for determining the optimal model according to best practices. Note, -->
<!-- however, that this table does not include the bootstrapped likelihood -->
<!-- ratio test (BLRT) by default, because this test is very computationally -->
<!-- expensive. It is recommended to use the function `tidySEM::BLRT()` to -->
<!-- compare a shortlist of likely candidate models based on other fit -->
<!-- indices. More on fit indices can be found in the Model Fit Indices -->
<!-- subsection of this paper. -->

A second consideration in model specification is the risk of overfitting [@hastieElementsStatisticalLearning2009].
Overfitting means that a model captures idiosyncratic noise in a sample,
and thus generalizes poorly to new samples.
It occurs when a model has many parameters relative to the number of observations
As explained before, the number of parameters in LCA scales with the number of estimated classes.
Consequently, LCA with many classes have a potentially very high number of parameters.



In Bayesian mixture modeling,
it was observed that if the estimated number of classes exceeded the true number, the number of observations assigned to these classes tended towards zero as sample size increased [@rousseauAsymptoticBehaviourPosterior2011].
Although it is not known whether frequentist LCA exhibits the same behavior,
this suggests that low class counts might indicate overfitting.


```{r, include = FALSE}
grolts <- structure(list(Number = c("1.", "2.", "3a.", "3b.", "3c.", "4.", 
"5.", "6a.", "6b.", "7.", "8.", "9.", "10.", "11.", "12.", "13.", 
"14a.", "14b.", "14c.", "15.", "16."), Item = c("Is the metric of time used in the statistical model reported?", 
"Is information presented about the mean and variance of time within a wave?", 
"Is the missing data mechanism reported?", "Is a description provided of what variables are related to attrition/missing data?", 
"Is a description provided of how missing data in the analyses were dealt with?", 
"Is information about the distribution of the observed variables included?", 
"Is the software mentioned?", "Are alternative specifications of within-class heterogeneity considered (e.g., LGCA vs. LGMM) and clearly documented? If not, was sufficient justification provided as to eliminate certain specifications from consideration?", 
"Are alternative specifications of the between-class differences in variance–covariance matrix structure considered and clearly documented? If not, was sufficient justification provided as to eliminate certain specifications from consideration?", 
"Are alternative shape/functional forms of the trajectories described?", 
"If covariates have been used, can analyses still be replicated?", 
"Is information reported about the number of random start values and final iterations included?", 
"Are the model comparison (and selection) tools described from a statistical perspective?", 
"Are the total number of fitted models reported, including a one-class solution?", 
"Are the number of cases per class reported for each model (absolute sample size, or proportion)?", 
"If classification of cases in a trajectory is the goal, is entropy reported?", 
"Is a plot included with the estimated mean trajectories of the final solution?", 
"Are plots included with the estimated mean trajectories for each model?", 
"Is a plot included of the combination of estimated means of the final model and the observed individual trajectories split out for each latent class?", 
"Are characteristics of the final class solution numerically described (i.e., means, SD/SE, n, CI, etc.)?", 
"Are the syntax files available (either in the appendix, supplementary materials, or from the authors)?"
), relevant = c(FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
TRUE, TRUE, TRUE)), row.names = c(NA, -21L), class = "data.frame")
```

### Software

	
LCA models can be estimated in a variety of ways.
Some of these packages have limited functionality, or implement specific
innovations. Other packages implement LCA in the context of a more
flexible structural equation modeling framework. The most notable
examples of the latter are the commercial programs Mplus and Latent
GOLD, and the free open source R-package OpenMx. The commercial packages
stand out because they offer relatively user-friendly interfaces and
implement sensible defaults for complex analyses, including LCA methods.
This lowers the threshold for applied researchers to adopt such methods.
Commercial software also has several downsides, however. One such
downside is that use of the software is restricted to those individuals
and institutions who can afford a license. Another downside is that the
source code, being proprietary, cannot be audited, debugged, or enhanced
by third parties. This incurs the risk that mistakes in the source code
may go unnoticed, and curbs progress as software developers cannot add
new functionality.

Conversely, the free open source program OpenMx [@neale_openmx_2016] is very flexible, but
not very user-friendly. We directly address this limitation using the
`tidySEM` R-package. New functionality in `tidySEM` seeks to lower the
threshold for latent class analysis using `OpenMx`. It adheres to best
practices in estimation and reporting, as described in this paper. The
user interface is simple, making use of the model syntax of the widely
used `lavaan` R-package [@rosseel_lavaan_2012]. This syntax offers a human-readable way to
specify latent variable models. Minor enhancements are made to simplify
the specification of LCA.

Because of the limitations of the aforementioned tools, we set out to
develop a free tool that provides sensible defaults and is easy to use,
but provides the option to access and modify all of the model inputs
(i.e., low barrier, high ceiling). `tidySEM` interfaces with existing
tools, and is able to translate between what existing tools are capable
of and what researchers and analysts carrying-out person-oriented
analyses would like to specify. Furthermore,`tidySEM` facilitates
fully-reproducible analyses and contributes to open science.

### Algorithm

LCA parameters and model fit statistics can be estimated in a variety of
ways. The choice of the estimator depends on the presence of missing
values, sample size, number of indicators, and available computational
resources [@weller_latent_2020]. A commonly used technique is maximum
likelihood (ML) estimation with the expectation-maximization (EM)
algorithm as a local optimizer. Imagine we are estimating two
parameters, e.g. the class-specific means $\mu_c$ on a continuous
(ignoring the variance for now).
EM attempts to find a combination of values for these two parameters that maximizes the log likelihood ($LL$) of the data.
In practice, instead of maximizing $LL$,
$-2*LL$ is minimized.
Transforming the likelihood this way does not change the resulting parameter estimates,
but it is mathematically convenient.
Moreover, the $-2*LL$ is asymptotically $\chi^2$ distributed if the null-hypothesis is true, and thus this quantity can be used for model fit tests [@wilksLargeSampleDistributionLikelihood1938].
To understand the optimization problem, imagine a three-dimensional landscape: 
The X and Y dimensions represent potential values of the class-specific means, $X = \mu_1$ and $Y = \mu_2$, and the Z-dimension is determined by $Z = -2*LL$. 
The optimizer must find the
deepest "valley" in this landscape,
which reflects the combination of $\mu_1$ and $\mu_2$ that minimizes the $-2*LL$.
The EM
optimizer behaves somewhat like a marble dropped in this landscape. It
is dropped at some random point in space, and will roll into the nearest
valley.
The challenge is that LCA models are often highly parametrized.
This means that the landscape is not three-dimensional, but (very) high-dimensional,
with potentially many valleys and sparse data to provide information about which valley is deepest.
If the marble rolls into one of these valleys,
it will settle there and not climb out again.
The estimator has "converged".
The risk is that the optimizer gets stuck in a shallower valley (a "local optimum"),
and never discovers the deepest valley (the "global optimum", or best solution).
One solution to this problem is to drop many marbles at random places,
compare their final $-2*LL$ values,
choose the solution
with the lowest $-2*LL$, and make sure that several marbles replicated
this solution.
This is the "random starts" approach implemented in, e.g., Mplus.

One problem with the random starts approach is that it is
computationally expensive to run this many replications. Moreover,
because the algorithm begins with random starting values,
it is inefficient because many marbles are likely to start very far away from any valley.
Finally, if all sets of starting values are close to a local optimum,
there is a risk that the global optimum is not discovered.
An alternative solution that overcomes these challenges is to use a global optimizer, like the simulated annealing algorithm [SA, @coranaMinimizingMultimodalFunctions1987].
SA does not behave quite like the marbles of the random starts approach;
instead, it iteratively considers some "destination" in the landscape,
and compares its $-2*LL$ to the current one.
If the destination $-2*LL$ is lower, 
the estimator moves there.
However, if the destination  $-2*LL$ is *higher*,
the estimator still moves there occasionally, with a certain probability.
Think of this as occasionally flicking the marble back out of valleys,
to see if it rolls back into the current valley, or finds another,
even deeper one.
This property allows SA it to escape local optima and find the global optimum.

Since SA is a global optimizer, it should be independent of starting values.
With this in mind, it is efficient to start estimation from a "reasonable solution", instead of a random starting point.
For example, if we assume that the different classes are likely to have different mean values on the indicators, 
then a nonparametric clustering algorithm - like K-means or hierarchical clustering - can be used to determine these cluster centroids [see also @biernackiChoosingStartingValues2003].
By default, `tidySEM` derives starting values using K-means clustering,
computing the mixture model starting values by treating the K-means solution as multi-group model.
Next, SA is used to find the global optimum solution.
Finally, SA is followed up with a short run of the ML algorithm,
as EM inherently produces an asymptotic
covariance matrix for the parameters that can be used to compute
standard errors.
Note that these defaults can be manually overridden.

In case of any (suspected) convergence problems,
note that `tidySEM` LCA models are `OpenMx` models.
Thus, existing `OpenMx` functions to aid model convergence can be used, like `mxTryHardWideSearch()` for continuous indicators, and `mxTryHardOrdinal()` for ordinal indicators.


### Class Enumeration

Class enumeration refers to the common practice of comparing models with different numbers of classes in LCA.
	
<!-- The total number of parameters scales with the number of estimated classes. -->
<!-- Consequently, latent class analyses have a potentially very high number of parameters. -->
<!-- As any of these parameters could be mis-specified, -->
<!-- it is important to consider alternative model specifications. -->
<!-- One way to obtain relative evidence in favor of different models is by using BIC weights, obtained by the function `tidySEM::ic_weights()` [@wagenmakersAICModelSelection2004]. -->

<!-- From sinhaPractitionerGuideLatent2021: -->
<!-- Testing for number of classes. In addition to indexing model fit, there are tests comparing a model with k classes to one with k-1 classes. Developed by Lo, Mendell and Rubin (36) based on work by Vuong (54) the VLMR test assumes multivariate normality, and it is not clear how sensitive the p-value is to violation of that assumption. It is also possible to use a bootstrapped p-value, although its validity outside of normally distributed data remains unknown.(55) In a Monte Carlo simulation of LCA using only categorical indicators, Nylund and colleagues found that the bootstrapped test (BLMR) consistently outperformed the simple Lo-Mendell-Rubin test (LMR).(34) Again in simulation studies with latent profile analysis (continuous indicators), Tein and colleagues found that the BLMR had higher statistical power than LMR, although both tests performed well at detecting the true class.(56) In our practice, across multiple analyses with real-life data consisting of a mixture of categorical and continuous indicators, we have found that the BLMR consistently favours k classes over k - 1 class to the point of being of limited value. -->
Class enumeration refers to the process of determining the appropriate number of classes.
This topic is closely related to model specification.
As explained before,
LCA can be done in an exploratory or in a confirmatory fashion.
In the confirmatory case, the set of models to be compared will be smaller.
In the exploratory case, the set of models typically consists of a sequence from 1 to some higher number of classes $K$.
The maximum number of classes $K$ may be chosen a-priori, or on theoretical accounts.
In practice, the limit is often dictated by the data;
after a certain number,
convergence problems may arise, 
or the proportion of cases assigned to the smallest classes may be so low that such a class would not be locally identified.
It is sensible to limit $K$ to the maximum number of classes that result in valid solutions.
<!-- In exploratory LCA, a sequence of models is fitted to the data -->
<!-- with each additional model estimating one more class than the previous -->
<!-- model. These models are then compared and the best solution is selected -->
<!-- as the final class solution. In some cases, prior theory can inform the -->
<!-- researcher about the number of classes to expect. Even in such -->
<!-- confirmatory LCA cases, it is nonetheless useful to know if the -->
<!-- theoretical model is markedly better than those with differing numbers -->
<!-- of classes. Therefore, it may always be useful to compare different -->
<!-- class solutions. -->

From a sequence of models, the final class solution is chosen based on
both theoretical and statistical criteria. Theory should drive the
selection of indicator variables, inform the expectations and reflect on
the findings. In addition to this, there are several statistical
criteria to consider in model selection. These include but are not
limited to likelihood ratio tests, information criteria, and the Bayes
factor [@weller_latent_2020; @masyn_latent_2013].

Relative model fit can be examined using the likelihood ratio test. This
is only appropriate when the two models we wish to compare are nested.
The likelihood ratio test statistic is computed as the difference in
maximum log-likelihoods of the two models, with the test degrees of
freedom being the difference in the degrees of freedom of the two
compared models. The test statistic follows the $\chi^2$ distribution,
and we want it to be non-significant in order to give support to the
simpler model. The likelihood ratio test can only compare two nested
models at a time [@lanza_introduction_2003].

### Model Fit Indices

As there are no absolute fit indices for LCA,
information criteria are typically used to assess relative fit.
The original information criterion is the Akaike Information Criterion (AIC);
it was designed to balance model fit and model complexity.
This is achieved by adding a penalty for the number of parameters to the -2\*log-likelihood (which is the most fundamental measure of model fit).
The lower
the value of an information criterion, the better the overall fit of the
model.
The Bayesian Information Criterion (BIC) multiplies the penalty for complexity with a function of the sample size,
such that complex models are penalized more in smaller samples.
Finally,
the so-called *sample size adjusted* BIC (saBIC) implements a different penalty for sample size.

Note however that this table does not include the bootstrapped likelihood ratio test (BLRT) by default,
because this test is very computationally expensive.
It is recommended to use the function `tidySEM::BLRT()` to compare a shortlist of likely candidate models based on other fit indices.

Fit indices typically used for determining the optimal number of classes include
the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC).
Both information criteria are based on the -2 log likelihood (which is lower for better fitting models),
and add a penalty for the number of parameters (thus incentivizing simpler models).
This helps balance fit and model complexity.
The BIC usually applies a stronger penalty for complexity that scales logarithmically with the sample size.

Information criteria may occasionally contradict each other, so it is
important to identify a suitable strategy to reconcile them. One option
is to select a specific fit index before analyzing the data. Another
option is to always prefer the most parsimonious model that has best fit
according to any of the available fit indices. Yet another option is to
incorporate information from multiple fit indices using the analytic
hierarchy process [@akogul_comparison_2016]. Finally, one might make an
elbow plot and compare multiple information criteria
[@nylund-gibson_ten_2018].

The literature suggests that the saBIC performs especially well for class enumeration.
However, unlike the AIC and BIC, its penalty for sample size is not grounded in theory.
BIC also performs well and is grounded in theory; as such, it may be the most appropriate information criterion to use for model
comparison [@nylund-gibson_ten_2018; @masyn_latent_2013]. 
All three ICs are available in `tidySEM` output.

<!-- The general objective of information criteria is to evaluate the model's  -->
<!-- out-of-sample predictive accuracy, -->
<!-- thus curtailing overfitting. -->
<!-- Fit measures such as $R^2$ evaluate the in-sample predictive accuracy,  -->
<!-- i.e. the model's ability to predict the observed outcomes based on the same  -->
<!-- data that was used to fit the model. In-sample metrics are positively biased,  -->
<!-- meaning that they overestimate the fit the model has in reality, i.e. when  -->
<!-- presented with new data. While common ways to overcome this bias is through -->
<!-- resampling methods such as cross-validation, or use of out-of-sample data such -->
<!-- as a test set, ICs correct for this positive bias by evaluating the model's  -->
<!-- accuracy in a way which approximates the out-of-sample predictive accuracy.  -->
<!-- ICs achieve this by applying different penalty metrics. For example, $R^2$ will  -->
<!-- increase even if an added predictor is fully redundant. ICs show preference for -->
<!-- simpler models and indicate worse fit when a predictor, or its added complexity  -->
<!-- is unnecessary [@mcelreath_statistical_2020].  -->

### Nested model tests

Another common test of model fit is the likelihood ratio $\chi^2$
goodness-of-fit test. However, this test is not implemented in
`tidySEM`.

A disadvantage of ICs is that they are not accompanied by standard errors or 
any measure of variability, only their absolute value. The difference between 
two models' ICs can be rather small. The lower information criterion would 
still indicate the better model, but if the ICs difference is very small, 
two models can be considered "functionally equal". In such situations, the 
interpretability of the model should take priority. 

LCA studies commonly report -2\*log likelihood of the final class
solution. This is a basic fit measure used to compute most information
criteria. However, since log likelihood is not penalized for model
complexity, it will continuously fall with the addition of more classes.

An alternative is using the bootstrapped likelihood ratio test which can
be run using `tidySEM::BLRT()`. Currently, this test is computationally
expensive and can be slow on most computers. A faster version of this
test, namely an implementation of *the lazy bootstrap*
[@van_kollenburg_lazy_2018] to `tidySEM` is being developed.

### Classification Diagnostics

Best models will divide the sample into subgroups which are internally
homogeneous and externally distinct. Classification diagnostics give us
a way to assess the degree to which this is the case. They are separate
from model fit indices as a model can fit the data well but show poor
latent class separation [@masyn_latent_2013]. Classification diagnostics
should not be used for model selection, but they can be used to
disqualify certain solutions because they are uninterpretable.
Interpretability should always be a consideration when considering
different class solutions [@nylund-gibson_ten_2018].

Three important classification diagnostics provided by `tidySEM` are:
(1) the *minimum* and *maximum* percentage of the sample assigned to a 
particular *class*, (2) the *range of the posterior class probabilities* by most
likely class membership, and (3) *entropy*. All three are based on posterior 
class probabilities.
<!-- MGV: I will work on adding average posterior class probability (AvePP) as well-->

The posterior class probability is a measure of classification
uncertainty which can be computed for each individual, or averaged for
each latent class. When the posterior class probability is computed for
each individual in the dataset, it represents each person's probability
of belonging to each latent class. For each person, the highest
posterior class probability is then determined and the individual is
assigned to the corresponding class. We want each individual's posterior
class probabilities to be high for one and low for the remaining latent
classes. This is considered a high classification accuracy and means
that the classes are distinct. To obtain posterior class probabilities,
run `tidySEM::class_prob()`. This function produces output comprised of
several elements:

`$sum.posterior` is a summary table of the posterior class probabilities
indicating what proportion of the data contributes to each class.

`$sum.mostlikely` is a summary table of the most likely class membership
based on the highest posterior class probability. From this table, we
compute the minimum and maximum percentage of the sample assigned to a
particular class, , i.e. **n_min** (the smallest class proportion based
on the posterior class probabilities) and **n_max** (the largest class
proportion based on the posterior class probabilities). We are
especially interested in **n_min** as if it is very small and comprised
of few observations, the model for that group might not be locally
identified. It may be impossible to calculate descriptive statistics for
such a small class. Estimating LCA parameters on small subsamples might
lead to bias in the results. Therefore, we advise caution when dealing
with small classes.

`$mostlikely.class` is a table with rows representing the class the
person was assigned to, and the columns indicating the average posterior
probability. The diagonal represents the probability that observations
in each class will be correctly classified. If any of the values on the
diagonal of this table is low, we might consider not to interpret that
solution. In `tidySEM` we use the diagonal to compute the range of the
posterior class probabilities by most likely class membership which
consists of the lowest class posterior probability (**prob_min**), and
the highest posterior probability (**prob_max**). Both **prob_min** and
**prob_max** can be used to disqualify certain class solutions, and are
a convenient way to summarize class separation in LCA. We want both
**prob_min** and **prob_max** to be high as that means that for all
classes the people who were assigned to that class have a high
probability of being there. **prob_min** is especially important as it
can diagnose if there is a class with low posterior probabilities which
could make one reconsider that class solution.

`$avg.mostlikely` contains the average posterior probabilities for each
class, for the subset of observations with most likely class of 1:k,
where k is the number of classes.

`$individual` is the individual posterior probability matrix, with
dimensions n (number of cases in the data) x k (number of classes). 
Additionally, it includes the `predicted` class as a function of the highest 
predicted probability. Individual class probabilities and/or predicted class 
are often useful to researchers who wish to carry out follow up analyses. 

Entropy is a summary measure of posterior class probabilities across
classes and individuals. It ranges from 0 (model classification no
better than random chance) to 1 (perfect classification). As a rule of
thumb, values above .80 are deemed acceptable and those approaching 1
are considered ideal. An appropriate use of entropy is that it can
disqualify certain solutions if class separability is too low. Entropy
was not built for nor should it be used for model selection during class
enumeration [@masyn_latent_2013].

**n_min**, **n_max**, **prob_min**, **prob_max**, and **entropy** and
can be obtained using `tidySEM::table_fit()`.

### Interpreting Class Solutions

An important outcome of LCA are conditional item probabilities, also
known as class-specific item probabilities [@masyn_latent_2013],
conditional response, or conditional solution probabilities
[@geiser_data_2012]. They indicate the probability of an item being
endorsed given that the observation belongs to a particular latent
class. Conditional item probabilities can be obtained using
`tidySEM::table_prob()`. If a particular item is endorsed by two or more
classes at markedly different rates, it is said to discriminate well
between the classes and is consequently considered a good indicator.
Classes are considered highly homogeneous with respect to an item when
for a particular item there is a distinct difference in conditional item
probabilities for two or more classes. For instance, if an item is
endorsed below 30% for one class and above 70% for another class, the
classes have high homogeneity with respect to this item
[@masyn_latent_2013]. Conditional item probabilities are the analogue of
mean and standard deviation when the indicators are binary or ordinal.

A problem which can occur is that of inadmissible solutions. With binary
indicators, LCA is modeling a cross-table with all the predictors. The
problem with such cross-tables is that they will often contain empty
cells, i.e. combinations of responses that never occur together. This
problem is reflected by extreme conditional item probabilities (as in
exactly 0 or 1). Such boundary parameter estimates could indicate that
the solution is invalid [@geiser_data_2012]. Boundary parameter
estimates can also happen with continuous indicators. For instance, if
we have a zero-inflated normal distribution and a two class solution,
one class might have the mean of zero and its standard deviation cannot
be determined since there is little variance. This too could be a sign
of an invalid solution, warn that too many classes were extracted, or
indicate a local optimum [@geiser_data_2012].

### Label Switching

The final class solution will usually discover and enumerate several
classes. The class ordering, however, is completely arbitrary. The class
labeled as Class 1 in one solution may become Class 2 or Class 3 in
another model, even when the only difference between the models is in
their starting values. Label switching is something to be mindful of
when comparing different LCA models [@masyn_latent_2013].

The order of clusters is nondeterministic when using K-means in
`tidySEM`. Therefore label switching is still a consideration. A simple
solution to this is setting a random seed number one line prior to
fitting the model. We advise `tidySEM` users to always do so in order to
circumvent label switching.

Class names should be chosen to accurately reflect group membership,
as theoretically relevant names according to the interpretation of the class 
solutions. Overly simplified and generalized class names may prove misleading 
to both audiences and researches alike leading to what is known as a naming
fallacy [@weller_latent_2020].

## Best Practices in Reporting

Among studies using LCA, reporting practices vary significantly
[@weller_latent_2020]. Various authors have tried to improve and
standardize ways of reporting LCA [e.g. @masyn_latent_2013;
@weller_latent_2020], but more work is needed. 
<!-- This does not belong here: -->
<!-- @van_lissa_worcs_2020 -->
<!-- developed WORCS, a workflow for open reproducible code in science. WORCS -->
<!-- consists of step-by-step guidelines for research projects based on the -->
<!-- TOP-guidelines developed by @nosek_promoting_2015. WORCS workflow can be -->
<!-- easily implemented in R in form of an R package which facilitates -->
<!-- preregistration, article drafting, version control, citation and -->
<!-- formatting, among others [@van_lissa_worcs_2020]. -->

TOP-guidelines emphasize the use of comprehensive citation (including
referencing the software used in the analysis), as well as code and data
sharing wherever possible [@nosek_promoting_2015]. @van_lissa_worcs_2020
If the original data cannot be shared, sharing synthetic data is a good alternative.
The function `worcs::synthetic()` provides a generic, non-parametric method to create a synthetic copy of data.
When synthesizing data for LCA, it is also possible to synthesize data directly from the model.
LCA models constructed in `tidySEM` are estimated using `OpenMx`,
and as such, can benefit from all existing functions in that package.
To synthesize data from a mixture model `mix`, use the function `mxGenerateData(mix)`.

the entire research project is made reproducible so that others may
download it and reproduce it with just one click; for guidance, see
@van_lissa_worcs_2020.

As the open science movement is gaining momentum, researchers are
becoming increasingly aware how important it is that analyses can be
reproduced and audited. In line with open science principles, one of the
suggested reporting standards relates to reproducible code. In this
context, it is important to note that user-friendly methods for
estimating LCA models have predominantly been available in commercial
software packages (e.g., *Mplus* and *Latent GOLD*). A potential
downside of commercial software is that it restricts the ability to
reproduce analyses to license holders, and prevents auditing research
because the underlying source code is proprietary. To overcome these
limitations, the present paper introduces new user-friendly functions in
the `tidySEM` R-package that can be used to estimate a wide range of LCA
models using the free, open-source R-package `OpenMx` as the backend. The 
reporting guidelines described in this paper are adopted in `tidySEM` by 
default. The `tidySEM` R-package thus makes advanced mixture modeling based 
on best practices widely accessible, and facilitates the adoption of the
estimation and reporting guidelines described in this paper.

### Visualization

Plots can greatly improve the interpretability of LCA models. There are
several stages where this is an important consideration.

First, in class enumeration, we want to compare several competing class
solutions. This can be done by means of the AIC and BIC. Here, we
suggest using an elbow plot with the $K-class\ solution$ on the X-axis,
and information criteria value on the Y-axis. For continuous variables, 
density plots can aid class enumeration. We demonstrate how to implement 
both elbow and density plots in the Tutorial subsection of this paper.

Second, once we have decided on the final class solution, we want to
interpret the response patterns on the indicators for each latent class.
While `tidySEM` can create a table showing the probability of each
item's response endorsement (using `tidySEM::table_prob`), it may be
easier to inspect these probabilities visually. For this reason, we
created `ggplot2::plot_prob()`. The resulting shows response patterns on
all indicators for each group. We give an example of this plot in the
Tutorial subsection.

## Myths and misunderstandings

Relatedly, a recent publication claimed that an assumption of mixture
models is that observed indicators are normally distributed
[@spurk_latent_2020]. This is incorrect. When the number of classes is
greater than one, Gaussian mixture models assume that the observed indicators 
are a mixture of multiple (multivariate) normal distributions. In our shoe
size example, it can be seen that the population distribution is
comprised of two normal distributions. When examined visually, the
population distribution is evidently bimodal. The Shapiro-Wilk normality
test ($W `r report(shoesize_shapiro[["statistic"]])`$, $p `r report(shoesize_shapiro[["p.value"]])`$ ) rejects the null hypothesis that the
sample comes from a normally distributed population. Yet, this is a
prototypical example of a mixed population distribution where LCA can
discover latent groups. If the population distribution were instead
normal, there would be no classes to extract as the whole population
would belong to a single (homogeneous) class.

A recent paper suggested maximum likelihood with robust standard errors
should be used when the observed indicators are not normally distributed
[@spurk_latent_2020].
This statement is incorrect;
LCA does not have an assumption of marginal normality, and there is - to our knowledge - no literature on the merits of robust standard errors for LCA.

<!-- and may lead readers -->
<!-- to believe that they must use commercial software, as robust maximum -->
<!-- likelihood is currently only implemented in Mplus and LatentGOLD. As -->
<!-- explained before, mixture modeling assumes that observed data are a -->
<!-- mixture of (multivariate) normal distributions; thus, the observed -->
<!-- indicators will likely not be normally distributed. -->
<!-- CJ: there is no literature that says robust standard errors are better with latent class analysis? -->

<!-- Treating ordinal data as continuous -->
<!-- People omitting the 1-class solution in class enumeration -->

# Tutorial

This is an example of an exploratory LCA using `tidySEM`.

## Loading the Dataset

In this example, we use *data_mix_ordinal*, a simulated data for mixture
modeling with ordinal indicators. This dataset is built-in to
`tidySEM`. For more information about the dataset, type
`?tidySEM::data_mix_ordinal` into the R console after loading the
`tidySEM` using library().

We load the dataset and convert the indicators into ordered factors.

```{r, include = TRUE, eval=F}
# Load required packages
library(tidySEM) 
# Load data
df <- data_mix_ordinal
```

## Exploring the Data

An important step to preceding any statistical analysis is data
exploration. Here we use `tidySEM::descriptives()` to describe the
dataset we are using.

```{r, include = TRUE, eval=F}
tidySEM::descriptives(df)
```

As we can see, the output includes various descriptives of our dataset.
Special attention should be paid to examining the pattern of
missingness, as discussed in the *Handling missing data* section of this
paper. In our example, we see that there are no missing values, hence we
proceed with our analysis.

## Conducting Latent Class Analysis

Before we fit a series of LCA models, we set a random seed using
`set.seed()`. This is an important
step as there is some inherent randomness in the LCA computations, and
having the same seed number ensures that two separate researcher obtain
exactly the same results when fitting LCA models.

Finally, we reach the step of fitting LCA models.
As all variables are ordinal, we can use the convenience function
`tidySEM::mx_lca()`, which is a wrapper for the generic function `mx_mixture()`,
optimized for latent class analysis with ordinal data.
Any mixture model can be specified through `mx_mixture()`,
but at the time of writing, there are two more wrapper functions for specialized models:
`mx_profiles()`, for latent profile analysis, and `mx_growth_mixture()`, for latent growth analysis and growth mixture models.
All of these functions have arguments `data` and number of `classes`.
All variables in `data` are included in the analysis,
so relevant variables must be selected first.
Below, we fit 1 to 4 class solutions.
<!-- Depending on your computer's computational power, -->
<!-- this might take a while. -->
<!-- As `tidySEM::mx_lca()` run several models at a time, the resulting object `res`  -->
<!-- is a `mixture_list` class where each $K$ class solution is a list element, or -->
<!-- more specifically an `OpenMx` model (`MxModel`). -->

```{r fitting_LCA, include = TRUE, eval=F}
set.seed(123) # setting seed 
res <- mx_lca(data = df, classes = 1:4) # fitting LCA 1 to 4 class solutions
```

<!-- Notice that the model run 10 times for each $K$ class solution. -->
<!-- This way we can choose the best fitting model across all the solutions. -->
<!-- In this example, we see that all models converged without issues.  -->
<!-- We can inspect the class of resulting objects. -->

```{r, include = TRUE, eval=F, echo = F}
is(res)
is(res[[1]])
```

## Class Enumeration

In class enumeration, we want to compare a sequence of LCA models fitted
to the data. To aid the process, we create a model fit table using
`tidySEM::table_fit()` with the results object as the input. As the
output contains a lot of information on each of the four fitted models,
we select a subset of helpful model fit indices and classification
diagnostics.

```{r fit_table, include = TRUE, eval=F}
fit_table <- table_fit(res) # model fit table
fit_table[ , c("Name", "LL", "Parameters", 
               "AIC", "BIC", "Entropy", 
               "prob_min", "prob_max", 
               "n_min", "n_max")] # our selection
```

Our selection of fit indices and classification diagnostics includes:

```{r, echo=F}
Selection <- c(
    "Name", "LL", "Parameters", 
    "AIC", "BIC", "prob_min", 
    "prob_max", "n_min", "n_max")

Description <- c(
    "Number of classes $K$",
    "Basic fit measure of the natural log of the likelihood of the data",
    "Total number of model parameters (in all classes)",
    "Relative fit measure: Akaike Information Criterion",
    "Relative fit measure: Bayesian Information Criterion",
    "Lowest average posterior class probability for class cases were assigned to",
    "Highest average posterior class probability for class cases were assigned to",
    "Proportion of cases in the smallest class based on posterior class probability",
    "Proportion of cases in the largest class based on posterior class probability")

selection <- cbind(Selection, Description)

knitr::kable(selection, format = 'pipe', 
             caption = "Selection of Fit Indices and 
                        Classification Diagnostics")
```


We discussed several possible strategies to select the final class
solution. Here, we apply our own.

To aid our interpretation of the results, we create an elbow plot
showing the trends in information criteria across four models.

```{r elbow_plot, include = TRUE, message=F, warning=F, eval=F}
library(tidyverse) # for data-wrangling
library(ggplot2) # for plots

elbow_plot <- fit_table[ , c("Name", "AIC", "BIC")] # extract ICs
elbow_plot <- pivot_longer(elbow_plot, cols = c("AIC", "BIC"), 
                           names_to = "IC", values_to = "Value") # to long format

ggplot(elbow_plot, aes(x = Name, y = Value, group = IC))+
  geom_point(aes(color = IC))+
  geom_line(aes(color = IC))+
  labs(title="Elbow Plot of Information Criteria per Class Solution", 
       x = "Class Solution", y = " Value")+
  scale_color_manual(name = "Information Criterion", 
                     values = c(AIC = 'blue', BIC = 'red'))+
  theme_minimal()

```

From the elbow plot, we see that AIC has a lower penalty for model
complexity. However, we are more interested in the BIC values, which are
similar for the one, two and three-class solutions, but the four-class
solution fits significantly worse. For this reason, we eliminate the
four-class solution from the selection process.

Then we examine the model fit table. As expected, the -2\*log likelihood
falls successively with each added class. As previously stated,
classification diagnostics should not be used for model selection, but
they can be used to disqualify certain solutions because they are
uninterpretable. We see that prob_min and n_min for the four-class solution is
low, knowing that this solution also has a high BIC, we disqualify this
solution.

Out of the remaining three solutions, we notice that entropy is the
highest for the three-class solution, and it has a satisfactory prob_min
and n_min. Based on this, we retain the three class solution in model
selection. Note that entropy for the one-class solution will always
equal to one, as it is 100% true that every case is in that class. Based
on the low entropy of the two-class solution, we eliminate this model.

Finally, when comparing the one and three-class solutions, we inspect
the information criteria. For BIC, the one-class solution fits better,
but the difference is marginal. AIC tells us that the added complexity
of having three classes still explains the data better than a one-class
solution. Therefore, we select the three-class solution as our
final-class solution.

## Interpreting the Final Class Solution

To aid our understanding of the final class solution, we use
`ggplot2::plot_prob()` with the results of the three-class model as the
input. The resulting graph shows response patterns on all the indicators
for each group.

If we want to know the probability of each response option's endorsement
for each class, we can use `tidySEM::table_prob`. These are thresholds
for ordinal dependent variables in the probability scale.

```{r plot_prob, include = TRUE, eval=F}
plot_prob(res[[3]]) # visualizing the response patterns for the final model
table_prob(res[[3]]) # tabulating the response patterns for the final model
```

In the plot, we can see the distributions of the response probabilities
on the indicators for each of the three classes. For instance, we see
that in Class 1 the most common response to u2 is 2, while in Class 2
and Class 3 this is 0. We can also see that response 1 is a rare
response not forming the majority in any class. Class 2 distinguishes
itself because the majority scores the response 0 category of u3 and u4,
while in Class 1 and 2 this is not the case. Class 3 distinguishes
itself because the most common response to u3 and u4 is 3.

We can also interpret the response patterns numerically. It is a matter of 
preferences on how to interpret these probabilities. Here is where you would
**name** each class, such that each response pattern is theoretically meaningful.

## Extracting Posterior Class Probabilities

Another step is to extract posterior class probabilities. This is done
by the use of `tidySEM::class_prob` with the results of the final class
solution as the input.

```{r extract_Post_Class_Prob, include = TRUE, eval=F}
probs <- class_prob(res[[3]]) # extracting the posterior class probabilities
probs$mostlikely.class # posterior probabilities by most likely class membership
probs$individual # individual posterior class probabilities
```

\newpage

# References
